{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import logging\n",
    "import multiprocessing\n",
    "import traceback\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fmt = \"[%(asctime)s] %(levelname)s in %(module)s: %(message)s\"\n",
    "logging.basicConfig(format=log_fmt, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data'\n",
    "feature_path = './feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-09 14:30:21,837] INFO in <ipython-input-5-af34e33feb4f>: invite (9489162, 4)\n",
      "[2019-12-09 14:30:23,302] INFO in <ipython-input-5-af34e33feb4f>: test (1141683, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(f'{base_path}/invite_info_0926.txt', sep='\\t', header=None)\n",
    "train.columns = ['qid', 'uid', 'dt', 'label']\n",
    "logging.info(\"invite %s\", train.shape)\n",
    "\n",
    "test = pd.read_csv(f'{base_path}/invite_info_evaluate_0926.txt', sep='\\t', header=None)\n",
    "test.columns = ['qid', 'uid', 'dt']\n",
    "logging.info(\"test %s\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_day(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[0][1:]))\n",
    "\n",
    "\n",
    "def extract_hour(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[1][1:]))\n",
    "\n",
    "train['day'] = extract_day(train['dt'])\n",
    "train['week'] = train['day'] % 7\n",
    "train['hour'] = extract_hour(train['dt'])\n",
    "\n",
    "test['day'] = extract_day(test['dt'])\n",
    "test['week'] = test['day'] % 7\n",
    "test['hour'] = extract_hour(test['dt'])\n",
    "\n",
    "del train['dt'], test['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-09 14:31:10,187] INFO in <ipython-input-7-cbb4bab8955e>: user (1931654, 14)\n"
     ]
    }
   ],
   "source": [
    "# 加载用户\n",
    "user = pd.read_csv(f'{base_path}/member_info_0926.txt', header=None, sep='\\t')\n",
    "user.columns = ['uid', 'gender', 'freq', 'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "                'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5',  'score', 'follow_topic', 'inter_topic']\n",
    "\n",
    "del user['follow_topic'], user['inter_topic']\n",
    "logging.info(\"user %s\", user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge user\n",
    "train = pd.merge(train, user, on='uid', how='left')\n",
    "test = pd.merge(test, user, on='uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-09 14:31:48,056] INFO in <ipython-input-9-3053b1f3a755>: ques (1829900, 2)\n"
     ]
    }
   ],
   "source": [
    "# 加载问题\n",
    "ques = pd.read_csv(f'{base_path}/question_info_0926.txt', header=None, sep='\\t')\n",
    "ques.columns = ['qid', 'q_dt', 'title_t1', 'title_t2', 'desc_t1', 'desc_t2', 'topic']\n",
    "del ques['title_t1'], ques['title_t2'], ques['desc_t1'], ques['desc_t2'], ques['topic']\n",
    "logging.info(\"ques %s\", ques.shape)\n",
    "\n",
    "ques['q_day'] = extract_day(ques['q_dt'])\n",
    "ques['q_hour'] = extract_hour(ques['q_dt'])\n",
    "ques['q_week'] = ques['q_day'] % 7\n",
    "\n",
    "del ques['q_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ques\n",
    "train = pd.merge(train, ques, on='qid', how='left')\n",
    "test = pd.merge(test, ques, on='qid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['diff_iq_day'] = train['day'] - train['q_day']\n",
    "train['diff_iq_hour'] = train['diff_iq_day'] * 24 + (train['hour'] - train['q_hour'])\n",
    "\n",
    "test['diff_iq_day'] = test['day'] - test['q_day']\n",
    "test['diff_iq_hour'] = test['diff_iq_day'] * 24 + (test['hour'] - test['q_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 invete feature 2: intersection_ft_count, intersection_it_count\n",
    "t1 = pd.read_csv(f'{feature_path}/train_invite_feature_2.txt', sep='\\t', \n",
    "                 usecols=['intersection_ft_count', 'intersection_it_count'])\n",
    "train = pd.concat([train, t1], axis=1)\n",
    "\n",
    "t1 = pd.read_csv(f'{feature_path}/test_invite_feature_2.txt', sep='\\t', \n",
    "                 usecols=['intersection_ft_count', 'intersection_it_count'])\n",
    "test = pd.concat([test, t1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分 intersection_ft_count\n",
    "def to_bin_1(x):\n",
    "    if x>=3:\n",
    "        return 3\n",
    "    return x\n",
    "\n",
    "train['intersection_ft_count'] = train['intersection_ft_count'].apply(to_bin_1)\n",
    "test['intersection_ft_count'] = test['intersection_ft_count'].apply(to_bin_1)\n",
    "\n",
    "# 划分 intersection_it_count\n",
    "def to_bin_2(x):\n",
    "    if x>=4:\n",
    "        return 4\n",
    "    return x\n",
    "\n",
    "train['intersection_it_count'] = train['intersection_it_count'].apply(to_bin_2)\n",
    "test['intersection_it_count'] = test['intersection_it_count'].apply(to_bin_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1773515933229931"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17087539518378606\n",
      "0.19507707344646075\n",
      "0.22500282617325626\n",
      "0.2665859302869339\n"
     ]
    }
   ],
   "source": [
    "# intersection_ft_count 有0~5，划分为0~3 \n",
    "for i in range(0, 3):\n",
    "    print(train[train['intersection_ft_count']==i]['label'].mean())\n",
    "print(train[train['intersection_ft_count']>=3]['label'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18145724765232774\n",
      "0.13238402139873304\n",
      "0.1459849618021744\n",
      "0.19836384254009395\n",
      "0.2152317880794702\n"
     ]
    }
   ],
   "source": [
    "# intersection_ft_count 有0~5，划分为0~4\n",
    "for i in range(0, 4):\n",
    "    print(train[train['intersection_it_count']==i]['label'].mean())\n",
    "print(train[train['intersection_it_count']>=4]['label'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4折统计\n",
    "def fold_fn(x):\n",
    "    if 3838<=x<=3846:\n",
    "        return 0\n",
    "    if 3847<=x<=3853:\n",
    "        return 1\n",
    "    if 3854<=x<=3860:\n",
    "        return 2\n",
    "    if 3861<=x<=3867:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fold'] = train['day'].apply(fold_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 一阶\n",
    "def single_train_feat(df_, feat):\n",
    "    df = df_.copy()\n",
    "    extract_feat_1 = [feat+'_kfold_count', feat+'_label_mean', feat+'_label_sum', feat+'_label_std']\n",
    "    extract_feat_2 = [feat+'_kfold_hour_count', feat+'_label_hour_mean', \n",
    "                      feat+'_label_hour_sum', feat+'_label_hour_std']\n",
    "    extract_feat_3 = [feat+'_kfold_week_count', feat+'_label_week_mean', \n",
    "                      feat+'_label_week_sum', feat+'_label_week_std']\n",
    "    extract_feat = extract_feat_1 + extract_feat_2 + extract_feat_3\n",
    "    for c in extract_feat:\n",
    "        df[c] = -10000\n",
    "    for i in range(4):\n",
    "        t1 = df[df['fold']!=i].groupby(feat)['label'].agg(['count', 'mean', 'sum', 'std']).reset_index()\n",
    "        t1.columns = [feat] + extract_feat_1\n",
    "        df.loc[df['fold']==i, extract_feat_1] = pd.merge(df.loc[df['fold']==i, feat], t1, on=feat, \n",
    "                                                         how='left')[extract_feat_1].values\n",
    "        # 某小时\n",
    "        t1 = df[df['fold']!=i].groupby([feat, 'hour'])['label'].agg(['count', \n",
    "                                                                     'mean', 'sum', 'std']).reset_index()\n",
    "        t1.columns = [feat, 'hour'] + extract_feat_2\n",
    "        df.loc[df['fold']==i, extract_feat_2] = pd.merge(df.loc[df['fold']==i, [feat, 'hour']], \n",
    "                                                         t1, on=[feat, 'hour'], \n",
    "                                                         how='left')[extract_feat_2].values\n",
    "        # 一周的某一天\n",
    "        t1 = df[df['fold']!=i].groupby([feat, 'week'])['label'].agg(['count', \n",
    "                                                                     'mean', 'sum', 'std']).reset_index()\n",
    "        t1.columns = [feat, 'week'] + extract_feat_3\n",
    "        df.loc[df['fold']==i, extract_feat_3] = pd.merge(df.loc[df['fold']==i, [feat, 'week']], \n",
    "                                                         t1, on=[feat, 'week'], \n",
    "                                                         how='left')[extract_feat_3].values\n",
    "    # 数据压缩\n",
    "    for c in range(0, len(extract_feat), 2):\n",
    "        df[extract_feat[c]] = df[extract_feat[c]].fillna(0).astype('int32')\n",
    "    for c in range(1, len(extract_feat), 2):\n",
    "        df[extract_feat[c]] = df[extract_feat[c]].astype('float32')\n",
    "\n",
    "    return df[extract_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_targets = ['uid', 'qid', 'freq', 'score', \n",
    "                  'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "                  'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5',\n",
    "                  'diff_iq_day', 'diff_iq_hour', \n",
    "                  'intersection_ft_count', 'intersection_it_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_proc = len(single_targets)\n",
    "\n",
    "def kfold_worker_1(df, feat):\n",
    "    try:\n",
    "        t1 = single_train_feat(df, feat)\n",
    "        logging.info('%s, feature shape: %s', feat, t1.shape)\n",
    "        \n",
    "        pickle.dump(t1, open(f'{feature_path}/single_kfold_feat/train_{feat}.pkl', 'wb'))\n",
    "        logging.info('%s feature saved!', feat)\n",
    "        del t1\n",
    "        gc.collect()\n",
    "    except:\n",
    "        print(traceback.print_exct())\n",
    "\n",
    "def multi_proc_train(df, feat_list):\n",
    "    pool = multiprocessing.Pool(processes=n_proc)\n",
    "    for f in feat_list:\n",
    "        pool.apply_async(kfold_worker_1, (df, f))\n",
    "    pool.close()\n",
    "    pool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-09 11:42:28,118] INFO in <ipython-input-132-b9d848fe07d8>: freq, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:42:29,621] INFO in <ipython-input-132-b9d848fe07d8>: freq feature saved!\n",
      "[2019-12-09 11:43:02,866] INFO in <ipython-input-132-b9d848fe07d8>: score, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:43:04,536] INFO in <ipython-input-132-b9d848fe07d8>: score feature saved!\n",
      "[2019-12-09 11:45:00,648] INFO in <ipython-input-132-b9d848fe07d8>: qid, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:45:02,699] INFO in <ipython-input-132-b9d848fe07d8>: qid feature saved!\n",
      "[2019-12-09 11:45:13,097] INFO in <ipython-input-132-b9d848fe07d8>: uf_b1, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:45:14,609] INFO in <ipython-input-132-b9d848fe07d8>: uf_b1 feature saved!\n",
      "[2019-12-09 11:46:02,426] INFO in <ipython-input-132-b9d848fe07d8>: uid, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:46:04,782] INFO in <ipython-input-132-b9d848fe07d8>: uid feature saved!\n",
      "[2019-12-09 11:46:21,583] INFO in <ipython-input-132-b9d848fe07d8>: uf_b2, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:46:24,014] INFO in <ipython-input-132-b9d848fe07d8>: uf_b2 feature saved!\n",
      "[2019-12-09 11:46:39,877] INFO in <ipython-input-132-b9d848fe07d8>: uf_b3, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:46:42,135] INFO in <ipython-input-132-b9d848fe07d8>: uf_b3 feature saved!\n",
      "[2019-12-09 11:46:45,994] INFO in <ipython-input-132-b9d848fe07d8>: uf_c1, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:46:48,036] INFO in <ipython-input-132-b9d848fe07d8>: uf_c1 feature saved!\n",
      "[2019-12-09 11:47:03,965] INFO in <ipython-input-132-b9d848fe07d8>: uf_b4, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:47:06,201] INFO in <ipython-input-132-b9d848fe07d8>: uf_b4 feature saved!\n",
      "[2019-12-09 11:47:11,442] INFO in <ipython-input-132-b9d848fe07d8>: uf_c2, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:47:13,110] INFO in <ipython-input-132-b9d848fe07d8>: uf_c2 feature saved!\n",
      "[2019-12-09 11:47:56,207] INFO in <ipython-input-132-b9d848fe07d8>: uf_c5, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:47:57,613] INFO in <ipython-input-132-b9d848fe07d8>: uf_c5 feature saved!\n",
      "[2019-12-09 11:48:03,861] INFO in <ipython-input-132-b9d848fe07d8>: diff_iq_day, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:48:05,515] INFO in <ipython-input-132-b9d848fe07d8>: diff_iq_day feature saved!\n",
      "[2019-12-09 11:48:17,996] INFO in <ipython-input-132-b9d848fe07d8>: diff_iq_hour, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:48:19,466] INFO in <ipython-input-132-b9d848fe07d8>: diff_iq_hour feature saved!\n",
      "[2019-12-09 11:48:31,398] INFO in <ipython-input-132-b9d848fe07d8>: intersection_it_count, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:48:32,832] INFO in <ipython-input-132-b9d848fe07d8>: intersection_it_count feature saved!\n",
      "[2019-12-09 11:48:44,491] INFO in <ipython-input-132-b9d848fe07d8>: uf_b5, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:48:46,132] INFO in <ipython-input-132-b9d848fe07d8>: uf_b5 feature saved!\n",
      "[2019-12-09 11:48:47,132] INFO in <ipython-input-132-b9d848fe07d8>: intersection_ft_count, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:48:48,483] INFO in <ipython-input-132-b9d848fe07d8>: intersection_ft_count feature saved!\n",
      "[2019-12-09 11:50:03,391] INFO in <ipython-input-132-b9d848fe07d8>: uf_c3, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:50:05,236] INFO in <ipython-input-132-b9d848fe07d8>: uf_c3 feature saved!\n",
      "[2019-12-09 11:50:35,819] INFO in <ipython-input-132-b9d848fe07d8>: uf_c4, feature shape: (9489162, 12)\n",
      "[2019-12-09 11:50:37,718] INFO in <ipython-input-132-b9d848fe07d8>: uf_c4 feature saved!\n"
     ]
    }
   ],
   "source": [
    "multi_proc_train(train, single_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 一阶\n",
    "def single_test_feat(df, feat):\n",
    "    extract_feat_1 = [feat+'_kfold_count', feat+'_label_mean', feat+'_label_sum', feat+'_label_std']\n",
    "    extract_feat_2 = [feat+'_kfold_hour_count', feat+'_label_hour_mean', \n",
    "                      feat+'_label_hour_sum', feat+'_label_hour_std']\n",
    "    extract_feat_3 = [feat+'_kfold_week_count', feat+'_label_week_mean', \n",
    "                      feat+'_label_week_sum', feat+'_label_week_std']\n",
    "    extract_feat = extract_feat_1 + extract_feat_2 + extract_feat_3\n",
    "    \n",
    "    t1 = df.groupby(feat)['label'].agg(['count', 'mean', 'sum', 'std']).reset_index()\n",
    "    t1.columns = [feat] + extract_feat_1\n",
    "    \n",
    "    t2 = df.groupby([feat, 'hour'])['label'].agg(['count', 'mean', 'sum', 'std']).reset_index()\n",
    "    t2.columns = [feat, 'hour'] + extract_feat_2\n",
    "    \n",
    "    t3 = df.groupby([feat, 'week'])['label'].agg(['count', 'mean', 'sum', 'std']).reset_index()\n",
    "    t3.columns = [feat, 'week'] + extract_feat_3\n",
    "    \n",
    "    # 数据压缩\n",
    "    for c in range(0, 4, 2):\n",
    "        t1[extract_feat_1[c]] = ((t1[extract_feat_1[c]])*23/30).astype('int32')\n",
    "        t2[extract_feat_2[c]] = ((t2[extract_feat_2[c]])*23/30).astype('int32')\n",
    "        t3[extract_feat_3[c]] = ((t3[extract_feat_3[c]])*23/30).astype('int32')\n",
    "    for c in range(1, 4, 2):\n",
    "        t1[extract_feat_1[c]] = t1[extract_feat_1[c]].astype('float32')\n",
    "        t2[extract_feat_2[c]] = t2[extract_feat_2[c]].astype('float32')\n",
    "        t3[extract_feat_3[c]] = t3[extract_feat_3[c]].astype('float32')\n",
    "    \n",
    "    return t1, t2, t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2, l3 = single_test_feat(train[:10000], 'freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_proc = len(single_targets)\n",
    "\n",
    "def kfold_worker_2(train_df, feat):\n",
    "    try:\n",
    "        t1, t2, t3 = single_test_feat(train_df, feat)\n",
    "        logging.info('%s, feature shape: %s', feat, t1.shape)\n",
    "        \n",
    "        pickle.dump(t1, open(f'{feature_path}/single_kfold_feat/test_{feat}_t1.pkl', 'wb'))\n",
    "        pickle.dump(t2, open(f'{feature_path}/single_kfold_feat/test_{feat}_t2.pkl', 'wb'))\n",
    "        pickle.dump(t3, open(f'{feature_path}/single_kfold_feat/test_{feat}_t3.pkl', 'wb'))\n",
    "        logging.info('%s feature saved!', feat)\n",
    "        del t1, t2, t3\n",
    "        gc.collect()\n",
    "    except:\n",
    "        print(traceback.print_exct())\n",
    "\n",
    "def multi_proc_test(train_df, feat_list):\n",
    "    pool = multiprocessing.Pool(processes=n_proc)\n",
    "    for f in feat_list:\n",
    "        pool.apply_async(kfold_worker_2, (train_df, f))\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-09 14:51:38,532] INFO in <ipython-input-37-503dffd499d1>: qid, feature shape: (926203, 5)\n",
      "[2019-12-09 14:51:40,116] INFO in <ipython-input-37-503dffd499d1>: uid, feature shape: (1358213, 5)\n",
      "[2019-12-09 14:51:40,139] INFO in <ipython-input-37-503dffd499d1>: qid feature saved!\n",
      "[2019-12-09 14:51:44,223] INFO in <ipython-input-37-503dffd499d1>: uid feature saved!\n",
      "[2019-12-09 14:52:01,043] INFO in <ipython-input-37-503dffd499d1>: freq, feature shape: (5, 5)\n",
      "[2019-12-09 14:52:01,051] INFO in <ipython-input-37-503dffd499d1>: freq feature saved!\n",
      "[2019-12-09 14:52:09,769] INFO in <ipython-input-37-503dffd499d1>: score, feature shape: (724, 5)\n",
      "[2019-12-09 14:52:09,778] INFO in <ipython-input-37-503dffd499d1>: score feature saved!\n",
      "[2019-12-09 14:52:33,871] INFO in <ipython-input-37-503dffd499d1>: uf_b1, feature shape: (2, 5)\n",
      "[2019-12-09 14:52:33,877] INFO in <ipython-input-37-503dffd499d1>: uf_b1 feature saved!\n",
      "[2019-12-09 14:52:56,658] INFO in <ipython-input-37-503dffd499d1>: uf_b2, feature shape: (2, 5)\n",
      "[2019-12-09 14:52:56,664] INFO in <ipython-input-37-503dffd499d1>: uf_b2 feature saved!\n",
      "[2019-12-09 14:53:19,975] INFO in <ipython-input-37-503dffd499d1>: uf_b3, feature shape: (2, 5)\n",
      "[2019-12-09 14:53:19,986] INFO in <ipython-input-37-503dffd499d1>: uf_b3 feature saved!\n",
      "[2019-12-09 14:53:43,206] INFO in <ipython-input-37-503dffd499d1>: uf_b4, feature shape: (2, 5)\n",
      "[2019-12-09 14:53:43,214] INFO in <ipython-input-37-503dffd499d1>: uf_b4 feature saved!\n",
      "[2019-12-09 14:54:05,859] INFO in <ipython-input-37-503dffd499d1>: uf_b5, feature shape: (2, 5)\n",
      "[2019-12-09 14:54:05,864] INFO in <ipython-input-37-503dffd499d1>: uf_b5 feature saved!\n",
      "[2019-12-09 14:54:34,867] INFO in <ipython-input-37-503dffd499d1>: uf_c1, feature shape: (2250, 5)\n",
      "[2019-12-09 14:54:34,880] INFO in <ipython-input-37-503dffd499d1>: uf_c1 feature saved!\n",
      "[2019-12-09 14:54:57,190] INFO in <ipython-input-37-503dffd499d1>: uf_c2, feature shape: (240, 5)\n",
      "[2019-12-09 14:54:57,196] INFO in <ipython-input-37-503dffd499d1>: uf_c2 feature saved!\n",
      "[2019-12-09 14:55:16,516] INFO in <ipython-input-37-503dffd499d1>: uf_c3, feature shape: (399, 5)\n",
      "[2019-12-09 14:55:16,527] INFO in <ipython-input-37-503dffd499d1>: uf_c3 feature saved!\n",
      "[2019-12-09 14:55:39,454] INFO in <ipython-input-37-503dffd499d1>: uf_c4, feature shape: (1339, 5)\n",
      "[2019-12-09 14:55:39,465] INFO in <ipython-input-37-503dffd499d1>: uf_c4 feature saved!\n",
      "[2019-12-09 14:56:02,082] INFO in <ipython-input-37-503dffd499d1>: uf_c5, feature shape: (2, 5)\n",
      "[2019-12-09 14:56:02,089] INFO in <ipython-input-37-503dffd499d1>: uf_c5 feature saved!\n",
      "[2019-12-09 14:56:23,959] INFO in <ipython-input-37-503dffd499d1>: diff_iq_day, feature shape: (2778, 5)\n",
      "[2019-12-09 14:56:23,971] INFO in <ipython-input-37-503dffd499d1>: diff_iq_day feature saved!\n",
      "[2019-12-09 14:56:47,749] INFO in <ipython-input-37-503dffd499d1>: diff_iq_hour, feature shape: (34029, 5)\n",
      "[2019-12-09 14:56:47,775] INFO in <ipython-input-37-503dffd499d1>: diff_iq_hour feature saved!\n",
      "[2019-12-09 14:57:08,004] INFO in <ipython-input-37-503dffd499d1>: intersection_ft_count, feature shape: (4, 5)\n",
      "[2019-12-09 14:57:08,008] INFO in <ipython-input-37-503dffd499d1>: intersection_ft_count feature saved!\n",
      "[2019-12-09 14:57:33,151] INFO in <ipython-input-37-503dffd499d1>: intersection_it_count, feature shape: (5, 5)\n",
      "[2019-12-09 14:57:33,157] INFO in <ipython-input-37-503dffd499d1>: intersection_it_count feature saved!\n"
     ]
    }
   ],
   "source": [
    "multi_proc_test(train, single_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_merge(test_df, feat_df_list, feat):\n",
    "    extract_feat_1 = [feat+'_kfold_count', feat+'_label_mean', feat+'_label_sum', feat+'_label_std']\n",
    "    extract_feat_2 = [feat+'_kfold_hour_count', feat+'_label_hour_mean', \n",
    "                      feat+'_label_hour_sum', feat+'_label_hour_std']\n",
    "    extract_feat_3 = [feat+'_kfold_week_count', feat+'_label_week_mean', \n",
    "                      feat+'_label_week_sum', feat+'_label_week_std']\n",
    "    extract_feat = extract_feat_1 + extract_feat_2 + extract_feat_3\n",
    "    t1 = pd.merge(test, feat_df_list[0], on=[feat], how='left')\n",
    "    t1 = pd.merge(t1, feat_df_list[1], on=[feat, 'hour'], how='left')\n",
    "    t1 = pd.merge(t1, feat_df_list[2], on=[feat, 'week'], how='left')\n",
    "    for i in range(0, len(extract_feat), 2):\n",
    "        t1[extract_feat[i]] = t1[extract_feat[i]].fillna(0).astype('int32')\n",
    "    for i in range(1, len(extract_feat), 2):\n",
    "        t1[extract_feat[i]] = t1[extract_feat[i]].astype('float32')\n",
    "\n",
    "    return t1[extract_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = []\n",
    "l2.append(pickle.load(open(f'{feature_path}/single_kfold_feat/test_freq_t1.pkl', 'rb')))\n",
    "l2.append(pickle.load(open(f'{feature_path}/single_kfold_feat/test_freq_t2.pkl', 'rb')))\n",
    "l2.append(pickle.load(open(f'{feature_path}/single_kfold_feat/test_freq_t3.pkl', 'rb')))\n",
    "t1 = my_merge(test[:60], l2, 'freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_kfold_count</th>\n",
       "      <th>freq_label_mean</th>\n",
       "      <th>freq_label_sum</th>\n",
       "      <th>freq_label_std</th>\n",
       "      <th>freq_kfold_hour_count</th>\n",
       "      <th>freq_label_hour_mean</th>\n",
       "      <th>freq_label_hour_sum</th>\n",
       "      <th>freq_label_hour_std</th>\n",
       "      <th>freq_kfold_week_count</th>\n",
       "      <th>freq_label_week_mean</th>\n",
       "      <th>freq_label_week_sum</th>\n",
       "      <th>freq_label_week_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2941221</td>\n",
       "      <td>0.168021</td>\n",
       "      <td>494187</td>\n",
       "      <td>0.373885</td>\n",
       "      <td>188374</td>\n",
       "      <td>0.188355</td>\n",
       "      <td>35481</td>\n",
       "      <td>0.390996</td>\n",
       "      <td>379473</td>\n",
       "      <td>0.174408</td>\n",
       "      <td>66183</td>\n",
       "      <td>0.379461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3147340</td>\n",
       "      <td>0.159146</td>\n",
       "      <td>500885</td>\n",
       "      <td>0.365812</td>\n",
       "      <td>121117</td>\n",
       "      <td>0.128796</td>\n",
       "      <td>15599</td>\n",
       "      <td>0.334975</td>\n",
       "      <td>423071</td>\n",
       "      <td>0.151811</td>\n",
       "      <td>64226</td>\n",
       "      <td>0.358838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2941221</td>\n",
       "      <td>0.168021</td>\n",
       "      <td>494187</td>\n",
       "      <td>0.373885</td>\n",
       "      <td>179718</td>\n",
       "      <td>0.160438</td>\n",
       "      <td>28833</td>\n",
       "      <td>0.367012</td>\n",
       "      <td>473041</td>\n",
       "      <td>0.166582</td>\n",
       "      <td>78800</td>\n",
       "      <td>0.372603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115848</td>\n",
       "      <td>0.330607</td>\n",
       "      <td>38300</td>\n",
       "      <td>0.470433</td>\n",
       "      <td>563</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>276</td>\n",
       "      <td>0.500236</td>\n",
       "      <td>17831</td>\n",
       "      <td>0.313685</td>\n",
       "      <td>5593</td>\n",
       "      <td>0.464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2941221</td>\n",
       "      <td>0.168021</td>\n",
       "      <td>494187</td>\n",
       "      <td>0.373885</td>\n",
       "      <td>200781</td>\n",
       "      <td>0.134217</td>\n",
       "      <td>26948</td>\n",
       "      <td>0.340886</td>\n",
       "      <td>406345</td>\n",
       "      <td>0.157120</td>\n",
       "      <td>63844</td>\n",
       "      <td>0.363914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141678</th>\n",
       "      <td>2941221</td>\n",
       "      <td>0.168021</td>\n",
       "      <td>494187</td>\n",
       "      <td>0.373885</td>\n",
       "      <td>119087</td>\n",
       "      <td>0.165896</td>\n",
       "      <td>19756</td>\n",
       "      <td>0.371989</td>\n",
       "      <td>413991</td>\n",
       "      <td>0.167266</td>\n",
       "      <td>69246</td>\n",
       "      <td>0.373214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141679</th>\n",
       "      <td>856464</td>\n",
       "      <td>0.228575</td>\n",
       "      <td>195766</td>\n",
       "      <td>0.419915</td>\n",
       "      <td>41938</td>\n",
       "      <td>0.201400</td>\n",
       "      <td>8446</td>\n",
       "      <td>0.401050</td>\n",
       "      <td>125974</td>\n",
       "      <td>0.219275</td>\n",
       "      <td>27623</td>\n",
       "      <td>0.413757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141680</th>\n",
       "      <td>3147340</td>\n",
       "      <td>0.159146</td>\n",
       "      <td>500885</td>\n",
       "      <td>0.365812</td>\n",
       "      <td>167377</td>\n",
       "      <td>0.147436</td>\n",
       "      <td>24677</td>\n",
       "      <td>0.354541</td>\n",
       "      <td>434280</td>\n",
       "      <td>0.153933</td>\n",
       "      <td>66850</td>\n",
       "      <td>0.360885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141681</th>\n",
       "      <td>2941221</td>\n",
       "      <td>0.168021</td>\n",
       "      <td>494187</td>\n",
       "      <td>0.373885</td>\n",
       "      <td>279252</td>\n",
       "      <td>0.169203</td>\n",
       "      <td>47250</td>\n",
       "      <td>0.374932</td>\n",
       "      <td>408130</td>\n",
       "      <td>0.162868</td>\n",
       "      <td>66471</td>\n",
       "      <td>0.369246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141682</th>\n",
       "      <td>3147340</td>\n",
       "      <td>0.159146</td>\n",
       "      <td>500885</td>\n",
       "      <td>0.365812</td>\n",
       "      <td>232505</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>40758</td>\n",
       "      <td>0.380224</td>\n",
       "      <td>498536</td>\n",
       "      <td>0.158360</td>\n",
       "      <td>78948</td>\n",
       "      <td>0.365079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1141683 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         freq_kfold_count  freq_label_mean  freq_label_sum  freq_label_std  \\\n",
       "0                 2941221         0.168021          494187        0.373885   \n",
       "1                 3147340         0.159146          500885        0.365812   \n",
       "2                 2941221         0.168021          494187        0.373885   \n",
       "3                  115848         0.330607           38300        0.470433   \n",
       "4                 2941221         0.168021          494187        0.373885   \n",
       "...                   ...              ...             ...             ...   \n",
       "1141678           2941221         0.168021          494187        0.373885   \n",
       "1141679            856464         0.228575          195766        0.419915   \n",
       "1141680           3147340         0.159146          500885        0.365812   \n",
       "1141681           2941221         0.168021          494187        0.373885   \n",
       "1141682           3147340         0.159146          500885        0.365812   \n",
       "\n",
       "         freq_kfold_hour_count  freq_label_hour_mean  freq_label_hour_sum  \\\n",
       "0                       188374              0.188355                35481   \n",
       "1                       121117              0.128796                15599   \n",
       "2                       179718              0.160438                28833   \n",
       "3                          563              0.489796                  276   \n",
       "4                       200781              0.134217                26948   \n",
       "...                        ...                   ...                  ...   \n",
       "1141678                 119087              0.165896                19756   \n",
       "1141679                  41938              0.201400                 8446   \n",
       "1141680                 167377              0.147436                24677   \n",
       "1141681                 279252              0.169203                47250   \n",
       "1141682                 232505              0.175300                40758   \n",
       "\n",
       "         freq_label_hour_std  freq_kfold_week_count  freq_label_week_mean  \\\n",
       "0                   0.390996                 379473              0.174408   \n",
       "1                   0.334975                 423071              0.151811   \n",
       "2                   0.367012                 473041              0.166582   \n",
       "3                   0.500236                  17831              0.313685   \n",
       "4                   0.340886                 406345              0.157120   \n",
       "...                      ...                    ...                   ...   \n",
       "1141678             0.371989                 413991              0.167266   \n",
       "1141679             0.401050                 125974              0.219275   \n",
       "1141680             0.354541                 434280              0.153933   \n",
       "1141681             0.374932                 408130              0.162868   \n",
       "1141682             0.380224                 498536              0.158360   \n",
       "\n",
       "         freq_label_week_sum  freq_label_week_std  \n",
       "0                      66183             0.379461  \n",
       "1                      64226             0.358838  \n",
       "2                      78800             0.372603  \n",
       "3                       5593             0.464000  \n",
       "4                      63844             0.363914  \n",
       "...                      ...                  ...  \n",
       "1141678                69246             0.373214  \n",
       "1141679                27623             0.413757  \n",
       "1141680                66850             0.360885  \n",
       "1141681                66471             0.369246  \n",
       "1141682                78948             0.365079  \n",
       "\n",
       "[1141683 rows x 12 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_worker(test_df, feat):\n",
    "    l1 = []\n",
    "    l1.append(pickle.load(open(f'{feature_path}/single_kfold_feat/test_{feat}_t1.pkl', 'rb')))\n",
    "    l1.append(pickle.load(open(f'{feature_path}/single_kfold_feat/test_{feat}_t2.pkl', 'rb')))\n",
    "    l1.append(pickle.load(open(f'{feature_path}/single_kfold_feat/test_{feat}_t3.pkl', 'rb')))\n",
    "    t1 = my_merge(test_df, l1, feat)\n",
    "    logging.info('merged %s feature, shape: %s', feat, t1.shape)\n",
    "    pickle.dump(t1, open(f'{feature_path}/single_kfold_feat/test_{feat}_merged.pkl', 'wb'))\n",
    "\n",
    "def multi_proc_merge(test_df, feat_list):\n",
    "    pool = multiprocessing.Pool(processes=n_proc)\n",
    "    for f in feat_list:\n",
    "        pool.apply_async(merge_worker, (test_df, f))\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-09 17:04:05,466] INFO in <ipython-input-46-ac86bc0b42a2>: merged freq feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:08,366] INFO in <ipython-input-46-ac86bc0b42a2>: merged score feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:10,151] INFO in <ipython-input-46-ac86bc0b42a2>: merged qid feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:11,779] INFO in <ipython-input-46-ac86bc0b42a2>: merged uf_b1 feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:12,513] INFO in <ipython-input-46-ac86bc0b42a2>: merged uf_b2 feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:14,657] INFO in <ipython-input-46-ac86bc0b42a2>: merged uid feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:16,954] INFO in <ipython-input-46-ac86bc0b42a2>: merged uf_b3 feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:19,655] INFO in <ipython-input-46-ac86bc0b42a2>: merged uf_b4 feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:21,284] INFO in <ipython-input-46-ac86bc0b42a2>: merged uf_b5 feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:24,676] INFO in <ipython-input-46-ac86bc0b42a2>: merged uf_c1 feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:27,254] INFO in <ipython-input-46-ac86bc0b42a2>: merged uf_c2 feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:30,094] INFO in <ipython-input-46-ac86bc0b42a2>: merged uf_c3 feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:32,695] INFO in <ipython-input-46-ac86bc0b42a2>: merged uf_c4 feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:35,067] INFO in <ipython-input-46-ac86bc0b42a2>: merged uf_c5 feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:37,389] INFO in <ipython-input-46-ac86bc0b42a2>: merged diff_iq_day feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:40,144] INFO in <ipython-input-46-ac86bc0b42a2>: merged diff_iq_hour feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:42,302] INFO in <ipython-input-46-ac86bc0b42a2>: merged intersection_ft_count feature, shape: (1141683, 12)\n",
      "[2019-12-09 17:04:44,647] INFO in <ipython-input-46-ac86bc0b42a2>: merged intersection_it_count feature, shape: (1141683, 12)\n"
     ]
    }
   ],
   "source": [
    "# single_targets = ['uid', 'qid', 'freq', 'score', \n",
    "#                   'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "#                   'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5',\n",
    "#                   'diff_iq_day', 'diff_iq_hour', \n",
    "#                   'intersection_ft_count', 'intersection_it_count']\n",
    "multi_proc_merge(test, single_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
