{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import logging\n",
    "import multiprocessing\n",
    "import traceback\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fmt = \"[%(asctime)s] %(levelname)s in %(module)s: %(message)s\"\n",
    "logging.basicConfig(format=log_fmt, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data'\n",
    "feature_path = './feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-10 12:58:54,772] INFO in <ipython-input-4-af34e33feb4f>: invite (9489162, 4)\n",
      "[2019-12-10 12:58:57,232] INFO in <ipython-input-4-af34e33feb4f>: test (1141683, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(f'{base_path}/invite_info_0926.txt', sep='\\t', header=None)\n",
    "train.columns = ['qid', 'uid', 'dt', 'label']\n",
    "logging.info(\"invite %s\", train.shape)\n",
    "\n",
    "test = pd.read_csv(f'{base_path}/invite_info_evaluate_0926.txt', sep='\\t', header=None)\n",
    "test.columns = ['qid', 'uid', 'dt']\n",
    "logging.info(\"test %s\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_day(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[0][1:]))\n",
    "\n",
    "\n",
    "def extract_hour(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[1][1:]))\n",
    "\n",
    "train['day'] = extract_day(train['dt'])\n",
    "train['week'] = train['day'] % 7\n",
    "train['hour'] = extract_hour(train['dt'])\n",
    "\n",
    "test['day'] = extract_day(test['dt'])\n",
    "test['week'] = test['day'] % 7\n",
    "test['hour'] = extract_hour(test['dt'])\n",
    "\n",
    "del train['dt'], test['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-10 13:00:20,914] INFO in <ipython-input-6-cbb4bab8955e>: user (1931654, 14)\n"
     ]
    }
   ],
   "source": [
    "# 加载用户\n",
    "user = pd.read_csv(f'{base_path}/member_info_0926.txt', header=None, sep='\\t')\n",
    "user.columns = ['uid', 'gender', 'freq', 'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "                'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5',  'score', 'follow_topic', 'inter_topic']\n",
    "\n",
    "del user['follow_topic'], user['inter_topic']\n",
    "logging.info(\"user %s\", user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge user\n",
    "train = pd.merge(train, user, on='uid', how='left')\n",
    "test = pd.merge(test, user, on='uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-10 13:01:40,216] INFO in <ipython-input-8-3053b1f3a755>: ques (1829900, 2)\n"
     ]
    }
   ],
   "source": [
    "# 加载问题\n",
    "ques = pd.read_csv(f'{base_path}/question_info_0926.txt', header=None, sep='\\t')\n",
    "ques.columns = ['qid', 'q_dt', 'title_t1', 'title_t2', 'desc_t1', 'desc_t2', 'topic']\n",
    "del ques['title_t1'], ques['title_t2'], ques['desc_t1'], ques['desc_t2'], ques['topic']\n",
    "logging.info(\"ques %s\", ques.shape)\n",
    "\n",
    "ques['q_day'] = extract_day(ques['q_dt'])\n",
    "ques['q_hour'] = extract_hour(ques['q_dt'])\n",
    "ques['q_week'] = ques['q_day'] % 7\n",
    "\n",
    "del ques['q_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ques\n",
    "train = pd.merge(train, ques, on='qid', how='left')\n",
    "test = pd.merge(test, ques, on='qid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['diff_iq_day'] = train['day'] - train['q_day']\n",
    "train['diff_iq_hour'] = train['diff_iq_day'] * 24 + (train['hour'] - train['q_hour'])\n",
    "\n",
    "test['diff_iq_day'] = test['day'] - test['q_day']\n",
    "test['diff_iq_hour'] = test['diff_iq_day'] * 24 + (test['hour'] - test['q_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_iq_day_map(x):\n",
    "    if x>=31:\n",
    "        return 31\n",
    "    if x<0:\n",
    "        return 0\n",
    "    return x\n",
    "\n",
    "train['diff_iq_day'] = train['diff_iq_day'].apply(diff_iq_day_map)\n",
    "test['diff_iq_day'] = test['diff_iq_day'].apply(diff_iq_day_map)\n",
    "\n",
    "def diff_iq_hour_map(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    if x>200:\n",
    "        return 40\n",
    "    return x // 5\n",
    "train['diff_iq_hour'] = train['diff_iq_hour'].apply(diff_iq_hour_map)\n",
    "test['diff_iq_day'] = test['diff_iq_day'].apply(diff_iq_day_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_map(x):\n",
    "    if x<=280:\n",
    "        return -1\n",
    "    if x<=300:\n",
    "        return 0\n",
    "    if 300<x<=350:\n",
    "        return 1\n",
    "    if 350<x<=400:\n",
    "        return 2\n",
    "    if 400<x<=500:\n",
    "        return 3\n",
    "    if 500<x<=600:\n",
    "        return 4\n",
    "    if 600<x<=700:\n",
    "        return 5\n",
    "    if 700<x<=800:\n",
    "        return 6\n",
    "    return 7\n",
    "\n",
    "train['score'] = train['score'].apply(score_map)\n",
    "test['score'] = test['score'].apply(score_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 invete feature 2: intersection_ft_count, intersection_it_count\n",
    "t1 = pd.read_csv(f'{feature_path}/train_invite_feature_2.txt', sep='\\t', \n",
    "                 usecols=['intersection_ft_count', 'intersection_it_count'])\n",
    "train = pd.concat([train, t1], axis=1)\n",
    "\n",
    "t1 = pd.read_csv(f'{feature_path}/test_invite_feature_2.txt', sep='\\t', \n",
    "                 usecols=['intersection_ft_count', 'intersection_it_count'])\n",
    "test = pd.concat([test, t1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分 intersection_ft_count\n",
    "def to_bin_1(x):\n",
    "    if x>=3:\n",
    "        return 3\n",
    "    return x\n",
    "\n",
    "train['intersection_ft_count'] = train['intersection_ft_count'].apply(to_bin_1)\n",
    "test['intersection_ft_count'] = test['intersection_ft_count'].apply(to_bin_1)\n",
    "\n",
    "# 划分 intersection_it_count\n",
    "def to_bin_2(x):\n",
    "    if x>=4:\n",
    "        return 4\n",
    "    return x\n",
    "\n",
    "train['intersection_it_count'] = train['intersection_it_count'].apply(to_bin_2)\n",
    "test['intersection_it_count'] = test['intersection_it_count'].apply(to_bin_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4折统计\n",
    "def fold_fn(x):\n",
    "    if 3838<=x<=3846:\n",
    "        return 0\n",
    "    if 3847<=x<=3853:\n",
    "        return 1\n",
    "    if 3854<=x<=3860:\n",
    "        return 2\n",
    "    if 3861<=x<=3867:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fold'] = train['day'].apply(fold_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 一阶\n",
    "def single_train_feat(df_, feat):\n",
    "    df = df_.copy()\n",
    "    extract_feat_1 = [feat+'_kfold_count', feat+'_label_mean', feat+'_label_sum', feat+'_label_std']\n",
    "#     extract_feat_2 = [feat+'_kfold_hour_count', feat+'_label_hour_mean', \n",
    "#                       feat+'_label_hour_sum', feat+'_label_hour_std']\n",
    "#     extract_feat_3 = [feat+'_kfold_week_count', feat+'_label_week_mean', \n",
    "#                       feat+'_label_week_sum', feat+'_label_week_std']\n",
    "#     extract_feat = extract_feat_1 + extract_feat_2 + extract_feat_3\n",
    "    extract_feat = extract_feat_1\n",
    "    for c in extract_feat:\n",
    "        df[c] = -10000\n",
    "    for i in range(4):\n",
    "        t1 = df[df['fold']!=i].groupby(feat)['label'].agg(['count', 'mean', 'sum', 'std']).reset_index()\n",
    "#         t1.loc[t1['count']<5, ['mean', 'std']] = np.nan\n",
    "        t1.columns = [feat] + extract_feat_1\n",
    "        df.loc[df['fold']==i, extract_feat_1] = pd.merge(df.loc[df['fold']==i, feat], t1, on=feat, \n",
    "                                                         how='left')[extract_feat_1].values\n",
    "        # 某小时\n",
    "#         t1 = df[df['fold']!=i].groupby([feat, 'hour'])['label'].agg(['count', \n",
    "#                                                                      'mean', 'sum', 'std']).reset_index()\n",
    "#         t1.loc[t1['count']<5, ['mean', 'std']] = np.nan\n",
    "#         t1.columns = [feat, 'hour'] + extract_feat_2\n",
    "#         df.loc[df['fold']==i, extract_feat_2] = pd.merge(df.loc[df['fold']==i, [feat, 'hour']], \n",
    "#                                                          t1, on=[feat, 'hour'], \n",
    "#                                                          how='left')[extract_feat_2].values\n",
    "#         # 一周的某一天\n",
    "#         t1 = df[df['fold']!=i].groupby([feat, 'week'])['label'].agg(['count', \n",
    "#                                                                      'mean', 'sum', 'std']).reset_index()\n",
    "#         t1.loc[t1['count']<5, ['mean', 'std']] = np.nan\n",
    "#         t1.columns = [feat, 'week'] + extract_feat_3\n",
    "#         df.loc[df['fold']==i, extract_feat_3] = pd.merge(df.loc[df['fold']==i, [feat, 'week']], \n",
    "#                                                          t1, on=[feat, 'week'], \n",
    "#                                                          how='left')[extract_feat_3].values\n",
    "    # 数据压缩\n",
    "    for c in range(0, len(extract_feat), 2):\n",
    "        df[extract_feat[c]] = df[extract_feat[c]].fillna(0).astype('int32')\n",
    "    for c in range(1, len(extract_feat), 2):\n",
    "        df[extract_feat[c]] = df[extract_feat[c]].astype('float32')\n",
    "\n",
    "    return df[extract_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_targets = ['uid', 'qid', 'freq', 'score', \n",
    "                  'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "                  'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5',\n",
    "                  'diff_iq_day', 'diff_iq_hour', \n",
    "                  'intersection_ft_count', 'intersection_it_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_proc = len(single_targets)\n",
    "\n",
    "def kfold_worker_1(df, feat):\n",
    "    try:\n",
    "        t1 = single_train_feat(df, feat)\n",
    "        logging.info('%s, feature shape: %s', feat, t1.shape)\n",
    "        \n",
    "        pickle.dump(t1, open(f'{feature_path}/single_kfold_feat/train_{feat}.pkl', 'wb'))\n",
    "        logging.info('%s feature saved!', feat)\n",
    "        del t1\n",
    "        gc.collect()\n",
    "    except:\n",
    "        print(traceback.print_exct())\n",
    "\n",
    "def multi_proc_train(df, feat_list):\n",
    "    pool = multiprocessing.Pool(processes=n_proc)\n",
    "    for f in feat_list:\n",
    "        pool.apply_async(kfold_worker_1, (df, f))\n",
    "    pool.close()\n",
    "    pool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-10 13:09:00,614] INFO in <ipython-input-19-de9045d32bd3>: uid, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:09:01,376] INFO in <ipython-input-19-de9045d32bd3>: uid feature saved!\n",
      "[2019-12-10 13:09:14,784] INFO in <ipython-input-19-de9045d32bd3>: score, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:09:15,489] INFO in <ipython-input-19-de9045d32bd3>: score feature saved!\n",
      "[2019-12-10 13:09:20,687] INFO in <ipython-input-19-de9045d32bd3>: qid, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:09:21,827] INFO in <ipython-input-19-de9045d32bd3>: qid feature saved!\n",
      "[2019-12-10 13:09:22,144] INFO in <ipython-input-19-de9045d32bd3>: freq, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:09:22,726] INFO in <ipython-input-19-de9045d32bd3>: freq feature saved!\n",
      "[2019-12-10 13:09:58,619] INFO in <ipython-input-19-de9045d32bd3>: uf_b1, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:09:59,341] INFO in <ipython-input-19-de9045d32bd3>: uf_b1 feature saved!\n",
      "[2019-12-10 13:10:51,298] INFO in <ipython-input-19-de9045d32bd3>: uf_b2, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:10:51,923] INFO in <ipython-input-19-de9045d32bd3>: uf_b2 feature saved!\n",
      "[2019-12-10 13:11:33,232] INFO in <ipython-input-19-de9045d32bd3>: uf_b3, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:11:33,905] INFO in <ipython-input-19-de9045d32bd3>: uf_b3 feature saved!\n",
      "[2019-12-10 13:12:07,516] INFO in <ipython-input-19-de9045d32bd3>: uf_b4, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:12:08,306] INFO in <ipython-input-19-de9045d32bd3>: uf_b4 feature saved!\n",
      "[2019-12-10 13:12:40,490] INFO in <ipython-input-19-de9045d32bd3>: uf_b5, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:12:41,168] INFO in <ipython-input-19-de9045d32bd3>: uf_b5 feature saved!\n",
      "[2019-12-10 13:13:19,601] INFO in <ipython-input-19-de9045d32bd3>: uf_c1, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:13:20,257] INFO in <ipython-input-19-de9045d32bd3>: uf_c1 feature saved!\n",
      "[2019-12-10 13:14:05,054] INFO in <ipython-input-19-de9045d32bd3>: uf_c2, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:14:05,732] INFO in <ipython-input-19-de9045d32bd3>: uf_c2 feature saved!\n",
      "[2019-12-10 13:14:49,473] INFO in <ipython-input-19-de9045d32bd3>: uf_c3, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:14:50,144] INFO in <ipython-input-19-de9045d32bd3>: uf_c3 feature saved!\n",
      "[2019-12-10 13:15:33,638] INFO in <ipython-input-19-de9045d32bd3>: uf_c4, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:15:34,264] INFO in <ipython-input-19-de9045d32bd3>: uf_c4 feature saved!\n",
      "[2019-12-10 13:16:05,650] INFO in <ipython-input-19-de9045d32bd3>: uf_c5, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:16:06,452] INFO in <ipython-input-19-de9045d32bd3>: uf_c5 feature saved!\n",
      "[2019-12-10 13:16:42,352] INFO in <ipython-input-19-de9045d32bd3>: diff_iq_day, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:16:43,040] INFO in <ipython-input-19-de9045d32bd3>: diff_iq_day feature saved!\n",
      "[2019-12-10 13:18:22,705] INFO in <ipython-input-19-de9045d32bd3>: diff_iq_hour, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:18:23,822] INFO in <ipython-input-19-de9045d32bd3>: diff_iq_hour feature saved!\n",
      "[2019-12-10 13:18:49,879] INFO in <ipython-input-19-de9045d32bd3>: intersection_ft_count, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:18:50,593] INFO in <ipython-input-19-de9045d32bd3>: intersection_ft_count feature saved!\n",
      "[2019-12-10 13:19:11,889] INFO in <ipython-input-19-de9045d32bd3>: intersection_it_count, feature shape: (9489162, 4)\n",
      "[2019-12-10 13:19:13,075] INFO in <ipython-input-19-de9045d32bd3>: intersection_it_count feature saved!\n"
     ]
    }
   ],
   "source": [
    "multi_proc_train(train, single_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 一阶\n",
    "def single_test_feat(df, feat):\n",
    "    extract_feat_1 = [feat+'_kfold_count', feat+'_label_mean', feat+'_label_sum', feat+'_label_std']\n",
    "#     extract_feat_2 = [feat+'_kfold_hour_count', feat+'_label_hour_mean', \n",
    "#                       feat+'_label_hour_sum', feat+'_label_hour_std']\n",
    "#     extract_feat_3 = [feat+'_kfold_week_count', feat+'_label_week_mean', \n",
    "#                       feat+'_label_week_sum', feat+'_label_week_std']\n",
    "#     extract_feat = extract_feat_1 + extract_feat_2 + extract_feat_3\n",
    "    extract_feat = extract_feat_1\n",
    "    \n",
    "    t1 = df.groupby(feat)['label'].agg(['count', 'mean', 'sum', 'std']).reset_index()\n",
    "#     t1.loc[t1['count']<5, ['mean', 'std']] = np.nan\n",
    "    t1.columns = [feat] + extract_feat_1\n",
    "#     t2 = df.groupby([feat, 'hour'])['label'].agg(['count', 'mean', 'sum', 'std']).reset_index()\n",
    "#     t2.loc[t2['count']<5, ['mean', 'std']] = np.nan\n",
    "#     t2.columns = [feat, 'hour'] + extract_feat_2\n",
    "    \n",
    "#     t3 = df.groupby([feat, 'week'])['label'].agg(['count', 'mean', 'sum', 'std']).reset_index()\n",
    "#     t3.loc[t3['count']<5, ['mean', 'std']] = np.nan\n",
    "#     t3.columns = [feat, 'week'] + extract_feat_3\n",
    "    \n",
    "    # 数据压缩\n",
    "    for c in range(0, 4, 2):\n",
    "        t1[extract_feat_1[c]] = t1[extract_feat_1[c]].fillna(0).astype('int32')\n",
    "#         t2[extract_feat_2[c]] = ((t2[extract_feat_2[c]])*23/30).astype('int32')\n",
    "#         t3[extract_feat_3[c]] = ((t3[extract_feat_3[c]])*23/30).astype('int32')\n",
    "    for c in range(1, 4, 2):\n",
    "        t1[extract_feat_1[c]] = t1[extract_feat_1[c]].astype('float32')\n",
    "#         t2[extract_feat_2[c]] = t2[extract_feat_2[c]].astype('float32')\n",
    "#         t3[extract_feat_3[c]] = t3[extract_feat_3[c]].astype('float32')\n",
    "    \n",
    "#     return t1, t2, t3\n",
    "    return t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_proc = len(single_targets)\n",
    "\n",
    "def kfold_worker_2(train_df, feat):\n",
    "    try:\n",
    "#         t1, t2, t3 = single_test_feat(train_df, feat)\n",
    "        t1 = single_test_feat(train_df, feat)\n",
    "        logging.info('%s, feature shape: %s', feat, t1.shape)\n",
    "        \n",
    "        pickle.dump(t1, open(f'{feature_path}/single_kfold_feat/test_{feat}_t1.pkl', 'wb'))\n",
    "#         pickle.dump(t2, open(f'{feature_path}/single_kfold_feat/test_{feat}_t2.pkl', 'wb'))\n",
    "#         pickle.dump(t3, open(f'{feature_path}/single_kfold_feat/test_{feat}_t3.pkl', 'wb'))\n",
    "        logging.info('%s feature saved!', feat)\n",
    "#         del t1, t2, t3\n",
    "        del t1\n",
    "        gc.collect()\n",
    "    except:\n",
    "        print(traceback.print_exct())\n",
    "\n",
    "def multi_proc_test(train_df, feat_list):\n",
    "    pool = multiprocessing.Pool(processes=n_proc)\n",
    "    for f in feat_list:\n",
    "        pool.apply_async(kfold_worker_2, (train_df, f))\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-10 13:20:52,316] INFO in <ipython-input-22-855a6c763eb1>: uid, feature shape: (1358213, 5)\n",
      "[2019-12-10 13:20:53,026] INFO in <ipython-input-22-855a6c763eb1>: uid feature saved!\n",
      "[2019-12-10 13:21:35,266] INFO in <ipython-input-22-855a6c763eb1>: qid, feature shape: (926203, 5)\n",
      "[2019-12-10 13:21:36,126] INFO in <ipython-input-22-855a6c763eb1>: qid feature saved!\n",
      "[2019-12-10 13:22:00,438] INFO in <ipython-input-22-855a6c763eb1>: freq, feature shape: (5, 5)\n",
      "[2019-12-10 13:22:00,453] INFO in <ipython-input-22-855a6c763eb1>: freq feature saved!\n",
      "[2019-12-10 13:22:19,385] INFO in <ipython-input-22-855a6c763eb1>: score, feature shape: (9, 5)\n",
      "[2019-12-10 13:22:19,390] INFO in <ipython-input-22-855a6c763eb1>: score feature saved!\n",
      "[2019-12-10 13:23:02,804] INFO in <ipython-input-22-855a6c763eb1>: uf_b1, feature shape: (2, 5)\n",
      "[2019-12-10 13:23:02,822] INFO in <ipython-input-22-855a6c763eb1>: uf_b1 feature saved!\n",
      "[2019-12-10 13:23:52,012] INFO in <ipython-input-22-855a6c763eb1>: uf_b2, feature shape: (2, 5)\n",
      "[2019-12-10 13:23:52,022] INFO in <ipython-input-22-855a6c763eb1>: uf_b2 feature saved!\n",
      "[2019-12-10 13:24:28,615] INFO in <ipython-input-22-855a6c763eb1>: uf_b3, feature shape: (2, 5)\n",
      "[2019-12-10 13:24:28,626] INFO in <ipython-input-22-855a6c763eb1>: uf_b3 feature saved!\n",
      "[2019-12-10 13:25:07,272] INFO in <ipython-input-22-855a6c763eb1>: uf_b4, feature shape: (2, 5)\n",
      "[2019-12-10 13:25:07,284] INFO in <ipython-input-22-855a6c763eb1>: uf_b4 feature saved!\n",
      "[2019-12-10 13:25:50,558] INFO in <ipython-input-22-855a6c763eb1>: uf_b5, feature shape: (2, 5)\n",
      "[2019-12-10 13:25:50,570] INFO in <ipython-input-22-855a6c763eb1>: uf_b5 feature saved!\n",
      "[2019-12-10 13:26:43,794] INFO in <ipython-input-22-855a6c763eb1>: uf_c1, feature shape: (2250, 5)\n",
      "[2019-12-10 13:26:43,810] INFO in <ipython-input-22-855a6c763eb1>: uf_c1 feature saved!\n",
      "[2019-12-10 13:27:10,968] INFO in <ipython-input-22-855a6c763eb1>: uf_c2, feature shape: (240, 5)\n",
      "[2019-12-10 13:27:10,976] INFO in <ipython-input-22-855a6c763eb1>: uf_c2 feature saved!\n",
      "[2019-12-10 13:27:54,264] INFO in <ipython-input-22-855a6c763eb1>: uf_c3, feature shape: (399, 5)\n",
      "[2019-12-10 13:27:54,277] INFO in <ipython-input-22-855a6c763eb1>: uf_c3 feature saved!\n",
      "[2019-12-10 13:28:38,149] INFO in <ipython-input-22-855a6c763eb1>: uf_c4, feature shape: (1339, 5)\n",
      "[2019-12-10 13:28:38,159] INFO in <ipython-input-22-855a6c763eb1>: uf_c4 feature saved!\n",
      "[2019-12-10 13:29:27,438] INFO in <ipython-input-22-855a6c763eb1>: uf_c5, feature shape: (2, 5)\n",
      "[2019-12-10 13:29:27,447] INFO in <ipython-input-22-855a6c763eb1>: uf_c5 feature saved!\n",
      "[2019-12-10 13:29:51,590] INFO in <ipython-input-22-855a6c763eb1>: diff_iq_day, feature shape: (32, 5)\n",
      "[2019-12-10 13:29:51,597] INFO in <ipython-input-22-855a6c763eb1>: diff_iq_day feature saved!\n",
      "[2019-12-10 13:30:44,795] INFO in <ipython-input-22-855a6c763eb1>: diff_iq_hour, feature shape: (41, 5)\n",
      "[2019-12-10 13:30:44,818] INFO in <ipython-input-22-855a6c763eb1>: diff_iq_hour feature saved!\n",
      "[2019-12-10 13:31:34,366] INFO in <ipython-input-22-855a6c763eb1>: intersection_ft_count, feature shape: (4, 5)\n",
      "[2019-12-10 13:31:34,384] INFO in <ipython-input-22-855a6c763eb1>: intersection_ft_count feature saved!\n",
      "[2019-12-10 13:32:11,547] INFO in <ipython-input-22-855a6c763eb1>: intersection_it_count, feature shape: (5, 5)\n",
      "[2019-12-10 13:32:11,558] INFO in <ipython-input-22-855a6c763eb1>: intersection_it_count feature saved!\n"
     ]
    }
   ],
   "source": [
    "multi_proc_test(train, single_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_merge(test_df, feat_df_list, feat):\n",
    "    extract_feat_1 = [feat+'_kfold_count', feat+'_label_mean', feat+'_label_sum', feat+'_label_std']\n",
    "#     extract_feat_2 = [feat+'_kfold_hour_count', feat+'_label_hour_mean', \n",
    "#                       feat+'_label_hour_sum', feat+'_label_hour_std']\n",
    "#     extract_feat_3 = [feat+'_kfold_week_count', feat+'_label_week_mean', \n",
    "#                       feat+'_label_week_sum', feat+'_label_week_std']\n",
    "#     extract_feat = extract_feat_1 + extract_feat_2 + extract_feat_3\n",
    "    extract_feat = extract_feat_1 \n",
    "    t1 = pd.merge(test, feat_df_list[0], on=[feat], how='left')\n",
    "#     t1 = pd.merge(t1, feat_df_list[1], on=[feat, 'hour'], how='left')\n",
    "#     t1 = pd.merge(t1, feat_df_list[2], on=[feat, 'week'], how='left')\n",
    "    for i in range(0, len(extract_feat), 2):\n",
    "        t1[extract_feat[i]] = t1[extract_feat[i]].fillna(0).astype('int32')\n",
    "    for i in range(1, len(extract_feat), 2):\n",
    "        t1[extract_feat[i]] = t1[extract_feat[i]].astype('float32')\n",
    "\n",
    "    return t1[extract_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_worker(test_df, feat):\n",
    "    l1 = []\n",
    "    l1.append(pickle.load(open(f'{feature_path}/single_kfold_feat/test_{feat}_t1.pkl', 'rb')))\n",
    "#     l1.append(pickle.load(open(f'{feature_path}/single_kfold_feat/test_{feat}_t2.pkl', 'rb')))\n",
    "#     l1.append(pickle.load(open(f'{feature_path}/single_kfold_feat/test_{feat}_t3.pkl', 'rb')))\n",
    "    t1 = my_merge(test_df, l1, feat)\n",
    "    logging.info('merged %s feature, shape: %s', feat, t1.shape)\n",
    "    pickle.dump(t1, open(f'{feature_path}/single_kfold_feat/test_{feat}_merged.pkl', 'wb'))\n",
    "\n",
    "def multi_proc_merge(test_df, feat_list):\n",
    "    pool = multiprocessing.Pool(processes=n_proc)\n",
    "    for f in feat_list:\n",
    "        pool.apply_async(merge_worker, (test_df, f))\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-10 13:32:30,123] INFO in <ipython-input-25-98d5ab40bfd1>: merged qid feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:32:30,666] INFO in <ipython-input-25-98d5ab40bfd1>: merged uid feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:32:36,823] INFO in <ipython-input-25-98d5ab40bfd1>: merged freq feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:32:38,163] INFO in <ipython-input-25-98d5ab40bfd1>: merged score feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:32:44,428] INFO in <ipython-input-25-98d5ab40bfd1>: merged uf_b1 feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:32:46,263] INFO in <ipython-input-25-98d5ab40bfd1>: merged uf_b2 feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:32:50,002] INFO in <ipython-input-25-98d5ab40bfd1>: merged uf_b3 feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:32:53,100] INFO in <ipython-input-25-98d5ab40bfd1>: merged uf_b4 feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:32:58,020] INFO in <ipython-input-25-98d5ab40bfd1>: merged uf_b5 feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:33:02,021] INFO in <ipython-input-25-98d5ab40bfd1>: merged uf_c1 feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:33:06,617] INFO in <ipython-input-25-98d5ab40bfd1>: merged uf_c2 feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:33:11,949] INFO in <ipython-input-25-98d5ab40bfd1>: merged uf_c3 feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:33:13,211] INFO in <ipython-input-25-98d5ab40bfd1>: merged uf_c4 feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:33:18,385] INFO in <ipython-input-25-98d5ab40bfd1>: merged uf_c5 feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:33:21,599] INFO in <ipython-input-25-98d5ab40bfd1>: merged diff_iq_day feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:33:25,055] INFO in <ipython-input-25-98d5ab40bfd1>: merged diff_iq_hour feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:33:27,434] INFO in <ipython-input-25-98d5ab40bfd1>: merged intersection_ft_count feature, shape: (1141683, 4)\n",
      "[2019-12-10 13:33:32,943] INFO in <ipython-input-25-98d5ab40bfd1>: merged intersection_it_count feature, shape: (1141683, 4)\n"
     ]
    }
   ],
   "source": [
    "# single_targets = ['uid', 'qid', 'freq', 'score', \n",
    "#                   'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "#                   'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5',\n",
    "#                   'diff_iq_day', 'diff_iq_hour', \n",
    "#                   'intersection_ft_count', 'intersection_it_count']\n",
    "multi_proc_merge(test, single_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-10 13:33:34,395] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: qid\n",
      "[2019-12-10 13:33:35,471] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 8)\n",
      "[2019-12-10 13:33:35,648] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 8)\n",
      "[2019-12-10 13:33:35,651] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: freq\n",
      "[2019-12-10 13:33:37,043] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 12)\n",
      "[2019-12-10 13:33:37,267] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 12)\n",
      "[2019-12-10 13:33:37,271] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: score\n",
      "[2019-12-10 13:33:38,473] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 16)\n",
      "[2019-12-10 13:33:38,593] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 16)\n",
      "[2019-12-10 13:33:38,595] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: uf_b1\n",
      "[2019-12-10 13:33:40,295] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 20)\n",
      "[2019-12-10 13:33:40,586] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 20)\n",
      "[2019-12-10 13:33:40,587] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: uf_b2\n",
      "[2019-12-10 13:33:42,885] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 24)\n",
      "[2019-12-10 13:33:43,211] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 24)\n",
      "[2019-12-10 13:33:43,214] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: uf_b3\n",
      "[2019-12-10 13:33:45,853] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 28)\n",
      "[2019-12-10 13:33:46,172] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 28)\n",
      "[2019-12-10 13:33:46,173] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: uf_b4\n",
      "[2019-12-10 13:33:49,105] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 32)\n",
      "[2019-12-10 13:33:49,518] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 32)\n",
      "[2019-12-10 13:33:49,520] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: uf_b5\n",
      "[2019-12-10 13:33:52,855] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 36)\n",
      "[2019-12-10 13:33:53,199] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 36)\n",
      "[2019-12-10 13:33:53,202] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: uf_c1\n",
      "[2019-12-10 13:33:56,728] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 40)\n",
      "[2019-12-10 13:33:57,087] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 40)\n",
      "[2019-12-10 13:33:57,088] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: uf_c2\n",
      "[2019-12-10 13:34:00,915] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 44)\n",
      "[2019-12-10 13:34:01,359] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 44)\n",
      "[2019-12-10 13:34:01,362] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: uf_c3\n",
      "[2019-12-10 13:34:04,824] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 48)\n",
      "[2019-12-10 13:34:05,086] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 48)\n",
      "[2019-12-10 13:34:05,087] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: uf_c4\n",
      "[2019-12-10 13:34:07,963] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 52)\n",
      "[2019-12-10 13:34:08,260] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 52)\n",
      "[2019-12-10 13:34:08,261] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: uf_c5\n",
      "[2019-12-10 13:34:11,969] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 56)\n",
      "[2019-12-10 13:34:12,280] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 56)\n",
      "[2019-12-10 13:34:12,281] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: diff_iq_day\n",
      "[2019-12-10 13:34:16,368] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 60)\n",
      "[2019-12-10 13:34:16,720] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 60)\n",
      "[2019-12-10 13:34:16,722] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: diff_iq_hour\n",
      "[2019-12-10 13:34:21,359] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 64)\n",
      "[2019-12-10 13:34:21,952] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 64)\n",
      "[2019-12-10 13:34:21,953] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: intersection_ft_count\n",
      "[2019-12-10 13:34:27,574] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 68)\n",
      "[2019-12-10 13:34:28,275] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 68)\n",
      "[2019-12-10 13:34:28,280] INFO in <ipython-input-27-2339738d67f8>: adding kfold label feature, at: intersection_it_count\n",
      "[2019-12-10 13:34:34,156] INFO in <ipython-input-27-2339738d67f8>: train shape: (9489162, 72)\n",
      "[2019-12-10 13:34:34,839] INFO in <ipython-input-27-2339738d67f8>: test shape: (1141683, 72)\n"
     ]
    }
   ],
   "source": [
    "t1 = pickle.load(open('feature/single_kfold_feat/train_uid.pkl', 'rb'))\n",
    "t2 = pickle.load(open('feature/single_kfold_feat/test_uid_merged.pkl', 'rb'))\n",
    "t3 = ['qid', 'freq', 'score', 'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "      'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5', 'diff_iq_day', 'diff_iq_hour', \n",
    "      'intersection_ft_count', 'intersection_it_count']\n",
    "for f in t3:\n",
    "    logging.info('adding kfold label feature, at: %s', f)\n",
    "    \n",
    "    tt1 = pickle.load(open(f'{feature_path}/single_kfold_feat/train_{f}.pkl', 'rb'))\n",
    "    t1 = pd.concat([t1, tt1], axis=1)\n",
    "    logging.info('train shape: %s', t1.shape)\n",
    "    \n",
    "    tt1 = pickle.load(open(f'{feature_path}/single_kfold_feat/test_{f}_merged.pkl', 'rb'))\n",
    "    t2 = pd.concat([t2, tt1], axis=1)\n",
    "    logging.info('test shape: %s', t2.shape)\n",
    "\n",
    "pickle.dump(t1, open(f'{feature_path}/train_kfold_label_feature.pkl', 'wb'))\n",
    "pickle.dump(t2, open(f'{feature_path}/test_kfold_label_feature.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_feat = []\n",
    "# uid\n",
    "\n",
    "# qid \n",
    "pair_feat += [['qid', 'gender'], ['qid', 'freq'], ['qid', 'score']]\n",
    "for feat in ['uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', 'uf_c5']:\n",
    "    pair_feat.append(['qid', feat])\n",
    "pair_feat += [['qid', 'diff_iq_day'], ['qid', 'diff_qi_hour'], \n",
    "              ['qid', 'intersection_ft_count'], ['qid', 'intersection_it_count']]\n",
    "\n",
    "# 二分类\n",
    "pair_feat += [['uf_b1', 'uf_b2'], ['uf_b2', 'uf_b3']]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
