{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import logging\n",
    "import multiprocessing\n",
    "import traceback\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fmt = \"[%(asctime)s] %(levelname)s in %(module)s: %(message)s\"\n",
    "logging.basicConfig(format=log_fmt, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data'\n",
    "feature_path = './feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-11 13:56:09,914] INFO in <ipython-input-32-af34e33feb4f>: invite (9489162, 4)\n",
      "[2019-12-11 13:56:13,784] INFO in <ipython-input-32-af34e33feb4f>: test (1141683, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(f'{base_path}/invite_info_0926.txt', sep='\\t', header=None)\n",
    "train.columns = ['qid', 'uid', 'dt', 'label']\n",
    "logging.info(\"invite %s\", train.shape)\n",
    "\n",
    "test = pd.read_csv(f'{base_path}/invite_info_evaluate_0926.txt', sep='\\t', header=None)\n",
    "test.columns = ['qid', 'uid', 'dt']\n",
    "logging.info(\"test %s\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_day(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[0][1:]))\n",
    "\n",
    "\n",
    "def extract_hour(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[1][1:]))\n",
    "\n",
    "train['day'] = extract_day(train['dt'])\n",
    "train['week'] = train['day'] % 7\n",
    "train['hour'] = extract_hour(train['dt'])\n",
    "\n",
    "test['day'] = extract_day(test['dt'])\n",
    "test['week'] = test['day'] % 7\n",
    "test['hour'] = extract_hour(test['dt'])\n",
    "\n",
    "del train['dt'], test['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-11 14:04:40,237] INFO in <ipython-input-34-cbb4bab8955e>: user (1931654, 14)\n"
     ]
    }
   ],
   "source": [
    "# 加载用户\n",
    "user = pd.read_csv(f'{base_path}/member_info_0926.txt', header=None, sep='\\t')\n",
    "user.columns = ['uid', 'gender', 'freq', 'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "                'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5',  'score', 'follow_topic', 'inter_topic']\n",
    "\n",
    "del user['follow_topic'], user['inter_topic']\n",
    "logging.info(\"user %s\", user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge user\n",
    "train = pd.merge(train, user, on='uid', how='left')\n",
    "test = pd.merge(test, user, on='uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-11 14:05:54,805] INFO in <ipython-input-36-3053b1f3a755>: ques (1829900, 2)\n"
     ]
    }
   ],
   "source": [
    "# 加载问题\n",
    "ques = pd.read_csv(f'{base_path}/question_info_0926.txt', header=None, sep='\\t')\n",
    "ques.columns = ['qid', 'q_dt', 'title_t1', 'title_t2', 'desc_t1', 'desc_t2', 'topic']\n",
    "del ques['title_t1'], ques['title_t2'], ques['desc_t1'], ques['desc_t2'], ques['topic']\n",
    "logging.info(\"ques %s\", ques.shape)\n",
    "\n",
    "ques['q_day'] = extract_day(ques['q_dt'])\n",
    "ques['q_hour'] = extract_hour(ques['q_dt'])\n",
    "ques['q_week'] = ques['q_day'] % 7\n",
    "\n",
    "del ques['q_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ques\n",
    "train = pd.merge(train, ques, on='qid', how='left')\n",
    "test = pd.merge(test, ques, on='qid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['diff_iq_day'] = train['day'] - train['q_day']\n",
    "train['diff_iq_hour'] = train['diff_iq_day'] * 24 + (train['hour'] - train['q_hour'])\n",
    "\n",
    "test['diff_iq_day'] = test['day'] - test['q_day']\n",
    "test['diff_iq_hour'] = test['diff_iq_day'] * 24 + (test['hour'] - test['q_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_iq_day_map(x):\n",
    "    if x>=31:\n",
    "        return 31\n",
    "    if x<0:\n",
    "        return 0\n",
    "    return x\n",
    "\n",
    "train['diff_iq_day'] = train['diff_iq_day'].apply(diff_iq_day_map)\n",
    "test['diff_iq_day'] = test['diff_iq_day'].apply(diff_iq_day_map)\n",
    "\n",
    "def diff_iq_hour_map(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    if x>200:\n",
    "        return 40\n",
    "    return x // 5\n",
    "train['diff_iq_hour'] = train['diff_iq_hour'].apply(diff_iq_hour_map)\n",
    "test['diff_iq_day'] = test['diff_iq_day'].apply(diff_iq_day_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_map(x):\n",
    "    if x<=280:\n",
    "        return -1\n",
    "    if x<=300:\n",
    "        return 0\n",
    "    if 300<x<=350:\n",
    "        return 1\n",
    "    if 350<x<=400:\n",
    "        return 2\n",
    "    if 400<x<=500:\n",
    "        return 3\n",
    "    if 500<x<=600:\n",
    "        return 4\n",
    "    if 600<x<=700:\n",
    "        return 5\n",
    "    if 700<x<=800:\n",
    "        return 6\n",
    "    return 7\n",
    "\n",
    "train['score'] = train['score'].apply(score_map)\n",
    "test['score'] = test['score'].apply(score_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 invete feature 2: intersection_ft_count, intersection_it_count\n",
    "t1 = pd.read_csv(f'{feature_path}/train_invite_feature_2.txt', sep='\\t', \n",
    "                 usecols=['intersection_ft_count', 'intersection_it_count'])\n",
    "train = pd.concat([train, t1], axis=1)\n",
    "\n",
    "t1 = pd.read_csv(f'{feature_path}/test_invite_feature_2.txt', sep='\\t', \n",
    "                 usecols=['intersection_ft_count', 'intersection_it_count'])\n",
    "test = pd.concat([test, t1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分 intersection_ft_count\n",
    "def to_bin_1(x):\n",
    "    if x>=3:\n",
    "        return 3\n",
    "    return x\n",
    "\n",
    "train['intersection_ft_count'] = train['intersection_ft_count'].apply(to_bin_1)\n",
    "test['intersection_ft_count'] = test['intersection_ft_count'].apply(to_bin_1)\n",
    "\n",
    "# 划分 intersection_it_count\n",
    "def to_bin_2(x):\n",
    "    if x>=4:\n",
    "        return 4\n",
    "    return x\n",
    "\n",
    "train['intersection_it_count'] = train['intersection_it_count'].apply(to_bin_2)\n",
    "test['intersection_it_count'] = test['intersection_it_count'].apply(to_bin_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4折统计\n",
    "def fold_fn(x):\n",
    "    if 3838<=x<=3846:\n",
    "        return 0\n",
    "    if 3847<=x<=3853:\n",
    "        return 1\n",
    "    if 3854<=x<=3860:\n",
    "        return 2\n",
    "    if 3861<=x<=3867:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fold'] = train['day'].apply(fold_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 一阶\n",
    "def single_train_feat(df_, feat):\n",
    "    df = df_.copy()\n",
    "    extract_feat_1 = [feat+'_kfold_count', feat+'_label_mean', feat+'_label_sum', feat+'_label_std']\n",
    "#     extract_feat_2 = [feat+'_kfold_hour_count', feat+'_label_hour_mean', \n",
    "#                       feat+'_label_hour_sum', feat+'_label_hour_std']\n",
    "#     extract_feat_3 = [feat+'_kfold_week_count', feat+'_label_week_mean', \n",
    "#                       feat+'_label_week_sum', feat+'_label_week_std']\n",
    "#     extract_feat = extract_feat_1 + extract_feat_2 + extract_feat_3\n",
    "    extract_feat = extract_feat_1\n",
    "    for c in extract_feat:\n",
    "        df[c] = -10000\n",
    "    for i in range(4):\n",
    "        t1 = df[df['fold']!=i].groupby(feat)['label'].agg(['count', 'mean', 'sum', 'std']).reset_index()\n",
    "#         t1.loc[t1['count']<5, ['mean', 'std']] = np.nan\n",
    "        t1.columns = [feat] + extract_feat_1\n",
    "        df.loc[df['fold']==i, extract_feat_1] = pd.merge(df.loc[df['fold']==i, feat], t1, on=feat, \n",
    "                                                         how='left')[extract_feat_1].values\n",
    "        # 某小时\n",
    "#         t1 = df[df['fold']!=i].groupby([feat, 'hour'])['label'].agg(['count', \n",
    "#                                                                      'mean', 'sum', 'std']).reset_index()\n",
    "#         t1.loc[t1['count']<5, ['mean', 'std']] = np.nan\n",
    "#         t1.columns = [feat, 'hour'] + extract_feat_2\n",
    "#         df.loc[df['fold']==i, extract_feat_2] = pd.merge(df.loc[df['fold']==i, [feat, 'hour']], \n",
    "#                                                          t1, on=[feat, 'hour'], \n",
    "#                                                          how='left')[extract_feat_2].values\n",
    "#         # 一周的某一天\n",
    "#         t1 = df[df['fold']!=i].groupby([feat, 'week'])['label'].agg(['count', \n",
    "#                                                                      'mean', 'sum', 'std']).reset_index()\n",
    "#         t1.loc[t1['count']<5, ['mean', 'std']] = np.nan\n",
    "#         t1.columns = [feat, 'week'] + extract_feat_3\n",
    "#         df.loc[df['fold']==i, extract_feat_3] = pd.merge(df.loc[df['fold']==i, [feat, 'week']], \n",
    "#                                                          t1, on=[feat, 'week'], \n",
    "#                                                          how='left')[extract_feat_3].values\n",
    "\n",
    "    for c in range(0, len(extract_feat), 2):\n",
    "        df[extract_feat[c]] = ((df[extract_feat[c]].fillna(0))/23).astype('float32')\n",
    "    for c in range(1, len(extract_feat), 2):\n",
    "        df[extract_feat[c]] = df[extract_feat[c]].astype('float32')\n",
    "\n",
    "    return df[extract_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_targets = ['uid', 'qid', 'freq', 'score', \n",
    "                  'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "                  'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5',\n",
    "                  'diff_iq_day', 'diff_iq_hour', \n",
    "                  'intersection_ft_count', 'intersection_it_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_proc = len(single_targets)\n",
    "\n",
    "def kfold_worker_1(df, feat):\n",
    "    try:\n",
    "        t1 = single_train_feat(df, feat)\n",
    "        logging.info('%s, feature shape: %s', feat, t1.shape)\n",
    "        \n",
    "        pickle.dump(t1, open(f'{feature_path}/single_kfold_feat/train_{feat}.pkl', 'wb'))\n",
    "        logging.info('%s feature saved!', feat)\n",
    "        del t1\n",
    "        gc.collect()\n",
    "    except:\n",
    "        print(traceback.print_exct())\n",
    "\n",
    "def multi_proc_train(df, feat_list):\n",
    "    pool = multiprocessing.Pool(processes=n_proc)\n",
    "    for f in feat_list:\n",
    "        pool.apply_async(kfold_worker_1, (df, f))\n",
    "    pool.close()\n",
    "    pool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-11 14:13:12,524] INFO in <ipython-input-47-de9045d32bd3>: qid, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:13:13,541] INFO in <ipython-input-47-de9045d32bd3>: qid feature saved!\n",
      "[2019-12-11 14:13:25,619] INFO in <ipython-input-47-de9045d32bd3>: freq, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:13:27,008] INFO in <ipython-input-47-de9045d32bd3>: freq feature saved!\n",
      "[2019-12-11 14:13:53,742] INFO in <ipython-input-47-de9045d32bd3>: uid, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:13:54,318] INFO in <ipython-input-47-de9045d32bd3>: uid feature saved!\n",
      "[2019-12-11 14:14:07,567] INFO in <ipython-input-47-de9045d32bd3>: score, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:14:08,095] INFO in <ipython-input-47-de9045d32bd3>: score feature saved!\n",
      "[2019-12-11 14:14:40,342] INFO in <ipython-input-47-de9045d32bd3>: uf_b1, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:14:41,266] INFO in <ipython-input-47-de9045d32bd3>: uf_b1 feature saved!\n",
      "[2019-12-11 14:15:59,246] INFO in <ipython-input-47-de9045d32bd3>: uf_b3, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:15:59,825] INFO in <ipython-input-47-de9045d32bd3>: uf_b3 feature saved!\n",
      "[2019-12-11 14:16:09,150] INFO in <ipython-input-47-de9045d32bd3>: uf_b2, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:16:10,051] INFO in <ipython-input-47-de9045d32bd3>: uf_b2 feature saved!\n",
      "[2019-12-11 14:17:13,298] INFO in <ipython-input-47-de9045d32bd3>: uf_b4, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:17:14,293] INFO in <ipython-input-47-de9045d32bd3>: uf_b4 feature saved!\n",
      "[2019-12-11 14:17:27,512] INFO in <ipython-input-47-de9045d32bd3>: uf_b5, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:17:28,246] INFO in <ipython-input-47-de9045d32bd3>: uf_b5 feature saved!\n",
      "[2019-12-11 14:18:23,799] INFO in <ipython-input-47-de9045d32bd3>: uf_c2, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:18:24,775] INFO in <ipython-input-47-de9045d32bd3>: uf_c2 feature saved!\n",
      "[2019-12-11 14:18:42,774] INFO in <ipython-input-47-de9045d32bd3>: uf_c1, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:18:43,792] INFO in <ipython-input-47-de9045d32bd3>: uf_c1 feature saved!\n",
      "[2019-12-11 14:19:06,102] INFO in <ipython-input-47-de9045d32bd3>: uf_c3, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:19:06,683] INFO in <ipython-input-47-de9045d32bd3>: uf_c3 feature saved!\n",
      "[2019-12-11 14:19:47,796] INFO in <ipython-input-47-de9045d32bd3>: uf_c4, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:19:48,558] INFO in <ipython-input-47-de9045d32bd3>: uf_c4 feature saved!\n",
      "[2019-12-11 14:21:17,304] INFO in <ipython-input-47-de9045d32bd3>: uf_c5, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:21:18,240] INFO in <ipython-input-47-de9045d32bd3>: uf_c5 feature saved!\n",
      "[2019-12-11 14:21:39,369] INFO in <ipython-input-47-de9045d32bd3>: intersection_ft_count, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:21:39,881] INFO in <ipython-input-47-de9045d32bd3>: intersection_ft_count feature saved!\n",
      "[2019-12-11 14:21:42,905] INFO in <ipython-input-47-de9045d32bd3>: diff_iq_day, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:21:43,894] INFO in <ipython-input-47-de9045d32bd3>: diff_iq_day feature saved!\n",
      "[2019-12-11 14:21:59,631] INFO in <ipython-input-47-de9045d32bd3>: diff_iq_hour, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:22:00,242] INFO in <ipython-input-47-de9045d32bd3>: diff_iq_hour feature saved!\n",
      "[2019-12-11 14:23:22,001] INFO in <ipython-input-47-de9045d32bd3>: intersection_it_count, feature shape: (9489162, 4)\n",
      "[2019-12-11 14:23:22,994] INFO in <ipython-input-47-de9045d32bd3>: intersection_it_count feature saved!\n"
     ]
    }
   ],
   "source": [
    "multi_proc_train(train, single_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 一阶\n",
    "def single_test_feat(df, feat):\n",
    "    extract_feat_1 = [feat+'_kfold_count', feat+'_label_mean', feat+'_label_sum', feat+'_label_std']\n",
    "#     extract_feat_2 = [feat+'_kfold_hour_count', feat+'_label_hour_mean', \n",
    "#                       feat+'_label_hour_sum', feat+'_label_hour_std']\n",
    "#     extract_feat_3 = [feat+'_kfold_week_count', feat+'_label_week_mean', \n",
    "#                       feat+'_label_week_sum', feat+'_label_week_std']\n",
    "#     extract_feat = extract_feat_1 + extract_feat_2 + extract_feat_3\n",
    "    extract_feat = extract_feat_1\n",
    "    \n",
    "    t1 = df.groupby(feat)['label'].agg(['count', 'mean', 'sum', 'std']).reset_index()\n",
    "#     t1.loc[t1['count']<5, ['mean', 'std']] = np.nan\n",
    "    t1.columns = [feat] + extract_feat_1\n",
    "#     t2 = df.groupby([feat, 'hour'])['label'].agg(['count', 'mean', 'sum', 'std']).reset_index()\n",
    "#     t2.loc[t2['count']<5, ['mean', 'std']] = np.nan\n",
    "#     t2.columns = [feat, 'hour'] + extract_feat_2\n",
    "    \n",
    "#     t3 = df.groupby([feat, 'week'])['label'].agg(['count', 'mean', 'sum', 'std']).reset_index()\n",
    "#     t3.loc[t3['count']<5, ['mean', 'std']] = np.nan\n",
    "#     t3.columns = [feat, 'week'] + extract_feat_3\n",
    "    \n",
    "    # 数据压缩\n",
    "    for c in range(0, 4, 2):\n",
    "        t1[extract_feat_1[c]] = ((t1[extract_feat_1[c]].fillna(0))/30).astype('float32')\n",
    "#         t2[extract_feat_2[c]] = ((t2[extract_feat_2[c]])*23/30).astype('int32')\n",
    "#         t3[extract_feat_3[c]] = ((t3[extract_feat_3[c]])*23/30).astype('int32')\n",
    "    for c in range(1, 4, 2):\n",
    "        t1[extract_feat_1[c]] = t1[extract_feat_1[c]].astype('float32')\n",
    "#         t2[extract_feat_2[c]] = t2[extract_feat_2[c]].astype('float32')\n",
    "#         t3[extract_feat_3[c]] = t3[extract_feat_3[c]].astype('float32')\n",
    "    \n",
    "#     return t1, t2, t3\n",
    "    return t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_proc = len(single_targets)\n",
    "\n",
    "def kfold_worker_2(train_df, feat):\n",
    "    try:\n",
    "#         t1, t2, t3 = single_test_feat(train_df, feat)\n",
    "        t1 = single_test_feat(train_df, feat)\n",
    "        logging.info('%s, feature shape: %s', feat, t1.shape)\n",
    "        \n",
    "        pickle.dump(t1, open(f'{feature_path}/single_kfold_feat/test_{feat}_t1.pkl', 'wb'))\n",
    "#         pickle.dump(t2, open(f'{feature_path}/single_kfold_feat/test_{feat}_t2.pkl', 'wb'))\n",
    "#         pickle.dump(t3, open(f'{feature_path}/single_kfold_feat/test_{feat}_t3.pkl', 'wb'))\n",
    "        logging.info('%s feature saved!', feat)\n",
    "#         del t1, t2, t3\n",
    "        del t1\n",
    "        gc.collect()\n",
    "    except:\n",
    "        print(traceback.print_exct())\n",
    "\n",
    "def multi_proc_test(train_df, feat_list):\n",
    "    pool = multiprocessing.Pool(processes=n_proc)\n",
    "    for f in feat_list:\n",
    "        pool.apply_async(kfold_worker_2, (train_df, f))\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-11 14:24:58,310] INFO in <ipython-input-50-855a6c763eb1>: uid, feature shape: (1358213, 5)\n",
      "[2019-12-11 14:24:59,258] INFO in <ipython-input-50-855a6c763eb1>: uid feature saved!\n",
      "[2019-12-11 14:25:15,698] INFO in <ipython-input-50-855a6c763eb1>: qid, feature shape: (926203, 5)\n",
      "[2019-12-11 14:25:16,052] INFO in <ipython-input-50-855a6c763eb1>: qid feature saved!\n",
      "[2019-12-11 14:25:52,400] INFO in <ipython-input-50-855a6c763eb1>: freq, feature shape: (5, 5)\n",
      "[2019-12-11 14:25:52,405] INFO in <ipython-input-50-855a6c763eb1>: freq feature saved!\n",
      "[2019-12-11 14:26:32,288] INFO in <ipython-input-50-855a6c763eb1>: score, feature shape: (9, 5)\n",
      "[2019-12-11 14:26:32,293] INFO in <ipython-input-50-855a6c763eb1>: score feature saved!\n",
      "[2019-12-11 14:27:16,736] INFO in <ipython-input-50-855a6c763eb1>: uf_b1, feature shape: (2, 5)\n",
      "[2019-12-11 14:27:16,741] INFO in <ipython-input-50-855a6c763eb1>: uf_b1 feature saved!\n",
      "[2019-12-11 14:28:07,653] INFO in <ipython-input-50-855a6c763eb1>: uf_b2, feature shape: (2, 5)\n",
      "[2019-12-11 14:28:07,661] INFO in <ipython-input-50-855a6c763eb1>: uf_b2 feature saved!\n",
      "[2019-12-11 14:28:16,316] INFO in <ipython-input-50-855a6c763eb1>: uf_b3, feature shape: (2, 5)\n",
      "[2019-12-11 14:28:16,323] INFO in <ipython-input-50-855a6c763eb1>: uf_b3 feature saved!\n",
      "[2019-12-11 14:28:58,940] INFO in <ipython-input-50-855a6c763eb1>: uf_b4, feature shape: (2, 5)\n",
      "[2019-12-11 14:28:58,951] INFO in <ipython-input-50-855a6c763eb1>: uf_b4 feature saved!\n",
      "[2019-12-11 14:29:43,717] INFO in <ipython-input-50-855a6c763eb1>: uf_b5, feature shape: (2, 5)\n",
      "[2019-12-11 14:29:43,724] INFO in <ipython-input-50-855a6c763eb1>: uf_b5 feature saved!\n",
      "[2019-12-11 14:30:06,663] INFO in <ipython-input-50-855a6c763eb1>: uf_c1, feature shape: (2250, 5)\n",
      "[2019-12-11 14:30:06,679] INFO in <ipython-input-50-855a6c763eb1>: uf_c1 feature saved!\n",
      "[2019-12-11 14:31:01,794] INFO in <ipython-input-50-855a6c763eb1>: uf_c2, feature shape: (240, 5)\n",
      "[2019-12-11 14:31:01,801] INFO in <ipython-input-50-855a6c763eb1>: uf_c2 feature saved!\n",
      "[2019-12-11 14:31:41,585] INFO in <ipython-input-50-855a6c763eb1>: uf_c3, feature shape: (399, 5)\n",
      "[2019-12-11 14:31:41,591] INFO in <ipython-input-50-855a6c763eb1>: uf_c3 feature saved!\n",
      "[2019-12-11 14:32:20,565] INFO in <ipython-input-50-855a6c763eb1>: uf_c4, feature shape: (1339, 5)\n",
      "[2019-12-11 14:32:20,572] INFO in <ipython-input-50-855a6c763eb1>: uf_c4 feature saved!\n",
      "[2019-12-11 14:33:00,456] INFO in <ipython-input-50-855a6c763eb1>: uf_c5, feature shape: (2, 5)\n",
      "[2019-12-11 14:33:00,462] INFO in <ipython-input-50-855a6c763eb1>: uf_c5 feature saved!\n",
      "[2019-12-11 14:33:38,001] INFO in <ipython-input-50-855a6c763eb1>: diff_iq_day, feature shape: (32, 5)\n",
      "[2019-12-11 14:33:38,008] INFO in <ipython-input-50-855a6c763eb1>: diff_iq_day feature saved!\n",
      "[2019-12-11 14:34:18,793] INFO in <ipython-input-50-855a6c763eb1>: diff_iq_hour, feature shape: (41, 5)\n",
      "[2019-12-11 14:34:18,802] INFO in <ipython-input-50-855a6c763eb1>: diff_iq_hour feature saved!\n",
      "[2019-12-11 14:34:43,953] INFO in <ipython-input-50-855a6c763eb1>: intersection_ft_count, feature shape: (4, 5)\n",
      "[2019-12-11 14:34:43,963] INFO in <ipython-input-50-855a6c763eb1>: intersection_ft_count feature saved!\n",
      "[2019-12-11 14:35:45,384] INFO in <ipython-input-50-855a6c763eb1>: intersection_it_count, feature shape: (5, 5)\n",
      "[2019-12-11 14:35:45,391] INFO in <ipython-input-50-855a6c763eb1>: intersection_it_count feature saved!\n"
     ]
    }
   ],
   "source": [
    "multi_proc_test(train, single_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_merge(test_df, feat_df_list, feat):\n",
    "    extract_feat_1 = [feat+'_kfold_count', feat+'_label_mean', feat+'_label_sum', feat+'_label_std']\n",
    "#     extract_feat_2 = [feat+'_kfold_hour_count', feat+'_label_hour_mean', \n",
    "#                       feat+'_label_hour_sum', feat+'_label_hour_std']\n",
    "#     extract_feat_3 = [feat+'_kfold_week_count', feat+'_label_week_mean', \n",
    "#                       feat+'_label_week_sum', feat+'_label_week_std']\n",
    "#     extract_feat = extract_feat_1 + extract_feat_2 + extract_feat_3\n",
    "    extract_feat = extract_feat_1 \n",
    "    t1 = pd.merge(test_df, feat_df_list[0], on=[feat], how='left')\n",
    "#     t1 = pd.merge(t1, feat_df_list[1], on=[feat, 'hour'], how='left')\n",
    "#     t1 = pd.merge(t1, feat_df_list[2], on=[feat, 'week'], how='left')\n",
    "    for i in range(0, len(extract_feat), 2):\n",
    "        t1[extract_feat[i]] = t1[extract_feat[i]].fillna(0).astype('float32')\n",
    "    for i in range(1, len(extract_feat), 2):\n",
    "        t1[extract_feat[i]] = t1[extract_feat[i]].astype('float32')\n",
    "\n",
    "    return t1[extract_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_worker(test_df, feat):\n",
    "    l1 = []\n",
    "    l1.append(pickle.load(open(f'{feature_path}/single_kfold_feat/test_{feat}_t1.pkl', 'rb')))\n",
    "#     l1.append(pickle.load(open(f'{feature_path}/single_kfold_feat/test_{feat}_t2.pkl', 'rb')))\n",
    "#     l1.append(pickle.load(open(f'{feature_path}/single_kfold_feat/test_{feat}_t3.pkl', 'rb')))\n",
    "    t1 = my_merge(test_df, l1, feat)\n",
    "    logging.info('merged %s feature, shape: %s', feat, t1.shape)\n",
    "    pickle.dump(t1, open(f'{feature_path}/single_kfold_feat/test_{feat}_merged.pkl', 'wb'))\n",
    "\n",
    "def multi_proc_merge(test_df, feat_list):\n",
    "    pool = multiprocessing.Pool(processes=n_proc)\n",
    "    for f in feat_list:\n",
    "        pool.apply_async(merge_worker, (test_df, f))\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-11 14:36:03,186] INFO in <ipython-input-53-98d5ab40bfd1>: merged uid feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:36:07,625] INFO in <ipython-input-53-98d5ab40bfd1>: merged qid feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:36:12,058] INFO in <ipython-input-53-98d5ab40bfd1>: merged freq feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:36:17,072] INFO in <ipython-input-53-98d5ab40bfd1>: merged score feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:36:23,032] INFO in <ipython-input-53-98d5ab40bfd1>: merged uf_b1 feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:36:26,700] INFO in <ipython-input-53-98d5ab40bfd1>: merged uf_b2 feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:36:30,440] INFO in <ipython-input-53-98d5ab40bfd1>: merged uf_b3 feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:36:35,976] INFO in <ipython-input-53-98d5ab40bfd1>: merged uf_b4 feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:36:41,562] INFO in <ipython-input-53-98d5ab40bfd1>: merged uf_b5 feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:36:44,853] INFO in <ipython-input-53-98d5ab40bfd1>: merged uf_c1 feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:36:48,008] INFO in <ipython-input-53-98d5ab40bfd1>: merged uf_c2 feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:36:56,004] INFO in <ipython-input-53-98d5ab40bfd1>: merged uf_c3 feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:37:01,901] INFO in <ipython-input-53-98d5ab40bfd1>: merged uf_c4 feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:37:06,014] INFO in <ipython-input-53-98d5ab40bfd1>: merged uf_c5 feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:37:11,836] INFO in <ipython-input-53-98d5ab40bfd1>: merged diff_iq_day feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:37:14,066] INFO in <ipython-input-53-98d5ab40bfd1>: merged diff_iq_hour feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:37:17,972] INFO in <ipython-input-53-98d5ab40bfd1>: merged intersection_ft_count feature, shape: (1141683, 4)\n",
      "[2019-12-11 14:37:21,874] INFO in <ipython-input-53-98d5ab40bfd1>: merged intersection_it_count feature, shape: (1141683, 4)\n"
     ]
    }
   ],
   "source": [
    "# single_targets = ['uid', 'qid', 'freq', 'score', \n",
    "#                   'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "#                   'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5',\n",
    "#                   'diff_iq_day', 'diff_iq_hour', \n",
    "#                   'intersection_ft_count', 'intersection_it_count']\n",
    "multi_proc_merge(test, single_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-11 14:37:23,387] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: qid\n",
      "[2019-12-11 14:37:23,966] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 8)\n",
      "[2019-12-11 14:37:24,038] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 8)\n",
      "[2019-12-11 14:37:24,040] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: freq\n",
      "[2019-12-11 14:37:25,117] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 12)\n",
      "[2019-12-11 14:37:25,249] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 12)\n",
      "[2019-12-11 14:37:25,252] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: score\n",
      "[2019-12-11 14:37:26,572] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 16)\n",
      "[2019-12-11 14:37:26,771] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 16)\n",
      "[2019-12-11 14:37:26,775] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: uf_b1\n",
      "[2019-12-11 14:37:28,347] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 20)\n",
      "[2019-12-11 14:37:28,440] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 20)\n",
      "[2019-12-11 14:37:28,445] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: uf_b2\n",
      "[2019-12-11 14:37:29,931] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 24)\n",
      "[2019-12-11 14:37:30,164] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 24)\n",
      "[2019-12-11 14:37:30,166] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: uf_b3\n",
      "[2019-12-11 14:37:32,277] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 28)\n",
      "[2019-12-11 14:37:32,528] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 28)\n",
      "[2019-12-11 14:37:32,529] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: uf_b4\n",
      "[2019-12-11 14:37:34,879] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 32)\n",
      "[2019-12-11 14:37:35,181] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 32)\n",
      "[2019-12-11 14:37:35,184] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: uf_b5\n",
      "[2019-12-11 14:37:37,795] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 36)\n",
      "[2019-12-11 14:37:38,101] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 36)\n",
      "[2019-12-11 14:37:38,104] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: uf_c1\n",
      "[2019-12-11 14:37:40,973] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 40)\n",
      "[2019-12-11 14:37:41,290] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 40)\n",
      "[2019-12-11 14:37:41,292] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: uf_c2\n",
      "[2019-12-11 14:37:44,523] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 44)\n",
      "[2019-12-11 14:37:44,887] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 44)\n",
      "[2019-12-11 14:37:44,890] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: uf_c3\n",
      "[2019-12-11 14:37:48,336] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 48)\n",
      "[2019-12-11 14:37:48,767] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 48)\n",
      "[2019-12-11 14:37:48,769] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: uf_c4\n",
      "[2019-12-11 14:37:52,101] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 52)\n",
      "[2019-12-11 14:37:52,531] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 52)\n",
      "[2019-12-11 14:37:52,533] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: uf_c5\n",
      "[2019-12-11 14:37:56,357] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 56)\n",
      "[2019-12-11 14:37:56,768] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 56)\n",
      "[2019-12-11 14:37:56,770] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: diff_iq_day\n",
      "[2019-12-11 14:38:00,444] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 60)\n",
      "[2019-12-11 14:38:00,913] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 60)\n",
      "[2019-12-11 14:38:00,914] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: diff_iq_hour\n",
      "[2019-12-11 14:38:05,261] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 64)\n",
      "[2019-12-11 14:38:05,723] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 64)\n",
      "[2019-12-11 14:38:05,725] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: intersection_ft_count\n",
      "[2019-12-11 14:38:09,189] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 68)\n",
      "[2019-12-11 14:38:09,654] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 68)\n",
      "[2019-12-11 14:38:09,656] INFO in <ipython-input-55-2339738d67f8>: adding kfold label feature, at: intersection_it_count\n",
      "[2019-12-11 14:38:14,394] INFO in <ipython-input-55-2339738d67f8>: train shape: (9489162, 72)\n",
      "[2019-12-11 14:38:14,969] INFO in <ipython-input-55-2339738d67f8>: test shape: (1141683, 72)\n"
     ]
    }
   ],
   "source": [
    "t1 = pickle.load(open('feature/single_kfold_feat/train_uid.pkl', 'rb'))\n",
    "t2 = pickle.load(open('feature/single_kfold_feat/test_uid_merged.pkl', 'rb'))\n",
    "t3 = ['qid', 'freq', 'score', 'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "      'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5', 'diff_iq_day', 'diff_iq_hour', \n",
    "      'intersection_ft_count', 'intersection_it_count']\n",
    "for f in t3:\n",
    "    logging.info('adding kfold label feature, at: %s', f)\n",
    "    \n",
    "    tt1 = pickle.load(open(f'{feature_path}/single_kfold_feat/train_{f}.pkl', 'rb'))\n",
    "    t1 = pd.concat([t1, tt1], axis=1)\n",
    "    logging.info('train shape: %s', t1.shape)\n",
    "    \n",
    "    tt1 = pickle.load(open(f'{feature_path}/single_kfold_feat/test_{f}_merged.pkl', 'rb'))\n",
    "    t2 = pd.concat([t2, tt1], axis=1)\n",
    "    logging.info('test shape: %s', t2.shape)\n",
    "\n",
    "pickle.dump(t1, open(f'{feature_path}/train_kfold_label_feature.pkl', 'wb'))\n",
    "pickle.dump(t2, open(f'{feature_path}/test_kfold_label_feature.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_feat = []\n",
    "# uid\n",
    "\n",
    "# qid \n",
    "pair_feat += [['qid', 'gender'], ['qid', 'freq'], ['qid', 'score']]\n",
    "for feat in ['uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', 'uf_c5']:\n",
    "    pair_feat.append(['qid', feat])\n",
    "pair_feat += [['qid', 'diff_iq_day'], ['qid', 'diff_qi_hour'], \n",
    "              ['qid', 'intersection_ft_count'], ['qid', 'intersection_it_count']]\n",
    "\n",
    "# 二分类\n",
    "pair_feat += [['uf_b1', 'uf_b2'], ['uf_b2', 'uf_b3']]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
