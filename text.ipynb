{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import ray\n",
    "# ray.init(num_cpus=36)\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import logging\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "log_fmt = \"[%(asctime)s] %(levelname)s in %(module)s: %(message)s\"\n",
    "logging.basicConfig(format=log_fmt, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data'\n",
    "feature_path = './feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 话题向量\n",
    "topic_table = pd.read_csv(f'{base_path}/topic_vectors_64d.txt', sep='\\t', header=None)\n",
    "topic_table.columns = ['topic', 'vec']\n",
    "\n",
    "def str2vec(s):\n",
    "    tmp = s.split(' ')\n",
    "    res = []\n",
    "    for num in tmp:\n",
    "        res.append(float(num))\n",
    "    return res\n",
    "\n",
    "topic_table['vec'] = topic_table['vec'].apply(str2vec)\n",
    "\n",
    "# import pickle\n",
    "# pickle.dump(topic_table, open(f'{base_path}/topic_vec.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-05 11:45:33,759] INFO in <ipython-input-4-f4a7178965f4>: ques (1829900, 2)\n"
     ]
    }
   ],
   "source": [
    "# 问题\n",
    "ques = pd.read_csv(f'{base_path}/question_info_0926.txt', header=None, sep='\\t')\n",
    "ques.columns = ['qid', 'q_dt', 'title_t1', 'title_t2', 'desc_t1', 'desc_t2', 'topic']\n",
    "# del ques['title_t1'], ques['title_t2'], ques['desc_t1'], ques['desc_t2']\n",
    "del ques['q_dt'], ques['title_t1'], ques['title_t2'], ques['desc_t1'], ques['desc_t2']\n",
    "\n",
    "logging.info(\"ques %s\", ques.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-05 11:46:41,541] INFO in <ipython-input-5-c99731a9feaa>: ans (4513735, 3)\n"
     ]
    }
   ],
   "source": [
    "# 回答\n",
    "ans = pd.read_csv(f'{base_path}/answer_info_0926.txt', header=None, sep='\\t')\n",
    "ans.columns = ['aid', 'qid', 'uid', 'ans_dt', 'ans_t1', 'ans_t2', 'is_good', 'is_rec', 'is_dest', 'has_img',\n",
    "               'has_video', 'word_count', 'reci_cheer', 'reci_uncheer', 'reci_comment', 'reci_mark', 'reci_tks',\n",
    "               'reci_xxx', 'reci_no_help', 'reci_dis']\n",
    "del ans['is_good'], ans['is_rec'], ans['is_dest'], ans['has_img'], ans['has_video'] \n",
    "del ans['word_count']\n",
    "del ans['reci_cheer'], ans['reci_uncheer'], ans['reci_comment'], ans['reci_mark'], ans['reci_tks']\n",
    "del ans['reci_xxx'], ans['reci_no_help'], ans['reci_dis']\n",
    "del ans['ans_dt'], ans['ans_t1'], ans['ans_t2']\n",
    "logging.info(\"ans %s\", ans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ans 对应的问题的话题\n",
    "ans = pd.merge(ans, ques, on='qid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid\n",
       "M1000000382                                             T13,T567\n",
       "M1000000983    T6192,T1667,T2255,T1103,T70,T100,T20647,T1878,...\n",
       "M1000008978                                T1891,T56,T5,T39,T131\n",
       "M1000020034                                                 T597\n",
       "M1000022555                             T1440,T608,T103,T13,T103\n",
       "                                     ...                        \n",
       "M999984680     T26,T277,T76,T245,T542,T2274,T9526,T51857,T200...\n",
       "M999988985     T3259,T11393,T2231,T3928,T2229,T1814,T1257,T72...\n",
       "M999995457     T2,T488,T11088,T6248,T355,T7752,T674,T2,T22,T3...\n",
       "M999998695                      T810,T5568,T5568,T810,T5568,T810\n",
       "M999998888                       T35,T296,T4979,T3,T162,T67,T296\n",
       "Name: topic, Length: 767269, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_topic = ans[ans['topic']!='-1'].groupby('uid')['topic'].agg(','.join)  # 用户回答过的话题\n",
    "user_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(user_topic, open(f'{base_path}/user_topic.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-05 11:47:57,898] INFO in <ipython-input-9-340cfdc733a3>: invite (9489162, 3)\n",
      "[2019-12-05 11:48:00,586] INFO in <ipython-input-9-340cfdc733a3>: test (1141683, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(f'{base_path}/invite_info_0926.txt', sep='\\t', header=None)\n",
    "train.columns = ['qid', 'uid', 'dt', 'label']\n",
    "del train['dt']\n",
    "logging.info(\"invite %s\", train.shape)\n",
    "\n",
    "test = pd.read_csv(f'{base_path}/invite_info_evaluate_0926.txt', sep='\\t', header=None)\n",
    "test.columns = ['qid', 'uid', 'dt']\n",
    "del test['dt']\n",
    "logging.info(\"test %s\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, ques, on='qid', how='left')\n",
    "test = pd.merge(test, ques, on='qid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['user_topic'] = train['uid'].map(user_topic).fillna('-1')\n",
    "test['user_topic'] = test['uid'].map(user_topic).fillna('-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_table = pickle.load(open(f'{base_path}/topic_vec.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vec1, vec2):\n",
    "    return np.dot(vec1, vec2)/((np.linalg.norm(vec1)*(np.linalg.norm(vec2))))\n",
    "\n",
    "def eucl_sim(vec1, vec2):\n",
    "    return np.linalg.norm(np.array(vec1)-np.array(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_sim(q_topic, u_topic, mode):\n",
    "    n_most_common = 20\n",
    "    assert mode in ['train', 'test']\n",
    "        \n",
    "    if (q_topic == '-1') or (u_topic == '-1'):\n",
    "        return [0]*4 + [np.nan]*20\n",
    "    \n",
    "    q_topic_2 = q_topic.split(',')\n",
    "    u_topic_2 = u_topic.split(',')\n",
    "    counter = Counter(u_topic_2)\n",
    "    if mode == 'train':\n",
    "        counter = counter - Counter(q_topic_2)    # 去当前记录             \n",
    "    most_common_topic = counter.most_common(n_most_common)\n",
    "    if len(most_common_topic)== 0:         # 没有其他时期的回答\n",
    "        return [0]*4 + [np.nan]*20\n",
    "    \n",
    "    count_list = []\n",
    "    for ut_c in most_common_topic: \n",
    "        count_list.append(ut_c[1])\n",
    "    count_norm_list = np.array(list(count_list)) / np.sum(list(count_list))   # normalize\n",
    "   \n",
    "    sim_list = []                   # 两两交叉计算相似度\n",
    "    sim_norm_list = []\n",
    "    count_ut_in_qt_weighted = 0     # 问题话题在过往回答过的话题里的出现次数\n",
    "    count_ut_in_qt = 0             # 问题话题与过往回答过的话题的交集个数\n",
    "    count_norm_ut_in_qt = 0\n",
    "    \n",
    "    # 欧式距离相似度\n",
    "    sim_list_eucl = []                   # 两两交叉计算相似度\n",
    "    sim_norm_list_eucl = []\n",
    "\n",
    "    for qt in q_topic_2:\n",
    "        q_topic_index = int(qt[1:]) - 1   # q_topic 索引\n",
    "        q_topic_vec = topic_table.iloc[q_topic_index]['vec']\n",
    "        for ut_c, count, count_norm in zip(most_common_topic, count_list, count_norm_list):  \n",
    "            u_topic_index = int(ut_c[0][1:]) - 1   # u_topic 索引\n",
    "            u_topic_vec = topic_table.iloc[u_topic_index]['vec']\n",
    "            if q_topic_index == u_topic_index:\n",
    "                count_ut_in_qt_weighted += ut_c[1]\n",
    "                count_ut_in_qt += 1\n",
    "                count_norm_ut_in_qt += count_norm\n",
    "            \n",
    "            sim = cos_sim(q_topic_vec, u_topic_vec)\n",
    "            sim_norm = sim*count_norm\n",
    "            sim_eucl = eucl_sim(q_topic_vec, u_topic_vec)\n",
    "            sim_norm_eucl = sim_eucl*count_norm\n",
    "            \n",
    "            sim_list.append(sim)\n",
    "            sim_norm_list.append(sim_norm)\n",
    "            sim_list_eucl.append(sim_eucl)\n",
    "            sim_norm_list_eucl.append(sim_norm_eucl)\n",
    "            \n",
    "    \n",
    "#     print('1')\n",
    "    rate_ut_in_qt = count_ut_in_qt / len(q_topic_2)\n",
    "    \n",
    "    min_sim = np.min(sim_list)\n",
    "    max_sim = np.max(sim_list)\n",
    "    sum_sim = np.sum(sim_list)\n",
    "    mean_sim = np.mean(sim_list)\n",
    "    std_sim = np.std(sim_list)\n",
    "    \n",
    "#     print('2')\n",
    "    min_sim_norm = np.min(sim_norm_list)\n",
    "    max_sim_norm = np.max(sim_norm_list)\n",
    "    sum_sim_norm = np.sum(sim_norm_list)\n",
    "    mean_sim_norm = np.mean(sim_norm_list)\n",
    "    std_sim_norm = np.std(sim_norm_list)\n",
    "    \n",
    "    # 欧式\n",
    "#     print('3')\n",
    "    min_sim_eucl = np.min(sim_list_eucl)\n",
    "    max_sim_eucl = np.max(sim_list_eucl)\n",
    "    sum_sim_eucl = np.sum(sim_list_eucl)\n",
    "    mean_sim_eucl = np.mean(sim_list_eucl)\n",
    "    std_sim_eucl = np.std(sim_list_eucl)\n",
    "    \n",
    "#     print('4')\n",
    "    min_sim_norm_eucl = np.min(sim_norm_list_eucl)\n",
    "    max_sim_norm_eucl = np.max(sim_norm_list_eucl)\n",
    "    sum_sim_norm_eucl = np.sum(sim_norm_list_eucl)\n",
    "    mean_sim_norm_eucl = np.mean(sim_norm_list_eucl)\n",
    "    std_sim_norm_eucl = np.std(sim_norm_list_eucl)\n",
    "\n",
    "#     print('5')\n",
    "    res = [count_ut_in_qt_weighted, count_ut_in_qt, rate_ut_in_qt, count_norm_ut_in_qt]\n",
    "    res += [min_sim, max_sim, sum_sim, mean_sim, std_sim]\n",
    "    res += [min_sim_norm, max_sim_norm, sum_sim_norm, mean_sim_norm, std_sim_norm]\n",
    "    res += [min_sim_eucl, max_sim_eucl, sum_sim_eucl, mean_sim_eucl, std_sim_eucl]\n",
    "    res += [min_sim_norm_eucl, max_sim_norm_eucl, sum_sim_norm_eucl, mean_sim_norm_eucl, std_sim_norm_eucl]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 压缩数据\n",
    "def compress_data(df):\n",
    "    for col in ['qu_topic_count_weight', 'qu_topic_count']:\n",
    "        df[col] = df[col].astype('int32')\n",
    "    for col in ['qu_topic_rate', 'qu_topic_count_norm', 'min_sim', 'max_sim', 'sum_sim', 'mean_sim', \n",
    "                'std_sim', 'min_sim_norm', 'max_sim_norm', 'sum_sim_norm', 'mean_sim_norm', 'std_sim_norm',\n",
    "                'min_sim_eucl', 'max_sim_eucl', 'sum_sim_eucl', 'mean_sim_eucl', 'std_sim_eucl',\n",
    "                'min_sim_norm_eucl', 'max_sim_norm_eucl', 'sum_sim_norm_eucl', 'mean_sim_norm_eucl', 'std_sim_norm_eucl']:\n",
    "        df[col] = df[col].astype('float32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "def get_topic_feat(df, num, mode):\n",
    "    assert mode in ['train', 'test']\n",
    "    try:\n",
    "        logging.info('start to extract feature.')\n",
    "        t1 = df.apply(lambda x: get_topic_sim(x['topic'], x['user_topic'], mode), axis=1, result_type='expand')\n",
    "        t1.columns = ['qu_topic_count_weight', 'qu_topic_count', 'qu_topic_rate', 'qu_topic_count_norm',\n",
    "                  'min_sim', 'max_sim', 'sum_sim', 'mean_sim', 'std_sim', 'min_sim_norm', \n",
    "                  'max_sim_norm', 'sum_sim_norm', 'mean_sim_norm', 'std_sim_norm', \n",
    "                  'min_sim_eucl', 'max_sim_eucl', 'sum_sim_eucl', 'mean_sim_eucl', 'std_sim_eucl',\n",
    "                  'min_sim_norm_eucl', 'max_sim_norm_eucl', 'sum_sim_norm_eucl', 'mean_sim_norm_eucl', 'std_sim_norm_eucl']\n",
    "        logging.info('extracting finish.')\n",
    "        \n",
    "        # 压缩数据\n",
    "        t1 = compress_data(t1)\n",
    "        t1.to_csv(f'./temp/{mode}_topic_feature_{num}.txt', index=False, sep='\\t')\n",
    "        logging.info('file %s saving finish.', num)\n",
    "        del t1\n",
    "        gc.collect()\n",
    "    except:\n",
    "        print(traceback.print_exc())\n",
    "        \n",
    "def multi_proc(df, mode):\n",
    "    import multiprocessing\n",
    "    processes = 30\n",
    "    pool = multiprocessing.Pool(processes=processes)\n",
    "    len_data = len(df)\n",
    "    len_batch = len_data // processes\n",
    "    for i in range(processes):\n",
    "        start = i * len_batch\n",
    "        end = (i+1) * len_batch\n",
    "        if i == (processes-1):\n",
    "            end = len_data\n",
    "        tmp = df[start:end]\n",
    "        pool.apply_async(get_topic_feat, (tmp, i, mode))\n",
    "        \n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-05 15:47:53,964] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:47:54,944] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:47:56,042] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:47:58,136] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:47:58,509] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:47:59,651] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:00,633] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:01,828] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:02,657] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:03,617] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:04,707] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:05,701] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:06,873] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:07,706] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:08,663] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:09,698] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:10,694] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:11,632] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:12,367] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:13,804] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:15,038] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:15,692] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:16,791] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:17,742] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:18,711] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:19,480] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:20,623] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:21,564] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:22,339] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 15:48:23,394] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 17:06:59,408] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:07:17,968] INFO in <ipython-input-136-4de50dd160b9>: file 29 saving finish.\n",
      "[2019-12-05 17:08:48,993] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:09:06,537] INFO in <ipython-input-136-4de50dd160b9>: file 25 saving finish.\n",
      "[2019-12-05 17:09:45,487] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:10:01,121] INFO in <ipython-input-136-4de50dd160b9>: file 22 saving finish.\n",
      "[2019-12-05 17:11:33,111] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:11:42,730] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:11:47,797] INFO in <ipython-input-136-4de50dd160b9>: file 15 saving finish.\n",
      "[2019-12-05 17:11:57,486] INFO in <ipython-input-136-4de50dd160b9>: file 16 saving finish.\n",
      "[2019-12-05 17:13:02,955] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:13:18,035] INFO in <ipython-input-136-4de50dd160b9>: file 12 saving finish.\n",
      "[2019-12-05 17:13:48,858] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:14:03,338] INFO in <ipython-input-136-4de50dd160b9>: file 9 saving finish.\n",
      "[2019-12-05 17:17:15,132] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:17:29,710] INFO in <ipython-input-136-4de50dd160b9>: file 2 saving finish.\n",
      "[2019-12-05 17:17:54,456] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:18:08,773] INFO in <ipython-input-136-4de50dd160b9>: file 1 saving finish.\n",
      "[2019-12-05 17:18:48,650] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:19:03,079] INFO in <ipython-input-136-4de50dd160b9>: file 0 saving finish.\n",
      "[2019-12-05 17:28:08,827] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:28:23,486] INFO in <ipython-input-136-4de50dd160b9>: file 13 saving finish.\n",
      "[2019-12-05 17:41:56,990] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:42:11,956] INFO in <ipython-input-136-4de50dd160b9>: file 26 saving finish.\n",
      "[2019-12-05 17:43:03,176] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:43:17,646] INFO in <ipython-input-136-4de50dd160b9>: file 21 saving finish.\n",
      "[2019-12-05 17:45:05,469] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:45:20,194] INFO in <ipython-input-136-4de50dd160b9>: file 19 saving finish.\n",
      "[2019-12-05 17:45:48,330] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:46:02,787] INFO in <ipython-input-136-4de50dd160b9>: file 20 saving finish.\n",
      "[2019-12-05 17:46:05,223] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:46:19,530] INFO in <ipython-input-136-4de50dd160b9>: file 11 saving finish.\n",
      "[2019-12-05 17:48:12,712] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:48:27,108] INFO in <ipython-input-136-4de50dd160b9>: file 7 saving finish.\n",
      "[2019-12-05 17:56:37,332] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:56:51,691] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:56:52,019] INFO in <ipython-input-136-4de50dd160b9>: file 3 saving finish.\n",
      "[2019-12-05 17:57:06,538] INFO in <ipython-input-136-4de50dd160b9>: file 27 saving finish.\n",
      "[2019-12-05 17:57:59,502] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:58:13,809] INFO in <ipython-input-136-4de50dd160b9>: file 28 saving finish.\n",
      "[2019-12-05 17:58:30,726] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:58:45,121] INFO in <ipython-input-136-4de50dd160b9>: file 24 saving finish.\n",
      "[2019-12-05 17:58:54,893] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 17:59:09,217] INFO in <ipython-input-136-4de50dd160b9>: file 4 saving finish.\n",
      "[2019-12-05 18:02:54,306] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:03:00,848] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:03:07,420] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:03:09,334] INFO in <ipython-input-136-4de50dd160b9>: file 23 saving finish.\n",
      "[2019-12-05 18:03:15,202] INFO in <ipython-input-136-4de50dd160b9>: file 10 saving finish.\n",
      "[2019-12-05 18:03:22,279] INFO in <ipython-input-136-4de50dd160b9>: file 18 saving finish.\n",
      "[2019-12-05 18:04:03,230] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:04:18,597] INFO in <ipython-input-136-4de50dd160b9>: file 17 saving finish.\n",
      "[2019-12-05 18:04:40,120] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:04:54,529] INFO in <ipython-input-136-4de50dd160b9>: file 14 saving finish.\n",
      "[2019-12-05 18:05:15,593] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:05:29,263] INFO in <ipython-input-136-4de50dd160b9>: file 8 saving finish.\n",
      "[2019-12-05 18:06:24,457] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:06:36,363] INFO in <ipython-input-136-4de50dd160b9>: file 5 saving finish.\n",
      "[2019-12-05 18:07:08,296] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:07:22,697] INFO in <ipython-input-136-4de50dd160b9>: file 6 saving finish.\n",
      "[2019-12-05 18:07:33,525] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-05 18:07:33,752] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:33,828] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:33,951] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:34,128] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:34,424] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:34,658] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:34,795] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:35,169] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:35,409] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:35,610] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:35,885] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:36,016] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:36,196] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:36,408] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:36,544] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:36,695] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:36,801] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:36,944] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:37,096] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:37,400] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:37,666] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:37,944] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:38,134] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:38,233] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:38,482] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:38,588] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:38,724] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:38,934] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:07:39,095] INFO in <ipython-input-136-4de50dd160b9>: start to extract feature.\n",
      "[2019-12-05 18:16:45,693] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:16:47,691] INFO in <ipython-input-136-4de50dd160b9>: file 27 saving finish.\n",
      "[2019-12-05 18:16:57,065] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:16:58,917] INFO in <ipython-input-136-4de50dd160b9>: file 24 saving finish.\n",
      "[2019-12-05 18:17:03,434] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:17:05,195] INFO in <ipython-input-136-4de50dd160b9>: file 18 saving finish.\n",
      "[2019-12-05 18:17:31,150] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:17:32,852] INFO in <ipython-input-136-4de50dd160b9>: file 7 saving finish.\n",
      "[2019-12-05 18:17:40,610] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:17:42,392] INFO in <ipython-input-136-4de50dd160b9>: file 8 saving finish.\n",
      "[2019-12-05 18:17:52,619] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:17:54,339] INFO in <ipython-input-136-4de50dd160b9>: file 2 saving finish.\n",
      "[2019-12-05 18:17:54,561] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:17:56,341] INFO in <ipython-input-136-4de50dd160b9>: file 1 saving finish.\n",
      "[2019-12-05 18:18:39,366] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:18:41,043] INFO in <ipython-input-136-4de50dd160b9>: file 14 saving finish.\n",
      "[2019-12-05 18:19:46,385] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:19:48,055] INFO in <ipython-input-136-4de50dd160b9>: file 5 saving finish.\n",
      "[2019-12-05 18:21:00,340] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:21:01,581] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:21:02,020] INFO in <ipython-input-136-4de50dd160b9>: file 19 saving finish.\n",
      "[2019-12-05 18:21:03,283] INFO in <ipython-input-136-4de50dd160b9>: file 20 saving finish.\n",
      "[2019-12-05 18:21:10,290] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:21:11,960] INFO in <ipython-input-136-4de50dd160b9>: file 15 saving finish.\n",
      "[2019-12-05 18:21:19,151] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:21:20,848] INFO in <ipython-input-136-4de50dd160b9>: file 29 saving finish.\n",
      "[2019-12-05 18:21:50,347] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:21:52,002] INFO in <ipython-input-136-4de50dd160b9>: file 10 saving finish.\n",
      "[2019-12-05 18:21:52,972] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:21:54,650] INFO in <ipython-input-136-4de50dd160b9>: file 11 saving finish.\n",
      "[2019-12-05 18:22:15,952] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:22:17,655] INFO in <ipython-input-136-4de50dd160b9>: file 28 saving finish.\n",
      "[2019-12-05 18:22:21,749] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:22:23,429] INFO in <ipython-input-136-4de50dd160b9>: file 22 saving finish.\n",
      "[2019-12-05 18:22:35,510] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:22:37,180] INFO in <ipython-input-136-4de50dd160b9>: file 26 saving finish.\n",
      "[2019-12-05 18:22:39,556] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:22:40,783] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:22:41,258] INFO in <ipython-input-136-4de50dd160b9>: file 16 saving finish.\n",
      "[2019-12-05 18:22:42,468] INFO in <ipython-input-136-4de50dd160b9>: file 3 saving finish.\n",
      "[2019-12-05 18:22:47,085] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:22:48,801] INFO in <ipython-input-136-4de50dd160b9>: file 25 saving finish.\n",
      "[2019-12-05 18:22:49,543] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:22:51,229] INFO in <ipython-input-136-4de50dd160b9>: file 23 saving finish.\n",
      "[2019-12-05 18:22:52,409] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:22:54,094] INFO in <ipython-input-136-4de50dd160b9>: file 9 saving finish.\n",
      "[2019-12-05 18:23:04,707] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:23:06,432] INFO in <ipython-input-136-4de50dd160b9>: file 21 saving finish.\n",
      "[2019-12-05 18:23:15,362] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:23:17,009] INFO in <ipython-input-136-4de50dd160b9>: file 6 saving finish.\n",
      "[2019-12-05 18:23:19,928] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:23:21,613] INFO in <ipython-input-136-4de50dd160b9>: file 0 saving finish.\n",
      "[2019-12-05 18:23:23,120] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:23:23,749] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:23:24,823] INFO in <ipython-input-136-4de50dd160b9>: file 13 saving finish.\n",
      "[2019-12-05 18:23:25,495] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:23:25,858] INFO in <ipython-input-136-4de50dd160b9>: file 12 saving finish.\n",
      "[2019-12-05 18:23:27,407] INFO in <ipython-input-136-4de50dd160b9>: file 17 saving finish.\n",
      "[2019-12-05 18:23:36,690] INFO in <ipython-input-136-4de50dd160b9>: extracting finish.\n",
      "[2019-12-05 18:23:38,391] INFO in <ipython-input-136-4de50dd160b9>: file 4 saving finish.\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "multi_proc(train, 'train')\n",
    "multi_proc(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合数据\n",
    "\n",
    "# train\n",
    "topic_feat = None\n",
    "original_path = './temp'\n",
    "mode = 'train'\n",
    "for i in range(30):\n",
    "    d = pd.read_csv(f'{original_path}/{mode}_topic_feature_{i}.txt', sep='\\t')\n",
    "    if topic_feat is None:\n",
    "        topic_feat = d\n",
    "    else:\n",
    "        topic_feat = pd.concat([topic_feat, d], axis=0, ignore_index=True)\n",
    "logging.info('%s topic feature, shape: %s', mode, topic_feat.shape)\n",
    "\n",
    "topic_feat = compress_data(topic_feat)\n",
    "topic_feat.to_csv(f'{feature_path}/{mode}_topic_feature.txt', index=False, sep='\\t')\n",
    "logging.info('%s topic feature saved.', mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-06 02:50:54,874] INFO in <ipython-input-174-3290fe81e121>: test topic feature, shape: (1141683, 24)\n",
      "[2019-12-06 02:52:34,053] INFO in <ipython-input-174-3290fe81e121>: test topic feature saved.\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "topic_feat = None\n",
    "original_path = './temp'\n",
    "mode = 'test'\n",
    "for i in range(30):\n",
    "    d = pd.read_csv(f'{original_path}/{mode}_topic_feature_{i}.txt', sep='\\t')\n",
    "    if topic_feat is None:\n",
    "        topic_feat = d\n",
    "    else:\n",
    "        topic_feat = pd.concat([topic_feat, d], axis=0, ignore_index=True)\n",
    "        \n",
    "logging.info('%s topic feature, shape: %s', mode, topic_feat.shape)\n",
    "\n",
    "topic_feat = compress_data(topic_feat)\n",
    "topic_feat.to_csv(f'{feature_path}/{mode}_topic_feature.txt', index=False, sep='\\t')\n",
    "logging.info('%s topic feature saved.', mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 出了点小问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_topic_feat_16(df, num, mode):\n",
    "#     assert mode in ['train', 'test']\n",
    "#     try:\n",
    "#         logging.info('start to extract feature.')\n",
    "#         t1 = df.apply(lambda x: get_topic_sim(x['topic'], x['user_topic'], mode), axis=1, result_type='expand')\n",
    "#         t1.columns = ['qu_topic_count_weight', 'qu_topic_count', 'qu_topic_rate', 'qu_topic_count_norm',\n",
    "#                   'min_sim', 'max_sim', 'sum_sim', 'mean_sim', 'std_sim', 'min_sim_norm', \n",
    "#                   'max_sim_norm', 'sum_sim_norm', 'mean_sim_norm', 'std_sim_norm', \n",
    "#                   'min_sim_eucl', 'max_sim_eucl', 'sum_sim_eucl', 'mean_sim_eucl', 'std_sim_eucl',\n",
    "#                   'min_sim_norm_eucl', 'max_sim_norm_eucl', 'sum_sim_norm_eucl', 'mean_sim_norm_eucl', 'std_sim_norm_eucl']\n",
    "#         logging.info('extracting finish.')\n",
    "        \n",
    "#         # 压缩数据\n",
    "#         for col in ['qu_topic_count_weight', 'qu_topic_count']:\n",
    "#             t1[col] = t1[col].astype('int32')\n",
    "#         for col in ['qu_topic_rate', 'qu_topic_count_norm', 'min_sim', 'max_sim', 'sum_sim', 'mean_sim', \n",
    "#                     'std_sim', 'min_sim_norm', 'max_sim_norm', 'sum_sim_norm', 'mean_sim_norm', 'std_sim_norm',\n",
    "#                     'min_sim_eucl', 'max_sim_eucl', 'sum_sim_eucl', 'mean_sim_eucl', 'std_sim_eucl',\n",
    "#                     'min_sim_norm_eucl', 'max_sim_norm_eucl', 'sum_sim_norm_eucl', 'mean_sim_norm_eucl', 'std_sim_norm_eucl']:\n",
    "#             t1[col] = t1[col].astype('float32')\n",
    "#         t1.to_csv(f'./temp2/{mode}_topic_feature_16_{num}.txt', index=False, sep='\\t')\n",
    "#         logging.info('file %s saving finish.', num)\n",
    "#         del t1\n",
    "#         gc.collect()\n",
    "#     except:\n",
    "#         print(traceback.print_exc())\n",
    "        \n",
    "# def multi_proc_16(df, mode):\n",
    "#     import multiprocessing\n",
    "#     processes = 30\n",
    "#     pool = multiprocessing.Pool(processes=processes)\n",
    "#     len_data = len(df)\n",
    "#     len_batch = len_data // processes\n",
    "#     for i in range(processes):\n",
    "#         start = i * len_batch\n",
    "#         end = (i+1) * len_batch\n",
    "#         if i == (processes-1):\n",
    "#             end = len_data\n",
    "#         tmp = df[start:end]\n",
    "#         pool.apply_async(get_topic_feat_16, (tmp, i, mode))\n",
    "        \n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "\n",
    "# len_batch_origin = len(train)//30\n",
    "# multi_proc_16(train[(16*len_batch_origin):(17*len_batch_origin)], 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_feat = None\n",
    "# original_path = './temp2'\n",
    "# for i in range(30):\n",
    "# #     d = pd.read_csv(f'{original_path}/train_topic_feature_{i}.txt', sep='\\t')\n",
    "#     d = pd.read_csv(f'{original_path}/train_topic_feature_16_{i}.txt', sep='\\t')\n",
    "#     if topic_feat is None:\n",
    "#         topic_feat = d\n",
    "#     else:\n",
    "#         topic_feat = pd.concat([topic_feat, d], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 压缩数据\n",
    "# for col in ['qu_topic_count_weight', 'qu_topic_count']:\n",
    "#     topic_feat[col] = topic_feat[col].astype('int32')\n",
    "# for col in ['qu_topic_rate', 'qu_topic_count_norm', 'min_sim', 'max_sim', 'sum_sim', 'mean_sim', \n",
    "#             'std_sim', 'min_sim_norm', 'max_sim_norm', 'sum_sim_norm', 'mean_sim_norm', 'std_sim_norm',\n",
    "#             'min_sim_eucl', 'max_sim_eucl', 'sum_sim_eucl', 'mean_sim_eucl', 'std_sim_eucl',\n",
    "#             'min_sim_norm_eucl', 'max_sim_norm_eucl', 'sum_sim_norm_eucl', 'mean_sim_norm_eucl', 'std_sim_norm_eucl']:\n",
    "#     topic_feat[col] = topic_feat[col].astype('float32')\n",
    "# topic_feat.to_csv(f'./temp/train_topic_feature_16.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
