{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fmt = \"[%(asctime)s] %(levelname)s in %(module)s: %(message)s\"\n",
    "logging.basicConfig(format=log_fmt, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data'\n",
    "feature_path = './feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-30 17:28:13,194] INFO in <ipython-input-5-f5fcce844f4e>: invite (9489162, 3)\n",
      "[2019-11-30 17:28:14,751] INFO in <ipython-input-5-f5fcce844f4e>: test (1141683, 2)\n"
     ]
    }
   ],
   "source": [
    "# 加载邀请回答数据\n",
    "train = pd.read_csv(f'{base_path}/invite_info_0926.txt', sep='\\t', header=None)\n",
    "train.columns = ['qid', 'uid', 'dt', 'label']\n",
    "del train['dt']\n",
    "logging.info(\"invite %s\", train.shape)\n",
    "\n",
    "test = pd.read_csv(f'{base_path}/invite_info_evaluate_0926.txt', sep='\\t', header=None)\n",
    "test.columns = ['qid', 'uid', 'dt']\n",
    "sub = test.copy()\n",
    "sub_size = len(sub)\n",
    "del test['dt']\n",
    "logging.info(\"test %s\", test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 加载 kfold feature\n",
    "t1 = pd.read_csv(f'{feature_path}/train_kfold_feature.txt', sep='\\t')\n",
    "train = pd.concat([train, t1], axis=1)\n",
    "\n",
    "t1 = pd.read_csv(f'{feature_path}/test_kfold_feature.txt', sep='\\t')\n",
    "test = pd.concat([test, t1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 user 过去两个月的回答统计特征（除当条记录）\n",
    "t1 = pd.read_csv(f'{feature_path}/train_ua_feature.txt', sep='\\t')\n",
    "train = pd.concat([train, t1], axis=1)\n",
    "\n",
    "t1 = pd.read_csv(f'{feature_path}/test_ua_feature.txt', sep='\\t')\n",
    "test = pd.concat([test, t1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qid', 'uid', 'label', 'day', 'hour', 'q_inv_kfold_mean',\n",
       "       'q_inv_kfold_sum', 'q_inv_kfold_std', 'q_inv_kfold_count',\n",
       "       'u_inv_kfold_mean',\n",
       "       ...\n",
       "       'u_mean_reci_cheer', 'u_mean_reci_uncheer', 'u_mean_reci_comment',\n",
       "       'u_mean_reci_mark', 'u_mean_reci_tks', 'u_mean_reci_xxx',\n",
       "       'u_mean_reci_no_help', 'u_mean_reci_dis', 'u_mean_diff_qa_days',\n",
       "       'u_mean_diff_qa_hours'],\n",
       "      dtype='object', length=138)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-30 17:32:07,330] INFO in <ipython-input-10-af285af762e4>: user (1931654, 14)\n",
      "[2019-11-30 17:32:10,721] INFO in <ipython-input-10-af285af762e4>: user unq uid       1931654\n",
      "gender          3\n",
      "freq            5\n",
      "uf_b1           2\n",
      "uf_b2           2\n",
      "uf_b3           2\n",
      "uf_b4           2\n",
      "uf_b5           2\n",
      "uf_c1        2561\n",
      "uf_c2         291\n",
      "uf_c3         428\n",
      "uf_c4        1556\n",
      "uf_c5           2\n",
      "score         732\n",
      "dtype: int64\n",
      "[2019-11-30 17:32:10,727] INFO in <ipython-input-10-af285af762e4>: user cat ['gender', 'freq', 'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5']\n",
      "[2019-11-30 17:32:11,621] INFO in <ipython-input-10-af285af762e4>: encode gender\n",
      "[2019-11-30 17:32:12,491] INFO in <ipython-input-10-af285af762e4>: encode freq\n",
      "[2019-11-30 17:32:13,335] INFO in <ipython-input-10-af285af762e4>: encode uf_c1\n",
      "[2019-11-30 17:32:14,159] INFO in <ipython-input-10-af285af762e4>: encode uf_c2\n",
      "[2019-11-30 17:32:14,960] INFO in <ipython-input-10-af285af762e4>: encode uf_c3\n",
      "[2019-11-30 17:32:15,754] INFO in <ipython-input-10-af285af762e4>: encode uf_c4\n",
      "[2019-11-30 17:32:16,542] INFO in <ipython-input-10-af285af762e4>: encode uf_c5\n",
      "[2019-11-30 17:33:11,628] INFO in <ipython-input-10-af285af762e4>: train shape (9489162, 153), test shape (1141683, 152)\n"
     ]
    }
   ],
   "source": [
    "# 加载用户\n",
    "user = pd.read_csv(f'{base_path}/member_info_0926.txt', header=None, sep='\\t')\n",
    "user.columns = ['uid', 'gender', 'freq',\n",
    "                'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "                'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5', \n",
    "                'score', 'follow_topic', 'inter_topic']\n",
    "\n",
    "del user['follow_topic'], user['inter_topic']\n",
    "logging.info(\"user %s\", user.shape)\n",
    "\n",
    "unq = user.nunique()\n",
    "logging.info(\"user unq %s\", unq)\n",
    "\n",
    "for x in unq[unq == 1].index:\n",
    "    del user[x]\n",
    "    logging.info('del unq==1 %s', x)\n",
    "\n",
    "t = user.dtypes\n",
    "cats = [x for x in t[t == 'object'].index if x not in ['follow_topic', 'inter_topic', 'uid']]\n",
    "logging.info(\"user cat %s\", cats)\n",
    "\n",
    "for d in cats:\n",
    "    lb = LabelEncoder()\n",
    "    user[d] = lb.fit_transform(user[d])\n",
    "    logging.info('encode %s', d)\n",
    "    \n",
    "q_lb = LabelEncoder()\n",
    "q_lb.fit(list(train['qid'].astype(str).values) + list(test['qid'].astype(str).values))\n",
    "train['qid_enc'] = q_lb.transform(train['qid'])\n",
    "test['qid_enc'] = q_lb.transform(test['qid'])\n",
    "\n",
    "u_lb = LabelEncoder()\n",
    "u_lb.fit(user['uid'])\n",
    "train['uid_enc'] = u_lb.transform(train['uid'])\n",
    "test['uid_enc'] = u_lb.transform(test['uid'])\n",
    "\n",
    "# merge user\n",
    "train = pd.merge(train, user, on='uid', how='left')\n",
    "test = pd.merge(test, user, on='uid', how='left')\n",
    "logging.info(\"train shape %s, test shape %s\", train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qid', 'uid', 'label', 'day', 'hour', 'q_inv_kfold_mean',\n",
       "       'q_inv_kfold_sum', 'q_inv_kfold_std', 'q_inv_kfold_count',\n",
       "       'u_inv_kfold_mean',\n",
       "       ...\n",
       "       'uf_b2', 'uf_b3', 'uf_b4', 'uf_b5', 'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4',\n",
       "       'uf_c5', 'score'],\n",
       "      dtype='object', length=153)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qid', 'uid', 'day', 'hour', 'q_inv_kfold_mean', 'q_inv_kfold_sum',\n",
       "       'q_inv_kfold_std', 'q_inv_kfold_count', 'u_inv_kfold_mean',\n",
       "       'u_inv_kfold_sum',\n",
       "       ...\n",
       "       'uf_b2', 'uf_b3', 'uf_b4', 'uf_b5', 'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4',\n",
       "       'uf_c5', 'score'],\n",
       "      dtype='object', length=152)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((train, test), axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count编码\n",
    "count_fea = ['uid_enc', 'qid_enc', 'gender', 'freq', 'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5']\n",
    "for feat in count_fea:\n",
    "    col_name = '{}_count'.format(feat)\n",
    "    data[col_name] = data[feat].map(data[feat].value_counts().astype(int))\n",
    "    data.loc[data[col_name] < 2, feat] = -1\n",
    "    data[feat] += 1\n",
    "    data[col_name] = data[feat].map(data[feat].value_counts().astype(int))\n",
    "    data[col_name] = (data[col_name] - data[col_name].min()) / (data[col_name].max() - data[col_name].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['wk'] = data['day'] % 7\n",
    "# 选特征\n",
    "# feature_cols = [x for x in data.columns if x not in ('label', 'uid', 'qid', 'dt', 'day')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feat = ('label', 'uid', 'qid', 'dt', 'day') \n",
    "# drop_feat += ('q_ans_kfold_count', 'q_diff_qa_days_max', 'q_diff_qa_days_mean', 'q_diff_qa_days_sum', \n",
    "#               'q_has_img_max', 'q_has_img_mean', 'q_has_img_sum', 'q_has_video_max', 'q_has_video_mean', \n",
    "#               'q_has_video_sum','q_is_dest_max', 'q_is_dest_mean', 'q_is_dest_sum', 'q_is_good_max', \n",
    "#               'q_is_good_mean', 'q_is_good_sum', 'q_is_rec_max', 'q_is_rec_mean', 'q_is_rec_sum', \n",
    "#               'q_reci_cheer_max', 'q_reci_cheer_mean', 'q_reci_cheer_sum', 'q_reci_comment_max', \n",
    "#               'q_reci_comment_mean', 'q_reci_comment_sum', 'q_reci_dis_max', 'q_reci_dis_mean', \n",
    "#               'q_reci_dis_sum', 'q_reci_mark_max', 'q_reci_mark_mean', 'q_reci_mark_sum', 'q_reci_no_help_max',\n",
    "#               'q_reci_no_help_mean', 'q_reci_no_help_sum', 'q_reci_tks_max', 'q_reci_tks_mean', \n",
    "#               'q_reci_tks_sum', 'q_reci_uncheer_max', 'q_reci_uncheer_mean', 'q_reci_uncheer_sum', \n",
    "#               'q_reci_xxx_max', 'q_reci_xxx_mean', 'q_reci_xxx_sum', 'q_word_count_max', 'q_word_count_mean', \n",
    "#               'q_word_count_sum')\n",
    "# drop_feat += ('u_ans_kfold_count', 'u_diff_qa_days_max', 'u_diff_qa_days_mean', 'u_diff_qa_days_sum', \n",
    "#               'u_has_img_max', 'u_has_img_mean', 'u_has_img_sum', 'u_has_video_max', 'u_has_video_mean', \n",
    "#               'u_has_video_sum', 'u_is_dest_max', 'u_is_dest_mean', 'u_is_dest_sum', 'u_is_good_max', \n",
    "#               'u_is_good_mean', 'u_is_good_sum', 'u_is_rec_max', 'u_is_rec_mean', 'u_is_rec_sum', 'u_reci_cheer_max', \n",
    "#               'u_reci_cheer_mean', 'u_reci_cheer_sum', 'u_reci_comment_max', 'u_reci_comment_mean',\n",
    "#               'u_reci_comment_sum', 'u_reci_dis_max', 'u_reci_dis_mean', 'u_reci_dis_sum', 'u_reci_mark_max', \n",
    "#               'u_reci_mark_mean', 'u_reci_mark_sum', 'u_reci_no_help_max', 'u_reci_no_help_mean', \n",
    "#               'u_reci_no_help_sum', 'u_reci_tks_max', 'u_reci_tks_mean', 'u_reci_tks_sum', 'u_reci_uncheer_max', \n",
    "#               'u_reci_uncheer_mean', 'u_reci_uncheer_sum', 'u_reci_xxx_max', 'u_reci_xxx_mean', 'u_reci_xxx_sum', \n",
    "#               'u_word_count_max', 'u_word_count_mean', 'u_word_count_sum')\n",
    "feature_cols = [x for x in data.columns if x not in drop_feat]\n",
    "# feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-30 17:35:40,160] INFO in <ipython-input-17-20ad4e7d53e4>: feature size 159\n",
      "[2019-11-30 17:36:05,780] INFO in <ipython-input-17-20ad4e7d53e4>: train shape (9489162, 153), test shape (1141683, 152)\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"feature size %s\", len(feature_cols))\n",
    "\n",
    "X_train_all = data.iloc[:len(train)][feature_cols]\n",
    "y_train_all = data.iloc[:len(train)]['label']\n",
    "X_test = data.iloc[len(train):]\n",
    "assert len(X_test) == sub_size\n",
    "\n",
    "logging.info(\"train shape %s, test shape %s\", train.shape, test.shape)\n",
    "\n",
    "fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for index, (train_idx, val_idx) in enumerate(fold.split(X=X_train_all, y=y_train_all)):\n",
    "    break\n",
    "\n",
    "X_train, X_val, y_train, y_val = X_train_all.iloc[train_idx][feature_cols], X_train_all.iloc[val_idx][feature_cols], \\\n",
    "                                 y_train_all.iloc[train_idx], \\\n",
    "                                 y_train_all.iloc[val_idx]\n",
    "del X_train_all\n",
    "\n",
    "model_lgb = LGBMClassifier(n_estimators=2000, n_jobs=-1, objective='binary', seed=1000, silent=True)\n",
    "model_lgb.fit(X_train, y_train,\n",
    "              eval_metric=['logloss', 'auc'],\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              early_stopping_rounds=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.read_csv(f'{base_path}/invite_info_evaluate_0926.txt', sep='\\t', header=None)\n",
    "# sub.columns = ['qid', 'uid', 'dt']\n",
    "sub['label'] = model_lgb.predict_proba(X_test[feature_cols])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./result/2000_add_ua.txt', index=None, header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'feature': feature_cols, 'imp': model_lgb.feature_importances_})\n",
    "fi['rate'] = fi['imp'] / fi['imp'].sum()\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi.sort_values(by='rate', ascending=False)[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
