{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import logging\n",
    "import multiprocessing\n",
    "import traceback\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fmt = \"[%(asctime)s] %(levelname)s in %(module)s: %(message)s\"\n",
    "logging.basicConfig(format=log_fmt, level=logging.INFO)\n",
    "\n",
    "base_path = './data'\n",
    "feature_path = './feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-13 03:57:14,028] INFO in <ipython-input-6-af34e33feb4f>: invite (9489162, 4)\n",
      "[2019-12-13 03:57:16,421] INFO in <ipython-input-6-af34e33feb4f>: test (1141683, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(f'{base_path}/invite_info_0926.txt', sep='\\t', header=None)\n",
    "train.columns = ['qid', 'uid', 'dt', 'label']\n",
    "logging.info(\"invite %s\", train.shape)\n",
    "\n",
    "test = pd.read_csv(f'{base_path}/invite_info_evaluate_0926.txt', sep='\\t', header=None)\n",
    "test.columns = ['qid', 'uid', 'dt']\n",
    "logging.info(\"test %s\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_day(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[0][1:]))\n",
    "\n",
    "\n",
    "def extract_hour(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[1][1:]))\n",
    "\n",
    "train['day'] = extract_day(train['dt'])\n",
    "train['week'] = train['day'] % 7\n",
    "train['hour'] = extract_hour(train['dt'])\n",
    "\n",
    "test['day'] = extract_day(test['dt'])\n",
    "test['week'] = test['day'] % 7\n",
    "test['hour'] = extract_hour(test['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-13 03:58:47,459] INFO in <ipython-input-8-5451e5d8303c>: user (1931654, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载用户\n",
    "user = pd.read_csv(f'{base_path}/member_info_0926.txt', header=None, sep='\\t')\n",
    "user.columns = ['uid', 'gender', 'freq', 'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "                'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5',  'score', 'follow_topic', 'inter_topic']\n",
    "del user['follow_topic'], user['inter_topic']\n",
    "logging.info(\"user %s\", user.shape)\n",
    "\n",
    "# merge user\n",
    "train = pd.merge(train, user, on='uid', how='left')\n",
    "test = pd.merge(test, user, on='uid', how='left')\n",
    "\n",
    "del user\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-13 04:00:00,995] INFO in <ipython-input-9-56a30ffdc19b>: ques (1829900, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载问题\n",
    "ques = pd.read_csv(f'{base_path}/question_info_0926.txt', header=None, sep='\\t')\n",
    "ques.columns = ['qid', 'q_dt', 'title_t1', 'title_t2', 'desc_t1', 'desc_t2', 'topic']\n",
    "del ques['title_t1'], ques['title_t2'], ques['desc_t1'], ques['desc_t2'], ques['topic']\n",
    "logging.info(\"ques %s\", ques.shape)\n",
    "\n",
    "ques['q_day'] = extract_day(ques['q_dt'])\n",
    "ques['q_hour'] = extract_hour(ques['q_dt'])\n",
    "ques['q_week'] = ques['q_day'] % 7\n",
    "\n",
    "del ques['q_dt']\n",
    "\n",
    "# merge ques\n",
    "train = pd.merge(train, ques, on='qid', how='left')\n",
    "test = pd.merge(test, ques, on='qid', how='left')\n",
    "\n",
    "del ques\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['diff_iq_day'] = train['day'] - train['q_day']\n",
    "train['diff_iq_hour'] = train['diff_iq_day'] * 24 + (train['hour'] - train['q_hour'])\n",
    "\n",
    "test['diff_iq_day'] = test['day'] - test['q_day']\n",
    "test['diff_iq_hour'] = test['diff_iq_day'] * 24 + (test['hour'] - test['q_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_iq_day_map(x):\n",
    "    if x>=31:\n",
    "        return 31\n",
    "    if x<0:\n",
    "        return 0\n",
    "    return x\n",
    "\n",
    "train['diff_iq_day'] = train['diff_iq_day'].apply(diff_iq_day_map)\n",
    "test['diff_iq_day'] = test['diff_iq_day'].apply(diff_iq_day_map)\n",
    "\n",
    "def diff_iq_hour_map(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    if x>200:\n",
    "        return 40\n",
    "    return x // 5\n",
    "\n",
    "train['diff_iq_hour'] = train['diff_iq_hour'].apply(diff_iq_hour_map)\n",
    "test['diff_iq_hour'] = test['diff_iq_hour'].apply(diff_iq_hour_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_map(x):\n",
    "    if x<=280:\n",
    "        return -1\n",
    "    if x<=300:\n",
    "        return 0\n",
    "    if 300<x<=350:\n",
    "        return 1\n",
    "    if 350<x<=400:\n",
    "        return 2\n",
    "    if 400<x<=500:\n",
    "        return 3\n",
    "    if 500<x<=600:\n",
    "        return 4\n",
    "    if 600<x<=700:\n",
    "        return 5\n",
    "    if 700<x<=800:\n",
    "        return 6\n",
    "    return 7\n",
    "\n",
    "train['score'] = train['score'].apply(score_map)\n",
    "test['score'] = test['score'].apply(score_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 invete feature 2: intersection_ft_count, intersection_it_count\n",
    "t1 = pd.read_csv(f'{feature_path}/train_invite_feature_2.txt', sep='\\t', \n",
    "                 usecols=['intersection_ft_count', 'intersection_it_count'])\n",
    "train = pd.concat([train, t1], axis=1)\n",
    "\n",
    "t1 = pd.read_csv(f'{feature_path}/test_invite_feature_2.txt', sep='\\t', \n",
    "                 usecols=['intersection_ft_count', 'intersection_it_count'])\n",
    "test = pd.concat([test, t1], axis=1)\n",
    "\n",
    "# 划分 intersection_ft_count\n",
    "def to_bin_1(x):\n",
    "    if x>=3:\n",
    "        return 3\n",
    "    return x\n",
    "\n",
    "train['intersection_ft_count'] = train['intersection_ft_count'].apply(to_bin_1)\n",
    "test['intersection_ft_count'] = test['intersection_ft_count'].apply(to_bin_1)\n",
    "\n",
    "# 划分 intersection_it_count\n",
    "def to_bin_2(x):\n",
    "    if x>=4:\n",
    "        return 4\n",
    "    return x\n",
    "\n",
    "train['intersection_it_count'] = train['intersection_it_count'].apply(to_bin_2)\n",
    "test['intersection_it_count'] = test['intersection_it_count'].apply(to_bin_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 kfold topic feature, QU\n",
    "t1 = pd.read_csv(f'./feature/train_kfold_topic_feature.txt', sep='\\t', \n",
    "                 usecols=['qu_topic_count_weight', 'qu_topic_count'])\n",
    "train = pd.concat([train, t1], axis=1)\n",
    "\n",
    "t1 = pd.read_csv(f'./feature/test_kfold_topic_feature.txt', sep='\\t', \n",
    "                 usecols=['qu_topic_count_weight', 'qu_topic_count'])\n",
    "test = pd.concat([test, t1], axis=1)\n",
    "\n",
    "def qu_weight_map(x):\n",
    "    if x<=2:\n",
    "        return x\n",
    "    if x<=4:\n",
    "        return x\n",
    "    for i in range(1, 16):\n",
    "        if x<=4+5*i:\n",
    "            return 4+i\n",
    "    return 20\n",
    "train['qu_topic_count_weight'] = train['qu_topic_count_weight'].apply(qu_weight_map)\n",
    "test['qu_topic_count_weight'] = test['qu_topic_count_weight'].apply(qu_weight_map)\n",
    "\n",
    "def qu_count_map(x):\n",
    "    if x>=6:\n",
    "        return 5\n",
    "    return x\n",
    "train['qu_topic_count'] = train['qu_topic_count'].apply(qu_count_map)\n",
    "test['qu_topic_count'] = test['qu_topic_count'].apply(qu_count_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4折统计\n",
    "def fold_fn(x):\n",
    "    if 3838<=x<=3846:\n",
    "        return 0\n",
    "    if 3847<=x<=3853:\n",
    "        return 1\n",
    "    if 3854<=x<=3860:\n",
    "        return 2\n",
    "    if 3861<=x<=3867:\n",
    "        return 3\n",
    "    \n",
    "train['fold'] = train['day'].apply(fold_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qid', 'uid', 'dt', 'label', 'day', 'week', 'hour', 'gender', 'freq',\n",
       "       'uf_b1', 'uf_b2', 'uf_b3', 'uf_b4', 'uf_b5', 'uf_c1', 'uf_c2', 'uf_c3',\n",
       "       'uf_c4', 'uf_c5', 'score', 'q_day', 'q_hour', 'q_week', 'diff_iq_day',\n",
       "       'diff_iq_hour', 'intersection_ft_count', 'intersection_it_count',\n",
       "       'qu_topic_count_weight', 'qu_topic_count', 'fold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 当天基础统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集上当天统计\n",
    "def day_stat(train_df, f):\n",
    "    logging.info('day answer stat on: %s', f)\n",
    "    extract_feat = f + '_day_labelrate'\n",
    "    t1 = train_df.groupby([f,'day'], as_index=False)['label'].agg({\n",
    "        extract_feat: 'mean',\n",
    "    })\n",
    "    res = pd.merge(train_df, t1, on=[f,'day'], how='left')\n",
    "    return res[extract_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_feat = ['uid', 'qid', 'freq', 'gender', 'score', 'week', 'hour', \n",
    "               'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "               'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5',\n",
    "               'diff_iq_day', 'diff_iq_hour', \n",
    "               'intersection_ft_count', 'intersection_it_count']\n",
    "# single_feat = ['diff_iq_hour']\n",
    "for feat in single_feat:\n",
    "    t1 = day_stat(train, feat)\n",
    "    logging.info('stat on %s by day, extract finished. shape: %s', feat, t1.shape)\n",
    "    # 压缩数据\n",
    "    t1 = t1.astype('float32')\n",
    "    \n",
    "    pickle.dump(t1, open(f'./temp_label_feat/{feat}_day.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kfold 一阶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_1order_label_stat(train_df, test_df, single_feat_list):\n",
    "    t1 = train_df.copy()\n",
    "    t2 = test_df.copy()\n",
    "    \n",
    "    extract_feat = []\n",
    "    \n",
    "    # train\n",
    "    for fold_ in range(4):\n",
    "        logging.info('in train, fold: %s', fold_)\n",
    "        log_df = train_df[train_df['fold']!=fold_]\n",
    "        val_df = train_df[train_df['fold']==fold_]\n",
    "        for feat in single_feat_list:\n",
    "            f = feat + '_day_labelrate'\n",
    "            colname1 = 'labelrate_' + feat + '_kfold_mean'\n",
    "            colname2 = 'labelrate_' + feat + '_kfold_median'\n",
    "            # mean\n",
    "            order_label = log_df.groupby(feat)[f].mean()\n",
    "            t1.loc[t1['fold']==fold_, colname1] = val_df[feat].map(order_label)\n",
    "            # median\n",
    "            order_label = log_df.groupby(feat)[f].median()\n",
    "            t1.loc[t1['fold']==fold_, colname2] = val_df[feat].map(order_label)\n",
    "    len_t1 = len(t1)\n",
    "    for feat in single_feat_list:\n",
    "        extract_feat += ['labelrate_'+feat+'_kfold_mean', 'labelrate_'+feat+'_kfold_median']\n",
    "        assert len_t1 == t1[feat].count()\n",
    "        \n",
    "    # test\n",
    "    for feat in single_feat_list:\n",
    "        logging.info('in test, feat: %s', feat)\n",
    "        f = feat + '_day_labelrate'\n",
    "        colname1 = 'labelrate_' + feat + '_kfold_mean'\n",
    "        colname2 = 'labelrate_' + feat + '_kfold_median'\n",
    "        order_label = train_df.groupby(feat)[f].mean()\n",
    "        t2[colname1] = test_df[feat].map(order_label)\n",
    "        order_label = train_df.groupby(feat)[f].median()\n",
    "        t2[colname2] = test_df[feat].map(order_label)\n",
    "           \n",
    "    return t1[extract_feat], t2[extract_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-13 04:04:40,269] INFO in <ipython-input-19-7cd45ae0eb12>: concat uid\n",
      "[2019-12-13 04:04:45,619] INFO in <ipython-input-19-7cd45ae0eb12>: concat qid\n",
      "[2019-12-13 04:05:02,516] INFO in <ipython-input-19-7cd45ae0eb12>: concat freq\n",
      "[2019-12-13 04:05:18,065] INFO in <ipython-input-19-7cd45ae0eb12>: concat gender\n",
      "[2019-12-13 04:05:32,838] INFO in <ipython-input-19-7cd45ae0eb12>: concat score\n",
      "[2019-12-13 04:05:47,518] INFO in <ipython-input-19-7cd45ae0eb12>: concat week\n",
      "[2019-12-13 04:06:03,049] INFO in <ipython-input-19-7cd45ae0eb12>: concat hour\n",
      "[2019-12-13 04:06:17,633] INFO in <ipython-input-19-7cd45ae0eb12>: concat uf_b1\n",
      "[2019-12-13 04:06:25,619] INFO in <ipython-input-19-7cd45ae0eb12>: concat uf_b2\n",
      "[2019-12-13 04:06:41,279] INFO in <ipython-input-19-7cd45ae0eb12>: concat uf_b3\n",
      "[2019-12-13 04:06:54,191] INFO in <ipython-input-19-7cd45ae0eb12>: concat uf_b4\n",
      "[2019-12-13 04:07:08,762] INFO in <ipython-input-19-7cd45ae0eb12>: concat uf_b5\n",
      "[2019-12-13 04:07:24,768] INFO in <ipython-input-19-7cd45ae0eb12>: concat uf_c1\n",
      "[2019-12-13 04:07:40,577] INFO in <ipython-input-19-7cd45ae0eb12>: concat uf_c2\n",
      "[2019-12-13 04:07:56,325] INFO in <ipython-input-19-7cd45ae0eb12>: concat uf_c3\n",
      "[2019-12-13 04:08:11,931] INFO in <ipython-input-19-7cd45ae0eb12>: concat uf_c4\n",
      "[2019-12-13 04:08:27,524] INFO in <ipython-input-19-7cd45ae0eb12>: concat uf_c5\n",
      "[2019-12-13 04:08:43,992] INFO in <ipython-input-19-7cd45ae0eb12>: concat diff_iq_day\n",
      "[2019-12-13 04:08:56,958] INFO in <ipython-input-19-7cd45ae0eb12>: concat diff_iq_hour\n",
      "[2019-12-13 04:09:13,412] INFO in <ipython-input-19-7cd45ae0eb12>: concat intersection_ft_count\n",
      "[2019-12-13 04:09:29,328] INFO in <ipython-input-19-7cd45ae0eb12>: concat intersection_it_count\n",
      "[2019-12-13 04:09:45,443] INFO in <ipython-input-19-7cd45ae0eb12>: t1 shape: (9489162, 51)\n"
     ]
    }
   ],
   "source": [
    "single_feat = ['uid', 'qid', 'freq', 'gender', 'score', 'week', 'hour', \n",
    "               'uf_b1', 'uf_b2','uf_b3', 'uf_b4', 'uf_b5', \n",
    "               'uf_c1', 'uf_c2', 'uf_c3', 'uf_c4', 'uf_c5',\n",
    "               'diff_iq_day', 'diff_iq_hour', \n",
    "               'intersection_ft_count', 'intersection_it_count']\n",
    "\n",
    "t1 = train.copy()\n",
    "for feat in single_feat:\n",
    "    logging.info('concat %s', feat)\n",
    "    t2 = pickle.load(open(f'./temp_label_feat/{feat}_day.pkl', 'rb'))\n",
    "    t1 = pd.concat([t1, t2], axis=1)\n",
    "logging.info('t1 shape: %s', t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-13 04:09:59,126] INFO in <ipython-input-18-ea4c60656de3>: in train, fold: 0\n",
      "[2019-12-13 04:13:24,839] INFO in <ipython-input-18-ea4c60656de3>: in train, fold: 1\n",
      "[2019-12-13 04:15:14,730] INFO in <ipython-input-18-ea4c60656de3>: in train, fold: 2\n",
      "[2019-12-13 04:17:08,814] INFO in <ipython-input-18-ea4c60656de3>: in train, fold: 3\n",
      "[2019-12-13 04:19:12,219] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: uid\n",
      "[2019-12-13 04:19:41,019] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: qid\n",
      "[2019-12-13 04:20:05,870] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: freq\n",
      "[2019-12-13 04:20:10,510] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: gender\n",
      "[2019-12-13 04:20:15,035] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: score\n",
      "[2019-12-13 04:20:16,434] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: week\n",
      "[2019-12-13 04:20:17,818] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: hour\n",
      "[2019-12-13 04:20:19,275] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: uf_b1\n",
      "[2019-12-13 04:20:20,622] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: uf_b2\n",
      "[2019-12-13 04:20:22,025] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: uf_b3\n",
      "[2019-12-13 04:20:23,421] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: uf_b4\n",
      "[2019-12-13 04:20:24,804] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: uf_b5\n",
      "[2019-12-13 04:20:26,201] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: uf_c1\n",
      "[2019-12-13 04:20:31,041] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: uf_c2\n",
      "[2019-12-13 04:20:35,332] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: uf_c3\n",
      "[2019-12-13 04:20:40,029] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: uf_c4\n",
      "[2019-12-13 04:20:44,883] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: uf_c5\n",
      "[2019-12-13 04:20:49,363] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: diff_iq_day\n",
      "[2019-12-13 04:20:50,795] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: diff_iq_hour\n",
      "[2019-12-13 04:20:52,240] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: intersection_ft_count\n",
      "[2019-12-13 04:20:53,653] INFO in <ipython-input-18-ea4c60656de3>: in test, feat: intersection_it_count\n",
      "[2019-12-13 04:21:00,893] INFO in <ipython-input-20-26059b79c792>: train feature shape: (9489162, 42), test feature shape: (1141683, 42)\n"
     ]
    }
   ],
   "source": [
    "tt1, tt2 = kfold_1order_label_stat(t1, test, single_feat)\n",
    "logging.info('train feature shape: %s, test feature shape: %s', tt1.shape, tt2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删掉所有取值都一样的列\n",
    "for i in tt1.columns:\n",
    "    if len(tt1[i].value_counts())==1:\n",
    "        print(i)\n",
    "        del tt1[i], tt2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 压缩数据\n",
    "t = tt1.dtypes\n",
    "for x in t[t == 'int64'].index:\n",
    "    tt1[x] = tt1[x].astype('int32')\n",
    "\n",
    "for x in t[t == 'float64'].index:\n",
    "    tt1[x] = tt1[x].astype('float32')\n",
    "    \n",
    "# 压缩数据\n",
    "t = tt2.dtypes\n",
    "for x in t[t == 'int64'].index:\n",
    "    tt2[x] = tt2[x].astype('int32')\n",
    "\n",
    "for x in t[t == 'float64'].index:\n",
    "    tt2[x] = tt2[x].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tt1, open(f'{feature_path}/train_kfold_1order_label_feature.pkl', 'wb'))\n",
    "pickle.dump(tt2, open(f'{feature_path}/test_kfold_1order_label_feature.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kfold 二阶交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_2order_label_stat(train_df, test_df, base_feat, other_feat):\n",
    "    t1 = train_df.copy()\n",
    "    t2 = test_df.copy()\n",
    "    extract_feat = []\n",
    "    for of in other_feat:\n",
    "        logging.info('at %s', of)\n",
    "        for bf in base_feat:\n",
    "            colname1 = 'labelrate_' + of + '_' + bf + '_kfold_mean'\n",
    "            colname2 = 'labelrate_' + of + '_' + bf + '_kfold_median'\n",
    "            extract_feat += [colname1, colname2]\n",
    "            \n",
    "            # train\n",
    "            for fold_ in range(4):\n",
    "                log_df = train_df[train_df['fold']!=fold_]\n",
    "                val_df = train_df[train_df['fold']==fold_]\n",
    "                # mean\n",
    "                order_label = log_df.groupby(of)[bf].mean()\n",
    "                t1.loc[t1['fold']==fold_, colname1] = val_df[of].map(order_label)\n",
    "                # median\n",
    "                order_label = log_df.groupby(of)[bf].median()\n",
    "                t1.loc[t1['fold']==fold_, colname2] = val_df[of].map(order_label)\n",
    "                \n",
    "            # test\n",
    "            order_label = train_df.groupby(of)[bf].mean()\n",
    "            t2[colname1] = test_df[of].map(order_label)\n",
    "            order_label = train_df.groupby(of)[bf].median()\n",
    "            t2[colname2] = test_df[of].map(order_label)\n",
    "            \n",
    "    return t1[extract_feat], t2[extract_feat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uid 交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-13 04:22:16,703] INFO in <ipython-input-25-9eec0be8829a>: t1 shape: (9489162, 31)\n"
     ]
    }
   ],
   "source": [
    "t1 = pickle.load(open('./temp_label_feat/uid_day.pkl', 'rb'))\n",
    "t1 = pd.concat([train, t1], axis=1)\n",
    "logging.info('t1 shape: %s', t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-13 04:22:27,276] INFO in <ipython-input-24-58a7414427f1>: at week\n",
      "[2019-12-13 04:23:05,506] INFO in <ipython-input-24-58a7414427f1>: at hour\n",
      "[2019-12-13 04:23:43,973] INFO in <ipython-input-24-58a7414427f1>: at diff_iq_day\n",
      "[2019-12-13 04:24:21,552] INFO in <ipython-input-24-58a7414427f1>: at diff_iq_hour\n",
      "[2019-12-13 04:24:58,535] INFO in <ipython-input-24-58a7414427f1>: at intersection_ft_count\n",
      "[2019-12-13 04:25:34,448] INFO in <ipython-input-24-58a7414427f1>: at intersection_it_count\n",
      "[2019-12-13 04:26:14,388] INFO in <ipython-input-24-58a7414427f1>: at qu_topic_count\n",
      "[2019-12-13 04:26:54,415] INFO in <ipython-input-24-58a7414427f1>: at qu_topic_count_weight\n",
      "[2019-12-13 04:27:40,970] INFO in <ipython-input-26-bd55177bfa65>: tt1 shape: (9489162, 16), tt2 shape: (1141683, 16)\n"
     ]
    }
   ],
   "source": [
    "base = ['uid_day_labelrate']\n",
    "other = ['week', 'hour', 'diff_iq_day', 'diff_iq_hour', 'intersection_ft_count', 'intersection_it_count',\n",
    "        'qu_topic_count', 'qu_topic_count_weight']\n",
    "tt1, tt2 = kfold_2order_label_stat(t1, test, base, other)\n",
    "logging.info('tt1 shape: %s, tt2 shape: %s', tt1.shape, tt2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelrate_week_uid_day_labelrate_kfold_median\n",
      "labelrate_hour_uid_day_labelrate_kfold_median\n",
      "labelrate_diff_iq_day_uid_day_labelrate_kfold_median\n",
      "labelrate_diff_iq_hour_uid_day_labelrate_kfold_median\n",
      "labelrate_intersection_ft_count_uid_day_labelrate_kfold_median\n",
      "labelrate_intersection_it_count_uid_day_labelrate_kfold_median\n"
     ]
    }
   ],
   "source": [
    "# 删掉所有取值都一样的列\n",
    "for i in tt1.columns:\n",
    "    if len(tt1[i].value_counts())==1:\n",
    "        print(i)\n",
    "        del tt1[i], tt2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 压缩数据\n",
    "t = tt1.dtypes\n",
    "for x in t[t == 'int64'].index:\n",
    "    tt1[x] = tt1[x].astype('int32')\n",
    "\n",
    "for x in t[t == 'float64'].index:\n",
    "    tt1[x] = tt1[x].astype('float32')\n",
    "    \n",
    "# 压缩数据\n",
    "t = tt2.dtypes\n",
    "for x in t[t == 'int64'].index:\n",
    "    tt2[x] = tt2[x].astype('int32')\n",
    "\n",
    "for x in t[t == 'float64'].index:\n",
    "    tt2[x] = tt2[x].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tt1, open(f'{feature_path}/train_kfold_uid_2order_label_feature.pkl', 'wb'))\n",
    "pickle.dump(tt2, open(f'{feature_path}/test_kfold_uid_2order_label_feature.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qid 交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-13 04:28:01,454] INFO in <ipython-input-30-cb9d4300239c>: t1 shape: (9489162, 31)\n"
     ]
    }
   ],
   "source": [
    "t1 = pickle.load(open('./temp_label_feat/qid_day.pkl', 'rb'))\n",
    "t1 = pd.concat([train, t1], axis=1)\n",
    "logging.info('t1 shape: %s', t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-13 04:28:14,441] INFO in <ipython-input-24-58a7414427f1>: at gender\n",
      "[2019-12-13 04:29:02,696] INFO in <ipython-input-24-58a7414427f1>: at freq\n",
      "[2019-12-13 04:29:58,384] INFO in <ipython-input-24-58a7414427f1>: at score\n",
      "[2019-12-13 04:30:35,746] INFO in <ipython-input-24-58a7414427f1>: at uf_b1\n",
      "[2019-12-13 04:31:12,610] INFO in <ipython-input-24-58a7414427f1>: at uf_b2\n",
      "[2019-12-13 04:31:50,238] INFO in <ipython-input-24-58a7414427f1>: at uf_b3\n",
      "[2019-12-13 04:32:26,850] INFO in <ipython-input-24-58a7414427f1>: at uf_b4\n",
      "[2019-12-13 04:33:04,261] INFO in <ipython-input-24-58a7414427f1>: at uf_b5\n",
      "[2019-12-13 04:33:42,460] INFO in <ipython-input-24-58a7414427f1>: at uf_c5\n",
      "[2019-12-13 04:34:37,259] INFO in <ipython-input-24-58a7414427f1>: at diff_iq_day\n",
      "[2019-12-13 04:35:16,552] INFO in <ipython-input-24-58a7414427f1>: at diff_iq_hour\n",
      "[2019-12-13 04:35:58,573] INFO in <ipython-input-24-58a7414427f1>: at qu_topic_count\n",
      "[2019-12-13 04:36:42,049] INFO in <ipython-input-24-58a7414427f1>: at qu_topic_count_weight\n",
      "[2019-12-13 04:37:25,591] INFO in <ipython-input-31-2f50827fece5>: tt1 shape: (9489162, 26), tt2 shape: (1141683, 26)\n"
     ]
    }
   ],
   "source": [
    "base = ['qid_day_labelrate']\n",
    "other = ['gender', 'freq', 'score', \n",
    "         'uf_b1', 'uf_b2', 'uf_b3', 'uf_b4', 'uf_b5', 'uf_c5', \n",
    "         'diff_iq_day', 'diff_iq_hour', 'qu_topic_count', 'qu_topic_count_weight']\n",
    "tt1, tt2 = kfold_2order_label_stat(t1, test, base, other)\n",
    "logging.info('tt1 shape: %s, tt2 shape: %s', tt1.shape, tt2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删掉所有取值都一样的列\n",
    "for i in tt1.columns:\n",
    "    if len(tt1[i].value_counts())==1:\n",
    "        print(i)\n",
    "        del tt1[i], tt2[i]\n",
    "gc.collect()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 压缩数据\n",
    "t = tt1.dtypes\n",
    "for x in t[t == 'int64'].index:\n",
    "    tt1[x] = tt1[x].astype('int32')\n",
    "\n",
    "for x in t[t == 'float64'].index:\n",
    "    tt1[x] = tt1[x].astype('float32')\n",
    "    \n",
    "# 压缩数据\n",
    "t = tt2.dtypes\n",
    "for x in t[t == 'int64'].index:\n",
    "    tt2[x] = tt2[x].astype('int32')\n",
    "\n",
    "for x in t[t == 'float64'].index:\n",
    "    tt2[x] = tt2[x].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tt1, open(f'{feature_path}/train_kfold_qid_2order_label_feature.pkl', 'wb'))\n",
    "pickle.dump(tt2, open(f'{feature_path}/test_kfold_qid_2order_label_feature.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二分类交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pickle.load(open('./temp_label_feat/uf_b2_day.pkl', 'rb'))\n",
    "t1 = pd.concat([train, t1], axis=1)\n",
    "logging.info('t1 shape: %s', t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base = ['uf_b2_day_labelrate']\n",
    "other = ['uf_b1', 'uf_b3']\n",
    "tt1, tt2 = kfold_2order_label_stat(t1, test, base, other)\n",
    "logging.info('tt1 shape: %s, tt2 shape: %s', tt1.shape, tt2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删掉所有取值都一样的列\n",
    "for i in tt1.columns:\n",
    "    if len(tt1[i].value_counts())==1:\n",
    "        print(i)\n",
    "        del tt1[i], tt2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 压缩数据\n",
    "t = tt1.dtypes\n",
    "for x in t[t == 'int64'].index:\n",
    "    tt1[x] = tt1[x].astype('int32')\n",
    "\n",
    "for x in t[t == 'float64'].index:\n",
    "    tt1[x] = tt1[x].astype('float32')\n",
    "    \n",
    "# 压缩数据\n",
    "t = tt2.dtypes\n",
    "for x in t[t == 'int64'].index:\n",
    "    tt2[x] = tt2[x].astype('int32')\n",
    "\n",
    "for x in t[t == 'float64'].index:\n",
    "    tt2[x] = tt2[x].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tt1, open(f'{feature_path}/train_kfold_uid_2order_label_feature.pkl', 'wb'))\n",
    "pickle.dump(tt2, open(f'{feature_path}/test_kfold_uid_2order_label_feature.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
