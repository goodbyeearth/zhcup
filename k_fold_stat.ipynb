{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fmt = \"[%(asctime)s] %(levelname)s in %(module)s: %(message)s\"\n",
    "logging.basicConfig(format=log_fmt, level=logging.INFO)\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-29 09:34:13,046] INFO in <ipython-input-111-af34e33feb4f>: invite (9489162, 4)\n",
      "[2019-11-29 09:34:14,521] INFO in <ipython-input-111-af34e33feb4f>: test (1141683, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(f'{base_path}/invite_info_0926.txt', sep='\\t', header=None)\n",
    "train.columns = ['qid', 'uid', 'dt', 'label']\n",
    "logging.info(\"invite %s\", train.shape)\n",
    "\n",
    "test = pd.read_csv(f'{base_path}/invite_info_evaluate_0926.txt', sep='\\t', header=None)\n",
    "test.columns = ['qid', 'uid', 'dt']\n",
    "logging.info(\"test %s\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_day(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[0][1:]))\n",
    "\n",
    "\n",
    "def extract_hour(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[1][1:]))\n",
    "\n",
    "train['day'] = extract_day(train['dt'])\n",
    "train['hour'] = extract_hour(train['dt'])\n",
    "\n",
    "test['day'] = extract_day(test['dt'])\n",
    "test['hour'] = extract_hour(test['dt'])\n",
    "\n",
    "del train['dt'], test['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-29 09:35:08,215] INFO in <ipython-input-113-9063dae39e17>: ques (1829900, 3)\n"
     ]
    }
   ],
   "source": [
    "# 加载问题\n",
    "ques = pd.read_csv(f'{base_path}/question_info_0926.txt', header=None, sep='\\t')\n",
    "ques.columns = ['qid', 'q_dt', 'title_t1', 'title_t2', 'desc_t1', 'desc_t2', 'topic']\n",
    "del ques['title_t1'], ques['title_t2'], ques['desc_t1'], ques['desc_t2']\n",
    "logging.info(\"ques %s\", ques.shape)\n",
    "\n",
    "ques['q_day'] = extract_day(ques['q_dt'])\n",
    "ques['q_hour'] = extract_hour(ques['q_dt'])\n",
    "\n",
    "del ques['q_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-29 09:36:28,525] INFO in <ipython-input-114-cdaa443c2e7e>: ans (4513735, 18)\n"
     ]
    }
   ],
   "source": [
    "# 加载回答\n",
    "ans = pd.read_csv(f'{base_path}/answer_info_0926.txt', header=None, sep='\\t')\n",
    "ans.columns = ['aid', 'qid', 'uid', 'ans_dt', 'ans_t1', 'ans_t2', 'is_good', 'is_rec', 'is_dest', 'has_img',\n",
    "               'has_video', 'word_count', 'reci_cheer', 'reci_uncheer', 'reci_comment', 'reci_mark', 'reci_tks',\n",
    "               'reci_xxx', 'reci_no_help', 'reci_dis']\n",
    "del ans['ans_t1'], ans['ans_t2']\n",
    "logging.info(\"ans %s\", ans.shape)\n",
    "\n",
    "ans['a_day'] = extract_day(ans['ans_dt'])\n",
    "ans['a_hour'] = extract_hour(ans['ans_dt'])\n",
    "del ans['ans_dt']\n",
    "\n",
    "ans = pd.merge(ans, ques, on='qid', how='left')\n",
    "del ques\n",
    "\n",
    "# 回答距提问的天数\n",
    "ans['diff_qa_days'] = ans['a_day'] - ans['q_day']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4折统计\n",
    "def fold_fn(x):\n",
    "    if 3838<=x<=3846:\n",
    "        return 0\n",
    "    if 3847<=x<=3853:\n",
    "        return 1\n",
    "    if 3854<=x<=3860:\n",
    "        return 2\n",
    "    if 3861<=x<=3867:\n",
    "        return 3\n",
    "    else:\n",
    "        return -1     # 更前的一个月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kfold_train_feature(data_df_, ans_df_): \n",
    "    train_df = data_df_.copy()\n",
    "    ans_df = ans_df_.copy()\n",
    "    logging.info(\"ans_df shape %s\", ans_df.shape)\n",
    "    \n",
    "    train_df['fold'] = train_df['day'].apply(fold_fn)\n",
    "    train_df_copy = train_df.copy()\n",
    "    \n",
    "    # 给 ans 加 fold 信息\n",
    "    ans_df['fold'] = ans_df['a_day'].apply(fold_fn)\n",
    "    logging.info(\"ans_df shape %s\", ans_df.shape)\n",
    "    \n",
    "    extract_q_feat = ['q_inv_kfold_mean', 'q_inv_kfold_sum', 'q_inv_kfold_std', 'q_inv_kfold_count']\n",
    "    extract_u_feat = ['u_inv_kfold_mean', 'u_inv_kfold_sum', 'u_inv_kfold_std', 'u_inv_kfold_count']\n",
    "    a_feat = ['is_good', 'is_rec', 'is_dest', 'has_img', 'has_video', 'word_count',\n",
    "              'reci_cheer', 'reci_uncheer', 'reci_comment', 'reci_mark', 'reci_tks',\n",
    "              'reci_xxx', 'reci_no_help', 'reci_dis', 'diff_qa_days']\n",
    "    \n",
    "    extract_a_feat = ['q_ans_kfold_count', 'u_ans_kfold_count']\n",
    "    for col in a_feat:\n",
    "        extract_a_feat += [f'q_{col}_sum', f'q_{col}_max', f'q_{col}_mean', \n",
    "                           f'u_{col}_sum', f'u_{col}_max', f'u_{col}_mean']\n",
    "        \n",
    "    extract_feat = extract_q_feat + extract_u_feat + extract_a_feat\n",
    "    \n",
    "    for feat in extract_feat:\n",
    "        train_df[feat] = -10000\n",
    "        \n",
    "    for fold_ in range(4):\n",
    "        logging.info(\"fold %s\", fold_)\n",
    "        \n",
    "        log_trn = train_df_copy.loc[train_df_copy['fold'] != fold_]    # 提这些记录里的信息\n",
    "        logging.info(\"log_trn shape %s\", log_trn.shape)\n",
    "        val_df = train_df_copy.loc[train_df_copy['fold'] == fold_]\n",
    "        logging.info(\"val_df shape %s\", val_df.shape)\n",
    "        log_ans = ans_df.loc[ans_df['fold'] != fold_]  # 排除掉当前 fold 的 ans\n",
    "        logging.info(\"log_ans shape %s\", log_ans.shape)\n",
    "        \n",
    "        # ques\n",
    "        logging.info(\"question info\")\n",
    "        t1 = log_trn.groupby('qid')['label'].agg(['mean', 'sum', 'std', 'count']).reset_index()\n",
    "        t1.columns = ['qid'] + extract_q_feat   # 回答率,回答次数,标准差,邀请次数\n",
    "        train_df.loc[train_df['fold']==fold_, extract_q_feat] = pd.merge(val_df, t1, on='qid', \n",
    "                                                                         how='left')[extract_q_feat].values\n",
    "\n",
    "        # user\n",
    "        logging.info(\"user info\")\n",
    "        t1 = log_trn.groupby('uid')['label'].agg(['mean', 'sum', 'std', 'count']).reset_index()\n",
    "        t1.columns = ['uid'] + extract_u_feat\n",
    "        train_df.loc[train_df['fold']==fold_, extract_u_feat] = pd.merge(val_df, t1, on='uid', \n",
    "                                                                         how='left')[extract_u_feat].values\n",
    "        \n",
    "        # ans\n",
    "        ans_q_group = log_ans.groupby('qid')\n",
    "        ans_u_group = log_ans.groupby('uid')\n",
    "        \n",
    "        logging.info(\"ans: q_ans_kfold_count\")\n",
    "        t1 = ans_q_group['aid'].count().reset_index()\n",
    "        t1.columns = ['qid', 'q_ans_kfold_count']          # 某问题在 answer_info 中的回答次数\n",
    "        train_df.loc[train_df['fold']==fold_, ['q_ans_kfold_count']] = pd.merge(val_df, t1, on='qid', \n",
    "                                                                                how='left')['q_ans_kfold_count'].values\n",
    "        \n",
    "        logging.info(\"ans: u_ans_kfold_count\")\n",
    "        t1 = ans_u_group['aid'].count().reset_index()\n",
    "        t1.columns = ['uid', 'u_ans_kfold_count']          # 某用户在 answer_info 中的回答次数\n",
    "        train_df.loc[train_df['fold']==fold_, ['u_ans_kfold_count']] = pd.merge(val_df, t1, on='uid', \n",
    "                                                                                how='left')['u_ans_kfold_count'].values\n",
    "        \n",
    "        for col in a_feat:\n",
    "            logging.info(\"ans: %s sum max mean\", col)\n",
    "            \n",
    "            t1 = ans_q_group[col].agg(['sum', 'max', 'mean']).reset_index()\n",
    "            f_name = [f'q_{col}_sum', f'q_{col}_max', f'q_{col}_mean']\n",
    "            t1.columns = ['qid'] + f_name\n",
    "            train_df.loc[train_df['fold']==fold_, f_name] = pd.merge(val_df, t1, on='qid', \n",
    "                                                                     how='left')[f_name].values\n",
    "            \n",
    "            t1 = ans_u_group[col].agg(['sum', 'max', 'mean']).reset_index()\n",
    "            f_name = [f'u_{col}_sum', f'u_{col}_max', f'u_{col}_mean']\n",
    "            t1.columns = ['uid'] + f_name\n",
    "            train_df.loc[train_df['fold']==fold_, f_name] = pd.merge(val_df, t1, on='uid', \n",
    "                                                                     how='left')[f_name].values\n",
    "            \n",
    "    for feat in extract_feat:\n",
    "        assert len(train_df[train_df[feat]==-10000]) == 0\n",
    "    del train_df['fold']\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-29 09:36:52,089] INFO in <ipython-input-116-b81cb14d6795>: ans_df shape (4513735, 23)\n",
      "[2019-11-29 09:37:06,690] INFO in <ipython-input-116-b81cb14d6795>: ans_df shape (4513735, 24)\n",
      "[2019-11-29 09:39:11,751] INFO in <ipython-input-116-b81cb14d6795>: fold 0\n",
      "[2019-11-29 09:39:12,750] INFO in <ipython-input-116-b81cb14d6795>: log_trn shape (7070010, 6)\n",
      "[2019-11-29 09:39:13,126] INFO in <ipython-input-116-b81cb14d6795>: val_df shape (2419152, 6)\n",
      "[2019-11-29 09:39:15,070] INFO in <ipython-input-116-b81cb14d6795>: log_ans shape (3796380, 24)\n",
      "[2019-11-29 09:39:15,071] INFO in <ipython-input-116-b81cb14d6795>: question info\n",
      "[2019-11-29 09:41:15,368] INFO in <ipython-input-116-b81cb14d6795>: user info\n",
      "[2019-11-29 09:41:45,443] INFO in <ipython-input-116-b81cb14d6795>: ans: q_ans_kfold_count\n",
      "[2019-11-29 09:41:56,927] INFO in <ipython-input-116-b81cb14d6795>: ans: u_ans_kfold_count\n",
      "[2019-11-29 09:42:05,313] INFO in <ipython-input-116-b81cb14d6795>: ans: is_good sum max mean\n",
      "[2019-11-29 09:42:41,379] INFO in <ipython-input-116-b81cb14d6795>: ans: is_rec sum max mean\n",
      "[2019-11-29 09:43:16,222] INFO in <ipython-input-116-b81cb14d6795>: ans: is_dest sum max mean\n",
      "[2019-11-29 09:43:50,743] INFO in <ipython-input-116-b81cb14d6795>: ans: has_img sum max mean\n",
      "[2019-11-29 09:44:24,905] INFO in <ipython-input-116-b81cb14d6795>: ans: has_video sum max mean\n",
      "[2019-11-29 09:44:58,873] INFO in <ipython-input-116-b81cb14d6795>: ans: word_count sum max mean\n",
      "[2019-11-29 09:45:32,623] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_cheer sum max mean\n",
      "[2019-11-29 09:46:05,571] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_uncheer sum max mean\n",
      "[2019-11-29 09:46:38,967] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_comment sum max mean\n",
      "[2019-11-29 09:47:11,681] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_mark sum max mean\n",
      "[2019-11-29 09:47:43,959] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_tks sum max mean\n",
      "[2019-11-29 09:48:15,415] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_xxx sum max mean\n",
      "[2019-11-29 09:48:47,230] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_no_help sum max mean\n",
      "[2019-11-29 09:49:21,225] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_dis sum max mean\n",
      "[2019-11-29 09:49:58,107] INFO in <ipython-input-116-b81cb14d6795>: ans: diff_qa_days sum max mean\n",
      "[2019-11-29 09:50:36,911] INFO in <ipython-input-116-b81cb14d6795>: fold 1\n",
      "[2019-11-29 09:50:37,960] INFO in <ipython-input-116-b81cb14d6795>: log_trn shape (7256684, 6)\n",
      "[2019-11-29 09:50:38,269] INFO in <ipython-input-116-b81cb14d6795>: val_df shape (2232478, 6)\n",
      "[2019-11-29 09:50:39,481] INFO in <ipython-input-116-b81cb14d6795>: log_ans shape (3835303, 24)\n",
      "[2019-11-29 09:50:39,483] INFO in <ipython-input-116-b81cb14d6795>: question info\n",
      "[2019-11-29 09:51:04,651] INFO in <ipython-input-116-b81cb14d6795>: user info\n",
      "[2019-11-29 09:51:22,141] INFO in <ipython-input-116-b81cb14d6795>: ans: q_ans_kfold_count\n",
      "[2019-11-29 09:51:29,656] INFO in <ipython-input-116-b81cb14d6795>: ans: u_ans_kfold_count\n",
      "[2019-11-29 09:51:34,407] INFO in <ipython-input-116-b81cb14d6795>: ans: is_good sum max mean\n",
      "[2019-11-29 09:51:50,434] INFO in <ipython-input-116-b81cb14d6795>: ans: is_rec sum max mean\n",
      "[2019-11-29 09:52:05,938] INFO in <ipython-input-116-b81cb14d6795>: ans: is_dest sum max mean\n",
      "[2019-11-29 09:52:21,253] INFO in <ipython-input-116-b81cb14d6795>: ans: has_img sum max mean\n",
      "[2019-11-29 09:52:37,010] INFO in <ipython-input-116-b81cb14d6795>: ans: has_video sum max mean\n",
      "[2019-11-29 09:52:52,620] INFO in <ipython-input-116-b81cb14d6795>: ans: word_count sum max mean\n",
      "[2019-11-29 09:53:07,970] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_cheer sum max mean\n",
      "[2019-11-29 09:53:23,673] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_uncheer sum max mean\n",
      "[2019-11-29 09:53:39,308] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_comment sum max mean\n",
      "[2019-11-29 09:53:54,645] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_mark sum max mean\n",
      "[2019-11-29 09:54:10,263] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_tks sum max mean\n",
      "[2019-11-29 09:54:25,921] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_xxx sum max mean\n",
      "[2019-11-29 09:54:41,382] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_no_help sum max mean\n",
      "[2019-11-29 09:54:56,975] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_dis sum max mean\n",
      "[2019-11-29 09:55:12,726] INFO in <ipython-input-116-b81cb14d6795>: ans: diff_qa_days sum max mean\n",
      "[2019-11-29 09:55:28,518] INFO in <ipython-input-116-b81cb14d6795>: fold 2\n",
      "[2019-11-29 09:55:29,367] INFO in <ipython-input-116-b81cb14d6795>: log_trn shape (7245299, 6)\n",
      "[2019-11-29 09:55:29,712] INFO in <ipython-input-116-b81cb14d6795>: val_df shape (2243863, 6)\n",
      "[2019-11-29 09:55:30,794] INFO in <ipython-input-116-b81cb14d6795>: log_ans shape (3860633, 24)\n",
      "[2019-11-29 09:55:30,795] INFO in <ipython-input-116-b81cb14d6795>: question info\n",
      "[2019-11-29 09:55:45,566] INFO in <ipython-input-116-b81cb14d6795>: user info\n",
      "[2019-11-29 09:56:03,130] INFO in <ipython-input-116-b81cb14d6795>: ans: q_ans_kfold_count\n",
      "[2019-11-29 09:56:10,815] INFO in <ipython-input-116-b81cb14d6795>: ans: u_ans_kfold_count\n",
      "[2019-11-29 09:56:15,689] INFO in <ipython-input-116-b81cb14d6795>: ans: is_good sum max mean\n",
      "[2019-11-29 09:56:31,546] INFO in <ipython-input-116-b81cb14d6795>: ans: is_rec sum max mean\n",
      "[2019-11-29 09:56:47,339] INFO in <ipython-input-116-b81cb14d6795>: ans: is_dest sum max mean\n",
      "[2019-11-29 09:57:03,003] INFO in <ipython-input-116-b81cb14d6795>: ans: has_img sum max mean\n",
      "[2019-11-29 09:57:18,520] INFO in <ipython-input-116-b81cb14d6795>: ans: has_video sum max mean\n",
      "[2019-11-29 09:57:34,321] INFO in <ipython-input-116-b81cb14d6795>: ans: word_count sum max mean\n",
      "[2019-11-29 09:57:50,185] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_cheer sum max mean\n",
      "[2019-11-29 09:58:05,962] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_uncheer sum max mean\n",
      "[2019-11-29 09:58:21,366] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_comment sum max mean\n",
      "[2019-11-29 09:58:37,226] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_mark sum max mean\n",
      "[2019-11-29 09:58:52,966] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_tks sum max mean\n",
      "[2019-11-29 09:59:08,698] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_xxx sum max mean\n",
      "[2019-11-29 09:59:24,217] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_no_help sum max mean\n",
      "[2019-11-29 09:59:40,069] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_dis sum max mean\n",
      "[2019-11-29 09:59:55,890] INFO in <ipython-input-116-b81cb14d6795>: ans: diff_qa_days sum max mean\n",
      "[2019-11-29 10:00:11,551] INFO in <ipython-input-116-b81cb14d6795>: fold 3\n",
      "[2019-11-29 10:00:12,637] INFO in <ipython-input-116-b81cb14d6795>: log_trn shape (6895493, 6)\n",
      "[2019-11-29 10:00:12,963] INFO in <ipython-input-116-b81cb14d6795>: val_df shape (2593669, 6)\n",
      "[2019-11-29 10:00:14,158] INFO in <ipython-input-116-b81cb14d6795>: log_ans shape (3828707, 24)\n",
      "[2019-11-29 10:00:14,160] INFO in <ipython-input-116-b81cb14d6795>: question info\n",
      "[2019-11-29 10:00:29,299] INFO in <ipython-input-116-b81cb14d6795>: user info\n",
      "[2019-11-29 10:00:47,313] INFO in <ipython-input-116-b81cb14d6795>: ans: q_ans_kfold_count\n",
      "[2019-11-29 10:00:54,509] INFO in <ipython-input-116-b81cb14d6795>: ans: u_ans_kfold_count\n",
      "[2019-11-29 10:00:59,785] INFO in <ipython-input-116-b81cb14d6795>: ans: is_good sum max mean\n",
      "[2019-11-29 10:01:17,246] INFO in <ipython-input-116-b81cb14d6795>: ans: is_rec sum max mean\n",
      "[2019-11-29 10:01:34,646] INFO in <ipython-input-116-b81cb14d6795>: ans: is_dest sum max mean\n",
      "[2019-11-29 10:01:51,928] INFO in <ipython-input-116-b81cb14d6795>: ans: has_img sum max mean\n",
      "[2019-11-29 10:02:09,169] INFO in <ipython-input-116-b81cb14d6795>: ans: has_video sum max mean\n",
      "[2019-11-29 10:02:26,579] INFO in <ipython-input-116-b81cb14d6795>: ans: word_count sum max mean\n",
      "[2019-11-29 10:02:44,091] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_cheer sum max mean\n",
      "[2019-11-29 10:03:01,602] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_uncheer sum max mean\n",
      "[2019-11-29 10:03:19,181] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_comment sum max mean\n",
      "[2019-11-29 10:03:36,426] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_mark sum max mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-29 10:03:53,843] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_tks sum max mean\n",
      "[2019-11-29 10:04:11,306] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_xxx sum max mean\n",
      "[2019-11-29 10:04:28,724] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_no_help sum max mean\n",
      "[2019-11-29 10:04:46,151] INFO in <ipython-input-116-b81cb14d6795>: ans: reci_dis sum max mean\n",
      "[2019-11-29 10:05:03,631] INFO in <ipython-input-116-b81cb14d6795>: ans: diff_qa_days sum max mean\n"
     ]
    }
   ],
   "source": [
    "train_kfold = extract_kfold_train_feature(train, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kfold_test_feature(test_df_, data_df_, ans_df_): \n",
    "    train_df = data_df_.copy()\n",
    "    logging.info(\"train_df shape %s\", train_df.shape)\n",
    "    test_df = test_df_.copy()\n",
    "    logging.info(\"test_df shape %s\", test_df.shape)\n",
    "    ans_df = ans_df_.copy()\n",
    "    logging.info(\"ans_df shape %s\", ans_df.shape)\n",
    "    \n",
    "    extract_q_feat = ['q_inv_kfold_mean', 'q_inv_kfold_sum', 'q_inv_kfold_std', 'q_inv_kfold_count']\n",
    "    extract_u_feat = ['u_inv_kfold_mean', 'u_inv_kfold_sum', 'u_inv_kfold_std', 'u_inv_kfold_count']\n",
    "#     a_feat = ['is_good', 'is_rec', 'is_dest', 'has_img', 'has_video', 'word_count',\n",
    "#               'reci_cheer', 'reci_uncheer', 'reci_comment', 'reci_mark', 'reci_tks',\n",
    "#               'reci_xxx', 'reci_no_help', 'reci_dis', 'diff_qa_days']\n",
    "    a_feat = ['diff_qa_days']\n",
    "    \n",
    "    extract_a_feat = ['q_ans_kfold_count', 'u_ans_kfold_count']\n",
    "    for col in a_feat:\n",
    "        extract_a_feat += [f'q_{col}_sum', f'q_{col}_max', f'q_{col}_mean', \n",
    "                           f'u_{col}_sum', f'u_{col}_max', f'u_{col}_mean']\n",
    "        \n",
    "    extract_feat = extract_q_feat + extract_u_feat + extract_a_feat\n",
    "\n",
    "    # ques\n",
    "    logging.info(\"question info\")\n",
    "    t1 = train_df.groupby('qid')['label'].agg(['mean', 'sum', 'std', 'count']).reset_index()\n",
    "    t1.columns = ['qid'] + extract_q_feat   # 回答率,回答次数,标准差,邀请次数\n",
    "    test_df = pd.merge(test_df, t1, on='qid', how='left')\n",
    "\n",
    "    # user\n",
    "    logging.info(\"user info\")\n",
    "    t1 = train_df.groupby('uid')['label'].agg(['mean', 'sum', 'std', 'count']).reset_index()\n",
    "    t1.columns = ['uid'] + extract_u_feat\n",
    "    test_df = pd.merge(test_df, t1, on='uid', how='left')\n",
    "\n",
    "    # ans\n",
    "    ans_q_group = ans_df.groupby('qid')\n",
    "    ans_u_group = ans_df.groupby('uid')\n",
    "    \n",
    "    logging.info(\"ans: q_ans_kfold_count\")\n",
    "    t1 = ans_q_group['aid'].count().reset_index()\n",
    "    t1.columns = ['qid', 'q_ans_kfold_count']          # 某问题在 answer_info 中的回答次数\n",
    "    test_df = pd.merge(test_df, t1, on='qid', how='left')\n",
    "\n",
    "    logging.info(\"ans: u_ans_kfold_count\")\n",
    "    t1 = ans_u_group['aid'].count().reset_index()\n",
    "    t1.columns = ['uid', 'u_ans_kfold_count']          # 某用户在 answer_info 中的回答次数\n",
    "    test_df = pd.merge(test_df, t1, on='uid', how='left')\n",
    "\n",
    "    for col in a_feat:\n",
    "        logging.info(\"ans: %s sum max mean\", col)\n",
    "        \n",
    "        t1 = ans_q_group[col].agg(['sum', 'max', 'mean']).reset_index()\n",
    "        f_name = [f'q_{col}_sum', f'q_{col}_max', f'q_{col}_mean']\n",
    "        t1.columns = ['qid'] + f_name\n",
    "        test_df = pd.merge(test_df, t1, on='qid', how='left')\n",
    "\n",
    "        t1 = ans_u_group[col].agg(['sum', 'max', 'mean']).reset_index()\n",
    "        f_name = [f'u_{col}_sum', f'u_{col}_max', f'u_{col}_mean']\n",
    "        t1.columns = ['uid'] + f_name\n",
    "        test_df = pd.merge(test_df, t1, on='uid', how='left')\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-29 07:05:34,210] INFO in <ipython-input-56-a98a4be4d7c5>: train_df shape (9489162, 5)\n",
      "[2019-11-29 07:05:34,293] INFO in <ipython-input-56-a98a4be4d7c5>: test_df shape (1141683, 4)\n",
      "[2019-11-29 07:05:35,103] INFO in <ipython-input-56-a98a4be4d7c5>: ans_df shape (4513735, 23)\n",
      "[2019-11-29 07:05:35,104] INFO in <ipython-input-56-a98a4be4d7c5>: question info\n",
      "[2019-11-29 07:05:43,066] INFO in <ipython-input-56-a98a4be4d7c5>: user info\n",
      "[2019-11-29 07:05:53,488] INFO in <ipython-input-56-a98a4be4d7c5>: ans: q_ans_kfold_count\n",
      "[2019-11-29 07:06:01,030] INFO in <ipython-input-56-a98a4be4d7c5>: ans: u_ans_kfold_count\n",
      "[2019-11-29 07:06:05,716] INFO in <ipython-input-56-a98a4be4d7c5>: ans: is_good sum max mean\n",
      "[2019-11-29 07:06:11,178] INFO in <ipython-input-56-a98a4be4d7c5>: ans: is_rec sum max mean\n",
      "[2019-11-29 07:06:16,381] INFO in <ipython-input-56-a98a4be4d7c5>: ans: is_dest sum max mean\n",
      "[2019-11-29 07:06:21,467] INFO in <ipython-input-56-a98a4be4d7c5>: ans: has_img sum max mean\n",
      "[2019-11-29 07:06:26,681] INFO in <ipython-input-56-a98a4be4d7c5>: ans: has_video sum max mean\n",
      "[2019-11-29 07:06:32,067] INFO in <ipython-input-56-a98a4be4d7c5>: ans: word_count sum max mean\n",
      "[2019-11-29 07:06:37,763] INFO in <ipython-input-56-a98a4be4d7c5>: ans: reci_cheer sum max mean\n",
      "[2019-11-29 07:06:43,341] INFO in <ipython-input-56-a98a4be4d7c5>: ans: reci_uncheer sum max mean\n",
      "[2019-11-29 07:06:49,030] INFO in <ipython-input-56-a98a4be4d7c5>: ans: reci_comment sum max mean\n",
      "[2019-11-29 07:06:54,649] INFO in <ipython-input-56-a98a4be4d7c5>: ans: reci_mark sum max mean\n",
      "[2019-11-29 07:07:00,254] INFO in <ipython-input-56-a98a4be4d7c5>: ans: reci_tks sum max mean\n",
      "[2019-11-29 07:07:06,112] INFO in <ipython-input-56-a98a4be4d7c5>: ans: reci_xxx sum max mean\n",
      "[2019-11-29 07:07:11,869] INFO in <ipython-input-56-a98a4be4d7c5>: ans: reci_no_help sum max mean\n",
      "[2019-11-29 07:07:17,438] INFO in <ipython-input-56-a98a4be4d7c5>: ans: reci_dis sum max mean\n",
      "[2019-11-29 07:07:23,384] INFO in <ipython-input-56-a98a4be4d7c5>: ans: diff_qa_days sum max mean\n"
     ]
    }
   ],
   "source": [
    "test_kfold = extract_kfold_test_feature(test, train[['uid', 'qid', 'day', 'hour', 'label']], ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_kfold['uid'], train_kfold['qid'], train_kfold['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_kfold['uid'], test_kfold['qid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 压缩数据\n",
    "t = train_kfold.dtypes\n",
    "for x in t[t == 'int64'].index:\n",
    "    train_kfold[x] = train_kfold[x].astype('int32')\n",
    "\n",
    "for x in t[t == 'float64'].index:\n",
    "    train_kfold[x] = train_kfold[x].astype('float32')\n",
    "\n",
    "t = test_kfold.dtypes\n",
    "for x in t[t == 'int64'].index:\n",
    "    test_kfold[x] = test_kfold[x].astype('int32')\n",
    "\n",
    "for x in t[t == 'float64'].index:\n",
    "    test_kfold[x] = test_kfold[x].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kfold.to_csv('feature/train_kfold_feature.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kfold.to_csv('feature/test_kfold_feature.txt', index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
