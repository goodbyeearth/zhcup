{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fmt = \"[%(asctime)s] %(levelname)s in %(module)s: %(message)s\"\n",
    "logging.basicConfig(format=log_fmt, level=logging.INFO)\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_day(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[0][1:]))\n",
    "\n",
    "\n",
    "def extract_hour(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[1][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-28 12:22:14,036] INFO in <ipython-input-5-d8d667ebe145>: invite (9489162, 4)\n",
      "[2019-11-28 12:22:15,656] INFO in <ipython-input-5-d8d667ebe145>: test (1141683, 3)\n"
     ]
    }
   ],
   "source": [
    "# 加载邀请回答数据\n",
    "\n",
    "train = pd.read_csv(f'{base_path}/invite_info_0926.txt', sep='\\t', header=None)\n",
    "train.columns = ['qid', 'uid', 'dt', 'label']\n",
    "logging.info(\"invite %s\", train.shape)\n",
    "\n",
    "test = pd.read_csv(f'{base_path}/invite_info_evaluate_0926.txt', sep='\\t', header=None)\n",
    "test.columns = ['qid', 'uid', 'dt']\n",
    "logging.info(\"test %s\", test.shape)\n",
    "\n",
    "sub = test.copy()\n",
    "\n",
    "sub_size = len(sub)\n",
    "\n",
    "train['day'] = extract_day(train['dt'])\n",
    "train['hour'] = extract_hour(train['dt'])\n",
    "\n",
    "test['day'] = extract_day(test['dt'])\n",
    "test['hour'] = extract_hour(test['dt'])\n",
    "\n",
    "del train['dt'], test['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-28 12:23:10,829] INFO in <ipython-input-6-9063dae39e17>: ques (1829900, 3)\n"
     ]
    }
   ],
   "source": [
    "# 加载问题\n",
    "ques = pd.read_csv(f'{base_path}/question_info_0926.txt', header=None, sep='\\t')\n",
    "ques.columns = ['qid', 'q_dt', 'title_t1', 'title_t2', 'desc_t1', 'desc_t2', 'topic']\n",
    "del ques['title_t1'], ques['title_t2'], ques['desc_t1'], ques['desc_t2']\n",
    "logging.info(\"ques %s\", ques.shape)\n",
    "\n",
    "ques['q_day'] = extract_day(ques['q_dt'])\n",
    "ques['q_hour'] = extract_hour(ques['q_dt'])\n",
    "\n",
    "del ques['q_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-28 12:24:27,491] INFO in <ipython-input-7-cdaa443c2e7e>: ans (4513735, 18)\n"
     ]
    }
   ],
   "source": [
    "# 加载回答\n",
    "ans = pd.read_csv(f'{base_path}/answer_info_0926.txt', header=None, sep='\\t')\n",
    "ans.columns = ['aid', 'qid', 'uid', 'ans_dt', 'ans_t1', 'ans_t2', 'is_good', 'is_rec', 'is_dest', 'has_img',\n",
    "               'has_video', 'word_count', 'reci_cheer', 'reci_uncheer', 'reci_comment', 'reci_mark', 'reci_tks',\n",
    "               'reci_xxx', 'reci_no_help', 'reci_dis']\n",
    "del ans['ans_t1'], ans['ans_t2']\n",
    "logging.info(\"ans %s\", ans.shape)\n",
    "\n",
    "ans['a_day'] = extract_day(ans['ans_dt'])\n",
    "ans['a_hour'] = extract_hour(ans['ans_dt'])\n",
    "del ans['ans_dt']\n",
    "\n",
    "ans = pd.merge(ans, ques, on='qid', how='left')\n",
    "del ques\n",
    "\n",
    "# 回答距提问的天数\n",
    "ans['diff_qa_days'] = ans['a_day'] - ans['q_day']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4513735"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kfold_train_feature(data_df_, ans_df_): \n",
    "    train_df = data_df_.copy()\n",
    "    train_df_copy = train_df.copy()\n",
    "    ans_df = ans_df_.copy()\n",
    "    logging.info(\"ans_df shape %s\", ans_df.shape)\n",
    "    \n",
    "    train_df['fold'] = None\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=1989)\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df)):\n",
    "        train_df.loc[val_idx, 'fold'] = fold_\n",
    "    \n",
    "    # 给 ans 加 fold 信息\n",
    "    t1 = train_df[['uid', 'qid', 'fold']].drop_duplicates(subset=['uid', 'qid'], keep='last', inplace=False)\n",
    "    ans_df = pd.merge(ans_df, t1, on=['uid', 'qid'], how='left')\n",
    "    logging.info(\"ans_df shape %s\", ans_df.shape)\n",
    "    \n",
    "    extract_q_feat = ['q_inv_kfold_mean', 'q_inv_kfold_sum', 'q_inv_kfold_std', 'q_inv_kfold_count']\n",
    "    extract_u_feat = ['u_inv_kfold_mean', 'u_inv_kfold_sum', 'u_inv_kfold_std', 'u_inv_kfold_count']\n",
    "    a_feat = ['is_good', 'is_rec', 'is_dest', 'has_img', 'has_video', 'word_count',\n",
    "              'reci_cheer', 'reci_uncheer', 'reci_comment', 'reci_mark', 'reci_tks',\n",
    "              'reci_xxx', 'reci_no_help', 'reci_dis', 'diff_qa_days']\n",
    "    \n",
    "    extract_a_feat = ['q_ans_kfold_count', 'u_ans_kfold_count']\n",
    "    for col in a_feat:\n",
    "        extract_a_feat += [f'q_{col}_sum', f'q_{col}_max', f'q_{col}_mean', \n",
    "                           f'u_{col}_sum', f'u_{col}_max', f'u_{col}_mean']\n",
    "        \n",
    "    extract_feat = extract_q_feat + extract_u_feat + extract_a_feat\n",
    "    \n",
    "    for feat in extract_feat:\n",
    "        train_df[feat] = -10000\n",
    "        \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df)):\n",
    "        logging.info(\"fold %s\", fold_)\n",
    "        \n",
    "        log_trn = train_df_copy.loc[trn_idx]    # 提这些记录里的信息\n",
    "        logging.info(\"log_trn shape %s\", log_trn.shape)\n",
    "        val_df = train_df_copy.loc[val_idx]\n",
    "        logging.info(\"val_df shape %s\", val_df.shape)\n",
    "        log_ans = ans_df.loc[ans_df['fold'] != fold_]  # 排除掉当前 fold 的 ans\n",
    "        logging.info(\"log_ans shape %s\", log_ans.shape)\n",
    "        \n",
    "        # ques\n",
    "        logging.info(\"question info\")\n",
    "        t1 = log_trn.groupby('qid')['label'].agg(['mean', 'sum', 'std', 'count']).reset_index()\n",
    "        t1.columns = ['qid'] + extract_q_feat   # 回答率,回答次数,标准差,邀请次数\n",
    "        train_df.loc[val_idx, extract_q_feat] = pd.merge(val_df, t1, on='qid', how='left')[extract_q_feat].values\n",
    "\n",
    "        # user\n",
    "        logging.info(\"user info\")\n",
    "        t1 = log_trn.groupby('uid')['label'].agg(['mean', 'sum', 'std', 'count']).reset_index()\n",
    "        t1.columns = ['uid'] + extract_u_feat\n",
    "        train_df.loc[val_idx, extract_u_feat] = pd.merge(val_df, t1, on='uid', how='left')[extract_u_feat].values\n",
    "        \n",
    "        # ans\n",
    "        ans_q_group = log_ans.groupby('qid')\n",
    "        ans_u_group = log_ans.groupby('uid')\n",
    "        \n",
    "        logging.info(\"ans: q_ans_kfold_count\")\n",
    "        t1 = ans_q_group['aid'].count().reset_index()\n",
    "        t1.columns = ['qid', 'q_ans_kfold_count']          # 某问题在 answer_info 中的回答次数\n",
    "        train_df.loc[val_idx, ['q_ans_kfold_count']] = pd.merge(val_df, t1, \n",
    "                                                                on='qid', how='left')['q_ans_kfold_count'].values\n",
    "        \n",
    "        logging.info(\"ans: u_ans_kfold_count\")\n",
    "        t1 = ans_u_group['aid'].count().reset_index()\n",
    "        t1.columns = ['uid', 'u_ans_kfold_count']          # 某用户在 answer_info 中的回答次数\n",
    "        train_df.loc[val_idx, ['u_ans_kfold_count']] = pd.merge(val_df, t1, \n",
    "                                                                on='uid', how='left')['u_ans_kfold_count'].values\n",
    "        \n",
    "        for col in a_feat:\n",
    "            logging.info(\"ans: %s sum max mean\", col)\n",
    "            \n",
    "            t1 = ans_q_group[col].agg(['sum', 'max', 'mean']).reset_index()\n",
    "            f_name = [f'q_{col}_sum', f'q_{col}_max', f'q_{col}_mean']\n",
    "            t1.columns = ['qid'] + f_name\n",
    "            train_df.loc[val_idx, f_name] = pd.merge(val_df, t1, on='qid', how='left')[f_name].values\n",
    "            \n",
    "            t1 = ans_u_group[col].agg(['sum', 'max', 'mean']).reset_index()\n",
    "            f_name = [f'u_{col}_sum', f'u_{col}_max', f'u_{col}_mean']\n",
    "            t1.columns = ['uid'] + f_name\n",
    "            train_df.loc[val_idx, f_name] = pd.merge(val_df, t1, on='uid', how='left')[f_name].values\n",
    "            \n",
    "    for feat in extract_feat:\n",
    "        assert len(train_df[train_df[feat]==-10000]) == 0\n",
    "    del train_df['fold']\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-28 12:33:53,044] INFO in <ipython-input-10-19cc53cc0914>: ans_df shape (4513735, 23)\n",
      "[2019-11-28 12:34:23,808] INFO in <ipython-input-10-19cc53cc0914>: ans_df shape (4513735, 24)\n",
      "[2019-11-28 12:34:33,036] INFO in <ipython-input-10-19cc53cc0914>: fold 0\n",
      "[2019-11-28 12:34:33,887] INFO in <ipython-input-10-19cc53cc0914>: log_trn shape (7591329, 5)\n",
      "[2019-11-28 12:34:34,178] INFO in <ipython-input-10-19cc53cc0914>: val_df shape (1897833, 5)\n",
      "[2019-11-28 12:34:36,273] INFO in <ipython-input-10-19cc53cc0914>: log_ans shape (4214053, 24)\n",
      "[2019-11-28 12:34:36,274] INFO in <ipython-input-10-19cc53cc0914>: question info\n",
      "[2019-11-28 12:35:10,465] INFO in <ipython-input-10-19cc53cc0914>: user info\n",
      "[2019-11-28 12:35:38,393] INFO in <ipython-input-10-19cc53cc0914>: ans: q_ans_kfold_count\n",
      "[2019-11-28 12:35:49,341] INFO in <ipython-input-10-19cc53cc0914>: ans: u_ans_kfold_count\n",
      "[2019-11-28 12:35:57,906] INFO in <ipython-input-10-19cc53cc0914>: ans: is_good sum max mean\n",
      "[2019-11-28 12:36:31,191] INFO in <ipython-input-10-19cc53cc0914>: ans: is_rec sum max mean\n",
      "[2019-11-28 12:37:03,535] INFO in <ipython-input-10-19cc53cc0914>: ans: is_dest sum max mean\n",
      "[2019-11-28 12:37:37,409] INFO in <ipython-input-10-19cc53cc0914>: ans: has_img sum max mean\n",
      "[2019-11-28 12:38:11,189] INFO in <ipython-input-10-19cc53cc0914>: ans: has_video sum max mean\n",
      "[2019-11-28 12:38:43,172] INFO in <ipython-input-10-19cc53cc0914>: ans: word_count sum max mean\n",
      "[2019-11-28 12:39:14,627] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_cheer sum max mean\n",
      "[2019-11-28 12:39:45,897] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_uncheer sum max mean\n",
      "[2019-11-28 12:40:16,375] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_comment sum max mean\n",
      "[2019-11-28 12:40:45,974] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_mark sum max mean\n",
      "[2019-11-28 12:41:15,937] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_tks sum max mean\n",
      "[2019-11-28 12:41:45,314] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_xxx sum max mean\n",
      "[2019-11-28 12:42:14,273] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_no_help sum max mean\n",
      "[2019-11-28 12:42:42,772] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_dis sum max mean\n",
      "[2019-11-28 12:43:10,901] INFO in <ipython-input-10-19cc53cc0914>: ans: diff_qa_days sum max mean\n",
      "[2019-11-28 12:43:38,766] INFO in <ipython-input-10-19cc53cc0914>: fold 1\n",
      "[2019-11-28 12:43:39,977] INFO in <ipython-input-10-19cc53cc0914>: log_trn shape (7591329, 5)\n",
      "[2019-11-28 12:43:40,283] INFO in <ipython-input-10-19cc53cc0914>: val_df shape (1897833, 5)\n",
      "[2019-11-28 12:43:41,208] INFO in <ipython-input-10-19cc53cc0914>: log_ans shape (4213300, 24)\n",
      "[2019-11-28 12:43:41,209] INFO in <ipython-input-10-19cc53cc0914>: question info\n",
      "[2019-11-28 12:44:01,435] INFO in <ipython-input-10-19cc53cc0914>: user info\n",
      "[2019-11-28 12:44:17,537] INFO in <ipython-input-10-19cc53cc0914>: ans: q_ans_kfold_count\n",
      "[2019-11-28 12:44:25,018] INFO in <ipython-input-10-19cc53cc0914>: ans: u_ans_kfold_count\n",
      "[2019-11-28 12:44:29,809] INFO in <ipython-input-10-19cc53cc0914>: ans: is_good sum max mean\n",
      "[2019-11-28 12:44:43,720] INFO in <ipython-input-10-19cc53cc0914>: ans: is_rec sum max mean\n",
      "[2019-11-28 12:44:57,854] INFO in <ipython-input-10-19cc53cc0914>: ans: is_dest sum max mean\n",
      "[2019-11-28 12:45:11,590] INFO in <ipython-input-10-19cc53cc0914>: ans: has_img sum max mean\n",
      "[2019-11-28 12:45:25,836] INFO in <ipython-input-10-19cc53cc0914>: ans: has_video sum max mean\n",
      "[2019-11-28 12:45:39,489] INFO in <ipython-input-10-19cc53cc0914>: ans: word_count sum max mean\n",
      "[2019-11-28 12:45:53,704] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_cheer sum max mean\n",
      "[2019-11-28 12:46:07,795] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_uncheer sum max mean\n",
      "[2019-11-28 12:46:22,004] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_comment sum max mean\n",
      "[2019-11-28 12:46:35,793] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_mark sum max mean\n",
      "[2019-11-28 12:46:49,987] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_tks sum max mean\n",
      "[2019-11-28 12:47:04,116] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_xxx sum max mean\n",
      "[2019-11-28 12:47:18,051] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_no_help sum max mean\n",
      "[2019-11-28 12:47:32,156] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_dis sum max mean\n",
      "[2019-11-28 12:47:46,013] INFO in <ipython-input-10-19cc53cc0914>: ans: diff_qa_days sum max mean\n",
      "[2019-11-28 12:48:00,395] INFO in <ipython-input-10-19cc53cc0914>: fold 2\n",
      "[2019-11-28 12:48:01,426] INFO in <ipython-input-10-19cc53cc0914>: log_trn shape (7591330, 5)\n",
      "[2019-11-28 12:48:01,722] INFO in <ipython-input-10-19cc53cc0914>: val_df shape (1897832, 5)\n",
      "[2019-11-28 12:48:02,582] INFO in <ipython-input-10-19cc53cc0914>: log_ans shape (4214078, 24)\n",
      "[2019-11-28 12:48:02,583] INFO in <ipython-input-10-19cc53cc0914>: question info\n",
      "[2019-11-28 12:48:16,724] INFO in <ipython-input-10-19cc53cc0914>: user info\n",
      "[2019-11-28 12:48:32,562] INFO in <ipython-input-10-19cc53cc0914>: ans: q_ans_kfold_count\n",
      "[2019-11-28 12:48:40,269] INFO in <ipython-input-10-19cc53cc0914>: ans: u_ans_kfold_count\n",
      "[2019-11-28 12:48:45,418] INFO in <ipython-input-10-19cc53cc0914>: ans: is_good sum max mean\n",
      "[2019-11-28 12:48:59,720] INFO in <ipython-input-10-19cc53cc0914>: ans: is_rec sum max mean\n",
      "[2019-11-28 12:49:13,583] INFO in <ipython-input-10-19cc53cc0914>: ans: is_dest sum max mean\n",
      "[2019-11-28 12:49:27,737] INFO in <ipython-input-10-19cc53cc0914>: ans: has_img sum max mean\n",
      "[2019-11-28 12:49:41,684] INFO in <ipython-input-10-19cc53cc0914>: ans: has_video sum max mean\n",
      "[2019-11-28 12:49:55,891] INFO in <ipython-input-10-19cc53cc0914>: ans: word_count sum max mean\n",
      "[2019-11-28 12:50:10,077] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_cheer sum max mean\n",
      "[2019-11-28 12:50:24,125] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_uncheer sum max mean\n",
      "[2019-11-28 12:50:38,275] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_comment sum max mean\n",
      "[2019-11-28 12:50:52,232] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_mark sum max mean\n",
      "[2019-11-28 12:51:06,461] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_tks sum max mean\n",
      "[2019-11-28 12:51:20,547] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_xxx sum max mean\n",
      "[2019-11-28 12:51:34,931] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_no_help sum max mean\n",
      "[2019-11-28 12:51:48,709] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_dis sum max mean\n",
      "[2019-11-28 12:52:02,965] INFO in <ipython-input-10-19cc53cc0914>: ans: diff_qa_days sum max mean\n",
      "[2019-11-28 12:52:16,883] INFO in <ipython-input-10-19cc53cc0914>: fold 3\n",
      "[2019-11-28 12:52:17,917] INFO in <ipython-input-10-19cc53cc0914>: log_trn shape (7591330, 5)\n",
      "[2019-11-28 12:52:18,200] INFO in <ipython-input-10-19cc53cc0914>: val_df shape (1897832, 5)\n",
      "[2019-11-28 12:52:19,192] INFO in <ipython-input-10-19cc53cc0914>: log_ans shape (4213351, 24)\n",
      "[2019-11-28 12:52:19,193] INFO in <ipython-input-10-19cc53cc0914>: question info\n",
      "[2019-11-28 12:52:33,397] INFO in <ipython-input-10-19cc53cc0914>: user info\n",
      "[2019-11-28 12:52:48,693] INFO in <ipython-input-10-19cc53cc0914>: ans: q_ans_kfold_count\n",
      "[2019-11-28 12:52:56,276] INFO in <ipython-input-10-19cc53cc0914>: ans: u_ans_kfold_count\n",
      "[2019-11-28 12:53:01,088] INFO in <ipython-input-10-19cc53cc0914>: ans: is_good sum max mean\n",
      "[2019-11-28 12:53:14,978] INFO in <ipython-input-10-19cc53cc0914>: ans: is_rec sum max mean\n",
      "[2019-11-28 12:53:29,032] INFO in <ipython-input-10-19cc53cc0914>: ans: is_dest sum max mean\n",
      "[2019-11-28 12:53:42,573] INFO in <ipython-input-10-19cc53cc0914>: ans: has_img sum max mean\n",
      "[2019-11-28 12:53:56,656] INFO in <ipython-input-10-19cc53cc0914>: ans: has_video sum max mean\n",
      "[2019-11-28 12:54:10,374] INFO in <ipython-input-10-19cc53cc0914>: ans: word_count sum max mean\n",
      "[2019-11-28 12:54:24,809] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_cheer sum max mean\n",
      "[2019-11-28 12:54:38,740] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_uncheer sum max mean\n",
      "[2019-11-28 12:54:52,816] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_comment sum max mean\n",
      "[2019-11-28 12:55:06,558] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_mark sum max mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-28 12:55:20,608] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_tks sum max mean\n",
      "[2019-11-28 12:55:34,359] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_xxx sum max mean\n",
      "[2019-11-28 12:55:48,449] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_no_help sum max mean\n",
      "[2019-11-28 12:56:02,269] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_dis sum max mean\n",
      "[2019-11-28 12:56:16,299] INFO in <ipython-input-10-19cc53cc0914>: ans: diff_qa_days sum max mean\n",
      "[2019-11-28 12:56:30,205] INFO in <ipython-input-10-19cc53cc0914>: fold 4\n",
      "[2019-11-28 12:56:31,515] INFO in <ipython-input-10-19cc53cc0914>: log_trn shape (7591330, 5)\n",
      "[2019-11-28 12:56:31,800] INFO in <ipython-input-10-19cc53cc0914>: val_df shape (1897832, 5)\n",
      "[2019-11-28 12:56:32,725] INFO in <ipython-input-10-19cc53cc0914>: log_ans shape (4213254, 24)\n",
      "[2019-11-28 12:56:32,726] INFO in <ipython-input-10-19cc53cc0914>: question info\n",
      "[2019-11-28 12:56:46,513] INFO in <ipython-input-10-19cc53cc0914>: user info\n",
      "[2019-11-28 12:57:01,863] INFO in <ipython-input-10-19cc53cc0914>: ans: q_ans_kfold_count\n",
      "[2019-11-28 12:57:09,783] INFO in <ipython-input-10-19cc53cc0914>: ans: u_ans_kfold_count\n",
      "[2019-11-28 12:57:14,572] INFO in <ipython-input-10-19cc53cc0914>: ans: is_good sum max mean\n",
      "[2019-11-28 12:57:28,668] INFO in <ipython-input-10-19cc53cc0914>: ans: is_rec sum max mean\n",
      "[2019-11-28 12:57:42,705] INFO in <ipython-input-10-19cc53cc0914>: ans: is_dest sum max mean\n",
      "[2019-11-28 12:57:56,204] INFO in <ipython-input-10-19cc53cc0914>: ans: has_img sum max mean\n",
      "[2019-11-28 12:58:10,265] INFO in <ipython-input-10-19cc53cc0914>: ans: has_video sum max mean\n",
      "[2019-11-28 12:58:23,971] INFO in <ipython-input-10-19cc53cc0914>: ans: word_count sum max mean\n",
      "[2019-11-28 12:58:38,144] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_cheer sum max mean\n",
      "[2019-11-28 12:58:52,053] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_uncheer sum max mean\n",
      "[2019-11-28 12:59:05,903] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_comment sum max mean\n",
      "[2019-11-28 12:59:19,769] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_mark sum max mean\n",
      "[2019-11-28 12:59:33,507] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_tks sum max mean\n",
      "[2019-11-28 12:59:47,441] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_xxx sum max mean\n",
      "[2019-11-28 13:00:01,241] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_no_help sum max mean\n",
      "[2019-11-28 13:00:15,341] INFO in <ipython-input-10-19cc53cc0914>: ans: reci_dis sum max mean\n",
      "[2019-11-28 13:00:29,026] INFO in <ipython-input-10-19cc53cc0914>: ans: diff_qa_days sum max mean\n"
     ]
    }
   ],
   "source": [
    "train_kfold = extract_kfold_train_feature(train, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kfold_test_feature(test_df_, data_df_, ans_df_): \n",
    "    train_df = data_df_.copy()\n",
    "    logging.info(\"train_df shape %s\", train_df.shape)\n",
    "    test_df = test_df_.copy()\n",
    "    logging.info(\"test_df shape %s\", test_df.shape)\n",
    "    ans_df = ans_df_.copy()\n",
    "    logging.info(\"ans_df shape %s\", ans_df.shape)\n",
    "    \n",
    "    extract_q_feat = ['q_inv_kfold_mean', 'q_inv_kfold_sum', 'q_inv_kfold_std', 'q_inv_kfold_count']\n",
    "    extract_u_feat = ['u_inv_kfold_mean', 'u_inv_kfold_sum', 'u_inv_kfold_std', 'u_inv_kfold_count']\n",
    "    a_feat = ['is_good', 'is_rec', 'is_dest', 'has_img', 'has_video', 'word_count',\n",
    "              'reci_cheer', 'reci_uncheer', 'reci_comment', 'reci_mark', 'reci_tks',\n",
    "              'reci_xxx', 'reci_no_help', 'reci_dis', 'diff_qa_days']\n",
    "    \n",
    "    extract_a_feat = ['q_ans_kfold_count', 'u_ans_kfold_count']\n",
    "    for col in a_feat:\n",
    "        extract_a_feat += [f'q_{col}_sum', f'q_{col}_max', f'q_{col}_mean', \n",
    "                           f'u_{col}_sum', f'u_{col}_max', f'u_{col}_mean']\n",
    "        \n",
    "    extract_feat = extract_q_feat + extract_u_feat + extract_a_feat\n",
    "\n",
    "    # ques\n",
    "    logging.info(\"question info\")\n",
    "    t1 = train_df.groupby('qid')['label'].agg(['mean', 'sum', 'std', 'count']).reset_index()\n",
    "    t1.columns = ['qid'] + extract_q_feat   # 回答率,回答次数,标准差,邀请次数\n",
    "    test_df = pd.merge(test_df, t1, on='qid', how='left')\n",
    "\n",
    "    # user\n",
    "    logging.info(\"user info\")\n",
    "    t1 = train_df.groupby('uid')['label'].agg(['mean', 'sum', 'std', 'count']).reset_index()\n",
    "    t1.columns = ['uid'] + extract_u_feat\n",
    "    test_df = pd.merge(test_df, t1, on='uid', how='left')\n",
    "\n",
    "    # ans\n",
    "    ans_q_group = ans_df.groupby('qid')\n",
    "    ans_u_group = ans_df.groupby('uid')\n",
    "    \n",
    "    logging.info(\"ans: q_ans_kfold_count\")\n",
    "    t1 = ans_q_group['aid'].count().reset_index()\n",
    "    t1.columns = ['qid', 'q_ans_kfold_count']          # 某问题在 answer_info 中的回答次数\n",
    "    test_df = pd.merge(test_df, t1, on='qid', how='left')\n",
    "\n",
    "    logging.info(\"ans: u_ans_kfold_count\")\n",
    "    t1 = ans_u_group['aid'].count().reset_index()\n",
    "    t1.columns = ['uid', 'u_ans_kfold_count']          # 某用户在 answer_info 中的回答次数\n",
    "    test_df = pd.merge(test_df, t1, on='uid', how='left')\n",
    "\n",
    "    for col in a_feat:\n",
    "        logging.info(\"ans: %s sum max mean\", col)\n",
    "        \n",
    "        t1 = ans_q_group[col].agg(['sum', 'max', 'mean']).reset_index()\n",
    "        f_name = [f'q_{col}_sum', f'q_{col}_max', f'q_{col}_mean']\n",
    "        t1.columns = ['qid'] + f_name\n",
    "        test_df = pd.merge(test_df, t1, on='qid', how='left')\n",
    "\n",
    "        t1 = ans_u_group[col].agg(['sum', 'max', 'mean']).reset_index()\n",
    "        f_name = [f'u_{col}_sum', f'u_{col}_max', f'u_{col}_mean']\n",
    "        t1.columns = ['uid'] + f_name\n",
    "        test_df = pd.merge(test_df, t1, on='uid', how='left')\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-28 13:00:45,992] INFO in <ipython-input-12-a98a4be4d7c5>: train_df shape (9489162, 5)\n",
      "[2019-11-28 13:00:46,062] INFO in <ipython-input-12-a98a4be4d7c5>: test_df shape (1141683, 4)\n",
      "[2019-11-28 13:00:46,398] INFO in <ipython-input-12-a98a4be4d7c5>: ans_df shape (4513735, 23)\n",
      "[2019-11-28 13:00:46,399] INFO in <ipython-input-12-a98a4be4d7c5>: question info\n",
      "[2019-11-28 13:00:54,155] INFO in <ipython-input-12-a98a4be4d7c5>: user info\n",
      "[2019-11-28 13:01:04,022] INFO in <ipython-input-12-a98a4be4d7c5>: ans: q_ans_kfold_count\n",
      "[2019-11-28 13:01:10,880] INFO in <ipython-input-12-a98a4be4d7c5>: ans: u_ans_kfold_count\n",
      "[2019-11-28 13:01:15,302] INFO in <ipython-input-12-a98a4be4d7c5>: ans: is_good sum max mean\n",
      "[2019-11-28 13:01:20,339] INFO in <ipython-input-12-a98a4be4d7c5>: ans: is_rec sum max mean\n",
      "[2019-11-28 13:01:25,172] INFO in <ipython-input-12-a98a4be4d7c5>: ans: is_dest sum max mean\n",
      "[2019-11-28 13:01:30,013] INFO in <ipython-input-12-a98a4be4d7c5>: ans: has_img sum max mean\n",
      "[2019-11-28 13:01:34,987] INFO in <ipython-input-12-a98a4be4d7c5>: ans: has_video sum max mean\n",
      "[2019-11-28 13:01:40,101] INFO in <ipython-input-12-a98a4be4d7c5>: ans: word_count sum max mean\n",
      "[2019-11-28 13:01:45,387] INFO in <ipython-input-12-a98a4be4d7c5>: ans: reci_cheer sum max mean\n",
      "[2019-11-28 13:01:50,808] INFO in <ipython-input-12-a98a4be4d7c5>: ans: reci_uncheer sum max mean\n",
      "[2019-11-28 13:01:56,017] INFO in <ipython-input-12-a98a4be4d7c5>: ans: reci_comment sum max mean\n",
      "[2019-11-28 13:02:01,375] INFO in <ipython-input-12-a98a4be4d7c5>: ans: reci_mark sum max mean\n",
      "[2019-11-28 13:02:06,586] INFO in <ipython-input-12-a98a4be4d7c5>: ans: reci_tks sum max mean\n",
      "[2019-11-28 13:02:11,870] INFO in <ipython-input-12-a98a4be4d7c5>: ans: reci_xxx sum max mean\n",
      "[2019-11-28 13:02:17,274] INFO in <ipython-input-12-a98a4be4d7c5>: ans: reci_no_help sum max mean\n",
      "[2019-11-28 13:02:22,654] INFO in <ipython-input-12-a98a4be4d7c5>: ans: reci_dis sum max mean\n",
      "[2019-11-28 13:02:28,334] INFO in <ipython-input-12-a98a4be4d7c5>: ans: diff_qa_days sum max mean\n"
     ]
    }
   ],
   "source": [
    "test_kfold = extract_kfold_test_feature(test, train[['uid', 'qid', 'day', 'hour', 'label']], ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354695"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo: 考虑在训练集中,人为补 nan\n",
    "# test_kfold['q_inv_kfold_mean'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1057029"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_kfold['u_inv_kfold_mean'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_kfold['uid'], train_kfold['qid'], train_kfold['label']\n",
    "del test_kfold['uid'], test_kfold['qid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 压缩数据\n",
    "t = train_kfold.dtypes\n",
    "for x in t[t == 'int64'].index:\n",
    "    train_kfold[x] = train_kfold[x].astype('int32')\n",
    "    test_kfold[x] = test_kfold[x].astype('int32')\n",
    "\n",
    "for x in t[t == 'float64'].index:\n",
    "    train_kfold[x] = train_kfold[x].astype('float32')\n",
    "    test_kfold[x] = test_kfold[x].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kfold.to_csv('feature/train_kfold_feature.txt', sep='\\t')\n",
    "test_kfold.to_csv('feature/test_kfold_feature.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
